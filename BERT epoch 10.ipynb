{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/amogh/anaconda3/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/amogh/anaconda3/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: transformers in /home/amogh/anaconda3/lib/python3.8/site-packages (4.28.0)\n",
      "Requirement already satisfied: scikit-learn in /home/amogh/anaconda3/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied: filelock in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: fsspec in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: sympy in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (1.6.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /home/amogh/anaconda3/lib/python3.8/site-packages (from torch) (2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: numpy in /home/amogh/anaconda3/lib/python3.8/site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: requests in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/amogh/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/amogh/anaconda3/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/amogh/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/amogh/anaconda3/lib/python3.8/site-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/amogh/anaconda3/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/amogh/anaconda3/lib/python3.8/site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/amogh/anaconda3/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amogh/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/amogh/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/amogh/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/amogh/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /home/amogh/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/amogh/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers scikit-learn  \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "from transformers import BertTokenizer, BertForSequenceClassification  \n",
    "import pandas as pd  \n",
    "from sklearn.metrics import precision_recall_fscore_support  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):  \n",
    "    def __init__(self, data):  \n",
    "        self.input_ids = data['input_ids']  \n",
    "        self.attention_mask = data['attention_mask']  \n",
    "        self.label = data['label']  \n",
    "\n",
    "    def __len__(self):  \n",
    "        return self.input_ids.size(0)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        return (  \n",
    "            self.input_ids[idx],   \n",
    "            self.attention_mask[idx],   \n",
    "            self.label[idx],   \n",
    "        )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-58cc5e8aee9f>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(train_data_path)\n",
      "<ipython-input-4-58cc5e8aee9f>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_data = torch.load(val_data_path)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"correct_train.pt\"  \n",
    "val_data_path = \"correct_val.pt\"  \n",
    "\n",
    "train_data = torch.load(train_data_path)  \n",
    "val_data = torch.load(val_data_path)  \n",
    "\n",
    "train_dataset = CustomDataset(train_data)  \n",
    "val_dataset = CustomDataset(val_data)  \n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  \n",
    "\n",
    "print(\"Data loaders created successfully.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM model initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amogh/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BiLSTM(nn.Module):  \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):  \n",
    "        super(BiLSTM, self).__init__()  \n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)  \n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, bidirectional=True, batch_first=True)  \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  \n",
    "        embedded = self.embedding(input_ids)  \n",
    "        lstm_out, _ = self.lstm(embedded)  \n",
    "        masked_out = lstm_out * attention_mask.unsqueeze(2)  \n",
    "        pooled = torch.mean(masked_out, dim=1)  \n",
    "        output = self.fc(pooled)  \n",
    "        return output  \n",
    "\n",
    "input_dim = 30522  \n",
    "hidden_dim = 128  \n",
    "output_dim = 5  \n",
    "\n",
    "bilstm_model = BiLSTM(input_dim, hidden_dim, output_dim)  \n",
    "bilstm_criterion = nn.CrossEntropyLoss()  \n",
    "bilstm_optimizer = optim.Adam(bilstm_model.parameters(), lr=0.001)  \n",
    "\n",
    "print(\"BiLSTM model initialized.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amogh/anaconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model initialized.\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)  \n",
    "bert_model = bert_model.to(device)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")  \n",
    "bert_criterion = nn.CrossEntropyLoss()  \n",
    "bert_optimizer = optim.Adam(bert_model.parameters(), lr=2e-5)  \n",
    "\n",
    "print(\"BERT model initialized.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_logs(model, criterion, optimizer, loader, epochs, is_bert=False):  \n",
    "    for epoch in range(epochs):  \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs} running...\")  \n",
    "        model.train()  \n",
    "        total_loss = 0  \n",
    "        print(next(model.parameters()).device)\n",
    "        \n",
    "\n",
    "\n",
    "        for batch_idx, (input_ids, attention_mask, labels) in enumerate(loader):  \n",
    "            optimizer.zero_grad()  \n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if is_bert:  \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)  \n",
    "                loss = outputs.loss  \n",
    "            else:  \n",
    "                outputs = model(input_ids, attention_mask)  \n",
    "                loss = criterion(outputs, labels)  \n",
    "\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            total_loss += loss.item()  \n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0 or batch_idx == len(loader) - 1:  \n",
    "                print(  \n",
    "                    f\"Epoch {epoch + 1}/{epochs}, Batch {batch_idx + 1}/{len(loader)}, \"  \n",
    "                    f\"Batch Loss: {loss.item():.4f}, Total Loss: {total_loss:.4f}\"  \n",
    "                )  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} completed. Total Loss: {total_loss:.4f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_with_logs(model, loader, is_bert=False):\n",
    "    print(\"\\nRunning Validation...\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions_list = []\n",
    "    total_batches = len(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_ids, attention_mask, labels) in enumerate(loader):\n",
    "            #optimizer.zero_grad()\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if is_bert:\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            predictions_list.extend(preds.tolist())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Print progress every 10 batches\n",
    "            if (batch_idx + 1) % 10== 0 or batch_idx == total_batches - 1:\n",
    "                print(f\"Validation Batch {batch_idx + 1}/{total_batches} completed.\")\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    return predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT\n",
      "\n",
      "Epoch 1/10 running...\n",
      "cuda:0\n",
      "Epoch 1/10, Batch 10/4401, Batch Loss: 1.6157, Total Loss: 16.2445\n",
      "Epoch 1/10, Batch 20/4401, Batch Loss: 1.7192, Total Loss: 32.2602\n",
      "Epoch 1/10, Batch 30/4401, Batch Loss: 1.5841, Total Loss: 47.8309\n",
      "Epoch 1/10, Batch 40/4401, Batch Loss: 1.4459, Total Loss: 62.5742\n",
      "Epoch 1/10, Batch 50/4401, Batch Loss: 1.1512, Total Loss: 76.3531\n",
      "Epoch 1/10, Batch 60/4401, Batch Loss: 1.3776, Total Loss: 90.5508\n",
      "Epoch 1/10, Batch 70/4401, Batch Loss: 1.3032, Total Loss: 105.4470\n",
      "Epoch 1/10, Batch 80/4401, Batch Loss: 1.5760, Total Loss: 119.1559\n",
      "Epoch 1/10, Batch 90/4401, Batch Loss: 1.0302, Total Loss: 132.6608\n",
      "Epoch 1/10, Batch 100/4401, Batch Loss: 1.4257, Total Loss: 146.6169\n",
      "Epoch 1/10, Batch 110/4401, Batch Loss: 1.2415, Total Loss: 160.7262\n",
      "Epoch 1/10, Batch 120/4401, Batch Loss: 1.4874, Total Loss: 174.7321\n",
      "Epoch 1/10, Batch 130/4401, Batch Loss: 1.6398, Total Loss: 188.0443\n",
      "Epoch 1/10, Batch 140/4401, Batch Loss: 1.2323, Total Loss: 201.7096\n",
      "Epoch 1/10, Batch 150/4401, Batch Loss: 1.4071, Total Loss: 216.2181\n",
      "Epoch 1/10, Batch 160/4401, Batch Loss: 1.5275, Total Loss: 230.2642\n",
      "Epoch 1/10, Batch 170/4401, Batch Loss: 1.3434, Total Loss: 244.1233\n",
      "Epoch 1/10, Batch 180/4401, Batch Loss: 1.3115, Total Loss: 257.8914\n",
      "Epoch 1/10, Batch 190/4401, Batch Loss: 1.1493, Total Loss: 271.4689\n",
      "Epoch 1/10, Batch 200/4401, Batch Loss: 1.4650, Total Loss: 286.3977\n",
      "Epoch 1/10, Batch 210/4401, Batch Loss: 1.3011, Total Loss: 300.6425\n",
      "Epoch 1/10, Batch 220/4401, Batch Loss: 1.1195, Total Loss: 312.7769\n",
      "Epoch 1/10, Batch 230/4401, Batch Loss: 1.1049, Total Loss: 324.7155\n",
      "Epoch 1/10, Batch 240/4401, Batch Loss: 1.1109, Total Loss: 337.4703\n",
      "Epoch 1/10, Batch 250/4401, Batch Loss: 0.9887, Total Loss: 350.6177\n",
      "Epoch 1/10, Batch 260/4401, Batch Loss: 1.0314, Total Loss: 364.2472\n",
      "Epoch 1/10, Batch 270/4401, Batch Loss: 1.5621, Total Loss: 378.7047\n",
      "Epoch 1/10, Batch 280/4401, Batch Loss: 1.2515, Total Loss: 391.9815\n",
      "Epoch 1/10, Batch 290/4401, Batch Loss: 1.5861, Total Loss: 405.2687\n",
      "Epoch 1/10, Batch 300/4401, Batch Loss: 1.3602, Total Loss: 419.3543\n",
      "Epoch 1/10, Batch 310/4401, Batch Loss: 1.3946, Total Loss: 433.2107\n",
      "Epoch 1/10, Batch 320/4401, Batch Loss: 1.6305, Total Loss: 446.3264\n",
      "Epoch 1/10, Batch 330/4401, Batch Loss: 0.9271, Total Loss: 459.6423\n",
      "Epoch 1/10, Batch 340/4401, Batch Loss: 1.5394, Total Loss: 474.0796\n",
      "Epoch 1/10, Batch 350/4401, Batch Loss: 1.4377, Total Loss: 487.6612\n",
      "Epoch 1/10, Batch 360/4401, Batch Loss: 1.3723, Total Loss: 500.7193\n",
      "Epoch 1/10, Batch 370/4401, Batch Loss: 1.3081, Total Loss: 513.2575\n",
      "Epoch 1/10, Batch 380/4401, Batch Loss: 1.4413, Total Loss: 526.0748\n",
      "Epoch 1/10, Batch 390/4401, Batch Loss: 1.1727, Total Loss: 538.8114\n",
      "Epoch 1/10, Batch 400/4401, Batch Loss: 1.6744, Total Loss: 551.2453\n",
      "Epoch 1/10, Batch 410/4401, Batch Loss: 1.3583, Total Loss: 565.5155\n",
      "Epoch 1/10, Batch 420/4401, Batch Loss: 1.0304, Total Loss: 578.8473\n",
      "Epoch 1/10, Batch 430/4401, Batch Loss: 1.5739, Total Loss: 591.9599\n",
      "Epoch 1/10, Batch 440/4401, Batch Loss: 1.2928, Total Loss: 605.0213\n",
      "Epoch 1/10, Batch 450/4401, Batch Loss: 1.2106, Total Loss: 617.1162\n",
      "Epoch 1/10, Batch 460/4401, Batch Loss: 1.3441, Total Loss: 629.1767\n",
      "Epoch 1/10, Batch 470/4401, Batch Loss: 1.2873, Total Loss: 641.1917\n",
      "Epoch 1/10, Batch 480/4401, Batch Loss: 1.0095, Total Loss: 652.9941\n",
      "Epoch 1/10, Batch 490/4401, Batch Loss: 1.3819, Total Loss: 664.6520\n",
      "Epoch 1/10, Batch 500/4401, Batch Loss: 0.8231, Total Loss: 677.5184\n",
      "Epoch 1/10, Batch 510/4401, Batch Loss: 1.0140, Total Loss: 688.0349\n",
      "Epoch 1/10, Batch 520/4401, Batch Loss: 1.5622, Total Loss: 701.1224\n",
      "Epoch 1/10, Batch 530/4401, Batch Loss: 1.4301, Total Loss: 714.6572\n",
      "Epoch 1/10, Batch 540/4401, Batch Loss: 1.6809, Total Loss: 727.5808\n",
      "Epoch 1/10, Batch 550/4401, Batch Loss: 1.0393, Total Loss: 740.0717\n",
      "Epoch 1/10, Batch 560/4401, Batch Loss: 1.1208, Total Loss: 752.9383\n",
      "Epoch 1/10, Batch 570/4401, Batch Loss: 1.0323, Total Loss: 766.3694\n",
      "Epoch 1/10, Batch 580/4401, Batch Loss: 1.0596, Total Loss: 779.1876\n",
      "Epoch 1/10, Batch 590/4401, Batch Loss: 0.5972, Total Loss: 791.0764\n",
      "Epoch 1/10, Batch 600/4401, Batch Loss: 1.1641, Total Loss: 802.8473\n",
      "Epoch 1/10, Batch 610/4401, Batch Loss: 1.0947, Total Loss: 814.2192\n",
      "Epoch 1/10, Batch 620/4401, Batch Loss: 1.1991, Total Loss: 826.5217\n",
      "Epoch 1/10, Batch 630/4401, Batch Loss: 1.4614, Total Loss: 839.6717\n",
      "Epoch 1/10, Batch 640/4401, Batch Loss: 0.9584, Total Loss: 852.1998\n",
      "Epoch 1/10, Batch 650/4401, Batch Loss: 1.0484, Total Loss: 864.7363\n",
      "Epoch 1/10, Batch 660/4401, Batch Loss: 1.4559, Total Loss: 877.3561\n",
      "Epoch 1/10, Batch 670/4401, Batch Loss: 0.7589, Total Loss: 888.6144\n",
      "Epoch 1/10, Batch 680/4401, Batch Loss: 0.9806, Total Loss: 900.8527\n",
      "Epoch 1/10, Batch 690/4401, Batch Loss: 1.4549, Total Loss: 911.6329\n",
      "Epoch 1/10, Batch 700/4401, Batch Loss: 0.9568, Total Loss: 924.4408\n",
      "Epoch 1/10, Batch 710/4401, Batch Loss: 1.1805, Total Loss: 935.3378\n",
      "Epoch 1/10, Batch 720/4401, Batch Loss: 1.2540, Total Loss: 947.5124\n",
      "Epoch 1/10, Batch 730/4401, Batch Loss: 1.0973, Total Loss: 960.3665\n",
      "Epoch 1/10, Batch 740/4401, Batch Loss: 1.2783, Total Loss: 972.0563\n",
      "Epoch 1/10, Batch 750/4401, Batch Loss: 1.1984, Total Loss: 983.3457\n",
      "Epoch 1/10, Batch 760/4401, Batch Loss: 0.5054, Total Loss: 993.7817\n",
      "Epoch 1/10, Batch 770/4401, Batch Loss: 1.5116, Total Loss: 1004.5702\n",
      "Epoch 1/10, Batch 780/4401, Batch Loss: 0.9726, Total Loss: 1016.9389\n",
      "Epoch 1/10, Batch 790/4401, Batch Loss: 1.0632, Total Loss: 1028.2828\n",
      "Epoch 1/10, Batch 800/4401, Batch Loss: 1.4547, Total Loss: 1041.2639\n",
      "Epoch 1/10, Batch 810/4401, Batch Loss: 0.6652, Total Loss: 1051.7561\n",
      "Epoch 1/10, Batch 820/4401, Batch Loss: 1.1530, Total Loss: 1063.1073\n",
      "Epoch 1/10, Batch 830/4401, Batch Loss: 1.2014, Total Loss: 1076.3766\n",
      "Epoch 1/10, Batch 840/4401, Batch Loss: 1.6373, Total Loss: 1088.6943\n",
      "Epoch 1/10, Batch 850/4401, Batch Loss: 1.4605, Total Loss: 1101.4589\n",
      "Epoch 1/10, Batch 860/4401, Batch Loss: 1.1437, Total Loss: 1112.4423\n",
      "Epoch 1/10, Batch 870/4401, Batch Loss: 0.8970, Total Loss: 1123.2277\n",
      "Epoch 1/10, Batch 880/4401, Batch Loss: 0.9693, Total Loss: 1133.1838\n",
      "Epoch 1/10, Batch 890/4401, Batch Loss: 1.1352, Total Loss: 1144.4491\n",
      "Epoch 1/10, Batch 900/4401, Batch Loss: 0.9471, Total Loss: 1155.6982\n",
      "Epoch 1/10, Batch 910/4401, Batch Loss: 1.2871, Total Loss: 1166.6567\n",
      "Epoch 1/10, Batch 920/4401, Batch Loss: 0.6316, Total Loss: 1175.9915\n",
      "Epoch 1/10, Batch 930/4401, Batch Loss: 1.8974, Total Loss: 1188.3776\n",
      "Epoch 1/10, Batch 940/4401, Batch Loss: 0.6080, Total Loss: 1199.4415\n",
      "Epoch 1/10, Batch 950/4401, Batch Loss: 1.1252, Total Loss: 1209.2196\n",
      "Epoch 1/10, Batch 960/4401, Batch Loss: 1.6446, Total Loss: 1219.5918\n",
      "Epoch 1/10, Batch 970/4401, Batch Loss: 1.3712, Total Loss: 1230.4377\n",
      "Epoch 1/10, Batch 980/4401, Batch Loss: 0.7995, Total Loss: 1241.6908\n",
      "Epoch 1/10, Batch 990/4401, Batch Loss: 0.9847, Total Loss: 1253.0457\n",
      "Epoch 1/10, Batch 1000/4401, Batch Loss: 1.4255, Total Loss: 1264.4988\n",
      "Epoch 1/10, Batch 1010/4401, Batch Loss: 1.1149, Total Loss: 1276.2973\n",
      "Epoch 1/10, Batch 1020/4401, Batch Loss: 0.7555, Total Loss: 1287.6731\n",
      "Epoch 1/10, Batch 1030/4401, Batch Loss: 1.4685, Total Loss: 1299.7085\n",
      "Epoch 1/10, Batch 1040/4401, Batch Loss: 1.1593, Total Loss: 1311.7410\n",
      "Epoch 1/10, Batch 1050/4401, Batch Loss: 0.9613, Total Loss: 1323.4592\n",
      "Epoch 1/10, Batch 1060/4401, Batch Loss: 0.8620, Total Loss: 1336.1355\n",
      "Epoch 1/10, Batch 1070/4401, Batch Loss: 1.4423, Total Loss: 1348.2437\n",
      "Epoch 1/10, Batch 1080/4401, Batch Loss: 1.0027, Total Loss: 1359.6048\n",
      "Epoch 1/10, Batch 1090/4401, Batch Loss: 0.6853, Total Loss: 1370.8789\n",
      "Epoch 1/10, Batch 1100/4401, Batch Loss: 0.7792, Total Loss: 1382.1478\n",
      "Epoch 1/10, Batch 1110/4401, Batch Loss: 0.9296, Total Loss: 1393.6508\n",
      "Epoch 1/10, Batch 1120/4401, Batch Loss: 0.5006, Total Loss: 1404.1968\n",
      "Epoch 1/10, Batch 1130/4401, Batch Loss: 1.0819, Total Loss: 1415.2596\n",
      "Epoch 1/10, Batch 1140/4401, Batch Loss: 0.9737, Total Loss: 1426.7345\n",
      "Epoch 1/10, Batch 1150/4401, Batch Loss: 1.2788, Total Loss: 1438.3699\n",
      "Epoch 1/10, Batch 1160/4401, Batch Loss: 1.6007, Total Loss: 1451.8782\n",
      "Epoch 1/10, Batch 1170/4401, Batch Loss: 1.3978, Total Loss: 1464.7804\n",
      "Epoch 1/10, Batch 1180/4401, Batch Loss: 0.8393, Total Loss: 1475.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1190/4401, Batch Loss: 1.0013, Total Loss: 1484.8570\n",
      "Epoch 1/10, Batch 1200/4401, Batch Loss: 1.4868, Total Loss: 1496.5814\n",
      "Epoch 1/10, Batch 1210/4401, Batch Loss: 1.4716, Total Loss: 1507.0319\n",
      "Epoch 1/10, Batch 1220/4401, Batch Loss: 1.2261, Total Loss: 1517.9858\n",
      "Epoch 1/10, Batch 1230/4401, Batch Loss: 1.0721, Total Loss: 1527.7584\n",
      "Epoch 1/10, Batch 1240/4401, Batch Loss: 1.0476, Total Loss: 1537.6592\n",
      "Epoch 1/10, Batch 1250/4401, Batch Loss: 0.9525, Total Loss: 1547.4470\n",
      "Epoch 1/10, Batch 1260/4401, Batch Loss: 1.4010, Total Loss: 1558.3639\n",
      "Epoch 1/10, Batch 1270/4401, Batch Loss: 0.9802, Total Loss: 1568.1528\n",
      "Epoch 1/10, Batch 1280/4401, Batch Loss: 0.6150, Total Loss: 1576.4318\n",
      "Epoch 1/10, Batch 1290/4401, Batch Loss: 1.0026, Total Loss: 1587.9316\n",
      "Epoch 1/10, Batch 1300/4401, Batch Loss: 0.8457, Total Loss: 1598.0644\n",
      "Epoch 1/10, Batch 1310/4401, Batch Loss: 0.9844, Total Loss: 1606.6645\n",
      "Epoch 1/10, Batch 1320/4401, Batch Loss: 0.4530, Total Loss: 1617.1187\n",
      "Epoch 1/10, Batch 1330/4401, Batch Loss: 1.2357, Total Loss: 1627.5667\n",
      "Epoch 1/10, Batch 1340/4401, Batch Loss: 0.8482, Total Loss: 1638.4816\n",
      "Epoch 1/10, Batch 1350/4401, Batch Loss: 0.7025, Total Loss: 1648.7488\n",
      "Epoch 1/10, Batch 1360/4401, Batch Loss: 1.1352, Total Loss: 1659.8884\n",
      "Epoch 1/10, Batch 1370/4401, Batch Loss: 1.4988, Total Loss: 1671.4746\n",
      "Epoch 1/10, Batch 1380/4401, Batch Loss: 1.5305, Total Loss: 1681.8067\n",
      "Epoch 1/10, Batch 1390/4401, Batch Loss: 1.2052, Total Loss: 1691.5729\n",
      "Epoch 1/10, Batch 1400/4401, Batch Loss: 0.7560, Total Loss: 1700.2944\n",
      "Epoch 1/10, Batch 1410/4401, Batch Loss: 0.8448, Total Loss: 1710.1684\n",
      "Epoch 1/10, Batch 1420/4401, Batch Loss: 1.0636, Total Loss: 1720.2979\n",
      "Epoch 1/10, Batch 1430/4401, Batch Loss: 1.6729, Total Loss: 1730.0927\n",
      "Epoch 1/10, Batch 1440/4401, Batch Loss: 0.7804, Total Loss: 1739.4913\n",
      "Epoch 1/10, Batch 1450/4401, Batch Loss: 0.9501, Total Loss: 1749.3134\n",
      "Epoch 1/10, Batch 1460/4401, Batch Loss: 1.3466, Total Loss: 1758.8737\n",
      "Epoch 1/10, Batch 1470/4401, Batch Loss: 0.7471, Total Loss: 1768.8767\n",
      "Epoch 1/10, Batch 1480/4401, Batch Loss: 0.6925, Total Loss: 1778.2183\n",
      "Epoch 1/10, Batch 1490/4401, Batch Loss: 0.9875, Total Loss: 1787.0058\n",
      "Epoch 1/10, Batch 1500/4401, Batch Loss: 1.1059, Total Loss: 1796.2401\n",
      "Epoch 1/10, Batch 1510/4401, Batch Loss: 1.0044, Total Loss: 1805.9633\n",
      "Epoch 1/10, Batch 1520/4401, Batch Loss: 1.7038, Total Loss: 1815.6003\n",
      "Epoch 1/10, Batch 1530/4401, Batch Loss: 0.7649, Total Loss: 1825.7463\n",
      "Epoch 1/10, Batch 1540/4401, Batch Loss: 1.0806, Total Loss: 1835.3997\n",
      "Epoch 1/10, Batch 1550/4401, Batch Loss: 1.1893, Total Loss: 1845.8302\n",
      "Epoch 1/10, Batch 1560/4401, Batch Loss: 0.8147, Total Loss: 1855.1266\n",
      "Epoch 1/10, Batch 1570/4401, Batch Loss: 0.7070, Total Loss: 1864.8564\n",
      "Epoch 1/10, Batch 1580/4401, Batch Loss: 0.6841, Total Loss: 1872.6727\n",
      "Epoch 1/10, Batch 1590/4401, Batch Loss: 0.7103, Total Loss: 1881.4593\n",
      "Epoch 1/10, Batch 1600/4401, Batch Loss: 0.8968, Total Loss: 1893.0155\n",
      "Epoch 1/10, Batch 1610/4401, Batch Loss: 1.0367, Total Loss: 1902.7272\n",
      "Epoch 1/10, Batch 1620/4401, Batch Loss: 1.0838, Total Loss: 1912.7928\n",
      "Epoch 1/10, Batch 1630/4401, Batch Loss: 1.0535, Total Loss: 1921.4096\n",
      "Epoch 1/10, Batch 1640/4401, Batch Loss: 0.4944, Total Loss: 1929.6128\n",
      "Epoch 1/10, Batch 1650/4401, Batch Loss: 1.1945, Total Loss: 1937.9804\n",
      "Epoch 1/10, Batch 1660/4401, Batch Loss: 1.1886, Total Loss: 1946.9832\n",
      "Epoch 1/10, Batch 1670/4401, Batch Loss: 0.5973, Total Loss: 1955.0628\n",
      "Epoch 1/10, Batch 1680/4401, Batch Loss: 1.1028, Total Loss: 1963.4545\n",
      "Epoch 1/10, Batch 1690/4401, Batch Loss: 1.0875, Total Loss: 1972.5436\n",
      "Epoch 1/10, Batch 1700/4401, Batch Loss: 1.0060, Total Loss: 1982.1803\n",
      "Epoch 1/10, Batch 1710/4401, Batch Loss: 0.6760, Total Loss: 1989.3300\n",
      "Epoch 1/10, Batch 1720/4401, Batch Loss: 1.2956, Total Loss: 1997.4495\n",
      "Epoch 1/10, Batch 1730/4401, Batch Loss: 1.0905, Total Loss: 2004.3519\n",
      "Epoch 1/10, Batch 1740/4401, Batch Loss: 1.3082, Total Loss: 2013.4053\n",
      "Epoch 1/10, Batch 1750/4401, Batch Loss: 0.4502, Total Loss: 2023.4389\n",
      "Epoch 1/10, Batch 1760/4401, Batch Loss: 1.1621, Total Loss: 2032.5129\n",
      "Epoch 1/10, Batch 1770/4401, Batch Loss: 0.9065, Total Loss: 2041.2877\n",
      "Epoch 1/10, Batch 1780/4401, Batch Loss: 0.5572, Total Loss: 2049.1718\n",
      "Epoch 1/10, Batch 1790/4401, Batch Loss: 1.3007, Total Loss: 2058.8612\n",
      "Epoch 1/10, Batch 1800/4401, Batch Loss: 1.3086, Total Loss: 2066.7577\n",
      "Epoch 1/10, Batch 1810/4401, Batch Loss: 0.8451, Total Loss: 2077.0177\n",
      "Epoch 1/10, Batch 1820/4401, Batch Loss: 0.6843, Total Loss: 2086.7898\n",
      "Epoch 1/10, Batch 1830/4401, Batch Loss: 0.6739, Total Loss: 2095.4254\n",
      "Epoch 1/10, Batch 1840/4401, Batch Loss: 1.6532, Total Loss: 2104.6272\n",
      "Epoch 1/10, Batch 1850/4401, Batch Loss: 0.6341, Total Loss: 2112.9889\n",
      "Epoch 1/10, Batch 1860/4401, Batch Loss: 0.9484, Total Loss: 2121.8670\n",
      "Epoch 1/10, Batch 1870/4401, Batch Loss: 1.3818, Total Loss: 2131.9974\n",
      "Epoch 1/10, Batch 1880/4401, Batch Loss: 0.7941, Total Loss: 2139.1731\n",
      "Epoch 1/10, Batch 1890/4401, Batch Loss: 0.8069, Total Loss: 2148.5335\n",
      "Epoch 1/10, Batch 1900/4401, Batch Loss: 1.0982, Total Loss: 2156.1092\n",
      "Epoch 1/10, Batch 1910/4401, Batch Loss: 0.7469, Total Loss: 2164.6395\n",
      "Epoch 1/10, Batch 1920/4401, Batch Loss: 1.2553, Total Loss: 2173.1895\n",
      "Epoch 1/10, Batch 1930/4401, Batch Loss: 0.6933, Total Loss: 2181.1866\n",
      "Epoch 1/10, Batch 1940/4401, Batch Loss: 1.0792, Total Loss: 2191.0432\n",
      "Epoch 1/10, Batch 1950/4401, Batch Loss: 0.5013, Total Loss: 2199.3506\n",
      "Epoch 1/10, Batch 1960/4401, Batch Loss: 0.4739, Total Loss: 2206.5754\n",
      "Epoch 1/10, Batch 1970/4401, Batch Loss: 1.2391, Total Loss: 2216.8426\n",
      "Epoch 1/10, Batch 1980/4401, Batch Loss: 1.2758, Total Loss: 2224.7453\n",
      "Epoch 1/10, Batch 1990/4401, Batch Loss: 0.7432, Total Loss: 2232.4240\n",
      "Epoch 1/10, Batch 2000/4401, Batch Loss: 0.6507, Total Loss: 2240.4468\n",
      "Epoch 1/10, Batch 2010/4401, Batch Loss: 0.7606, Total Loss: 2248.8860\n",
      "Epoch 1/10, Batch 2020/4401, Batch Loss: 0.6853, Total Loss: 2259.1897\n",
      "Epoch 1/10, Batch 2030/4401, Batch Loss: 1.0466, Total Loss: 2268.0055\n",
      "Epoch 1/10, Batch 2040/4401, Batch Loss: 0.4680, Total Loss: 2274.8197\n",
      "Epoch 1/10, Batch 2050/4401, Batch Loss: 1.0432, Total Loss: 2281.4415\n",
      "Epoch 1/10, Batch 2060/4401, Batch Loss: 0.6082, Total Loss: 2289.6756\n",
      "Epoch 1/10, Batch 2070/4401, Batch Loss: 0.3193, Total Loss: 2297.5012\n",
      "Epoch 1/10, Batch 2080/4401, Batch Loss: 1.1791, Total Loss: 2304.8811\n",
      "Epoch 1/10, Batch 2090/4401, Batch Loss: 0.3313, Total Loss: 2312.7696\n",
      "Epoch 1/10, Batch 2100/4401, Batch Loss: 1.2564, Total Loss: 2321.3660\n",
      "Epoch 1/10, Batch 2110/4401, Batch Loss: 0.3914, Total Loss: 2328.7234\n",
      "Epoch 1/10, Batch 2120/4401, Batch Loss: 0.9291, Total Loss: 2338.7284\n",
      "Epoch 1/10, Batch 2130/4401, Batch Loss: 0.9528, Total Loss: 2345.6901\n",
      "Epoch 1/10, Batch 2140/4401, Batch Loss: 1.0561, Total Loss: 2355.6607\n",
      "Epoch 1/10, Batch 2150/4401, Batch Loss: 0.5095, Total Loss: 2362.8432\n",
      "Epoch 1/10, Batch 2160/4401, Batch Loss: 0.6716, Total Loss: 2371.7598\n",
      "Epoch 1/10, Batch 2170/4401, Batch Loss: 0.5888, Total Loss: 2380.4679\n",
      "Epoch 1/10, Batch 2180/4401, Batch Loss: 0.3961, Total Loss: 2389.5369\n",
      "Epoch 1/10, Batch 2190/4401, Batch Loss: 0.6202, Total Loss: 2396.3298\n",
      "Epoch 1/10, Batch 2200/4401, Batch Loss: 0.4861, Total Loss: 2403.8891\n",
      "Epoch 1/10, Batch 2210/4401, Batch Loss: 0.6264, Total Loss: 2410.2812\n",
      "Epoch 1/10, Batch 2220/4401, Batch Loss: 0.2900, Total Loss: 2418.0266\n",
      "Epoch 1/10, Batch 2230/4401, Batch Loss: 0.3973, Total Loss: 2424.2451\n",
      "Epoch 1/10, Batch 2240/4401, Batch Loss: 1.3219, Total Loss: 2432.5597\n",
      "Epoch 1/10, Batch 2250/4401, Batch Loss: 0.4224, Total Loss: 2439.7839\n",
      "Epoch 1/10, Batch 2260/4401, Batch Loss: 0.2674, Total Loss: 2447.7300\n",
      "Epoch 1/10, Batch 2270/4401, Batch Loss: 0.7346, Total Loss: 2455.5856\n",
      "Epoch 1/10, Batch 2280/4401, Batch Loss: 0.8148, Total Loss: 2462.8822\n",
      "Epoch 1/10, Batch 2290/4401, Batch Loss: 0.9891, Total Loss: 2471.3374\n",
      "Epoch 1/10, Batch 2300/4401, Batch Loss: 1.2947, Total Loss: 2479.2627\n",
      "Epoch 1/10, Batch 2310/4401, Batch Loss: 0.3886, Total Loss: 2486.5047\n",
      "Epoch 1/10, Batch 2320/4401, Batch Loss: 0.4856, Total Loss: 2493.0863\n",
      "Epoch 1/10, Batch 2330/4401, Batch Loss: 0.6896, Total Loss: 2500.3309\n",
      "Epoch 1/10, Batch 2340/4401, Batch Loss: 0.1673, Total Loss: 2507.3710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 2350/4401, Batch Loss: 0.3675, Total Loss: 2514.3843\n",
      "Epoch 1/10, Batch 2360/4401, Batch Loss: 0.7728, Total Loss: 2521.9056\n",
      "Epoch 1/10, Batch 2370/4401, Batch Loss: 0.8106, Total Loss: 2528.1917\n",
      "Epoch 1/10, Batch 2380/4401, Batch Loss: 0.4088, Total Loss: 2536.1418\n",
      "Epoch 1/10, Batch 2390/4401, Batch Loss: 1.7901, Total Loss: 2543.5888\n",
      "Epoch 1/10, Batch 2400/4401, Batch Loss: 0.2591, Total Loss: 2549.6839\n",
      "Epoch 1/10, Batch 2410/4401, Batch Loss: 0.8099, Total Loss: 2556.9702\n",
      "Epoch 1/10, Batch 2420/4401, Batch Loss: 0.7973, Total Loss: 2564.6374\n",
      "Epoch 1/10, Batch 2430/4401, Batch Loss: 0.3274, Total Loss: 2570.5499\n",
      "Epoch 1/10, Batch 2440/4401, Batch Loss: 0.3555, Total Loss: 2576.8521\n",
      "Epoch 1/10, Batch 2450/4401, Batch Loss: 0.8902, Total Loss: 2584.9184\n",
      "Epoch 1/10, Batch 2460/4401, Batch Loss: 0.6247, Total Loss: 2590.1251\n",
      "Epoch 1/10, Batch 2470/4401, Batch Loss: 0.6851, Total Loss: 2597.2666\n",
      "Epoch 1/10, Batch 2480/4401, Batch Loss: 0.8467, Total Loss: 2604.7436\n",
      "Epoch 1/10, Batch 2490/4401, Batch Loss: 0.3308, Total Loss: 2609.9568\n",
      "Epoch 1/10, Batch 2500/4401, Batch Loss: 0.5951, Total Loss: 2616.6291\n",
      "Epoch 1/10, Batch 2510/4401, Batch Loss: 1.3653, Total Loss: 2623.5659\n",
      "Epoch 1/10, Batch 2520/4401, Batch Loss: 0.4726, Total Loss: 2629.3150\n",
      "Epoch 1/10, Batch 2530/4401, Batch Loss: 0.4636, Total Loss: 2634.8783\n",
      "Epoch 1/10, Batch 2540/4401, Batch Loss: 0.4319, Total Loss: 2639.4609\n",
      "Epoch 1/10, Batch 2550/4401, Batch Loss: 0.6648, Total Loss: 2646.5248\n",
      "Epoch 1/10, Batch 2560/4401, Batch Loss: 0.4136, Total Loss: 2652.9131\n",
      "Epoch 1/10, Batch 2570/4401, Batch Loss: 0.5454, Total Loss: 2661.5379\n",
      "Epoch 1/10, Batch 2580/4401, Batch Loss: 0.4904, Total Loss: 2667.9163\n",
      "Epoch 1/10, Batch 2590/4401, Batch Loss: 0.6310, Total Loss: 2675.0909\n",
      "Epoch 1/10, Batch 2600/4401, Batch Loss: 0.2660, Total Loss: 2682.4466\n",
      "Epoch 1/10, Batch 2610/4401, Batch Loss: 0.9576, Total Loss: 2688.1566\n",
      "Epoch 1/10, Batch 2620/4401, Batch Loss: 0.6799, Total Loss: 2695.2720\n",
      "Epoch 1/10, Batch 2630/4401, Batch Loss: 0.3103, Total Loss: 2700.5302\n",
      "Epoch 1/10, Batch 2640/4401, Batch Loss: 1.1783, Total Loss: 2706.7322\n",
      "Epoch 1/10, Batch 2650/4401, Batch Loss: 0.1402, Total Loss: 2711.1809\n",
      "Epoch 1/10, Batch 2660/4401, Batch Loss: 0.5666, Total Loss: 2716.1465\n",
      "Epoch 1/10, Batch 2670/4401, Batch Loss: 0.0454, Total Loss: 2720.8416\n",
      "Epoch 1/10, Batch 2680/4401, Batch Loss: 0.4483, Total Loss: 2725.5175\n",
      "Epoch 1/10, Batch 2690/4401, Batch Loss: 0.1844, Total Loss: 2731.4846\n",
      "Epoch 1/10, Batch 2700/4401, Batch Loss: 0.7040, Total Loss: 2736.6874\n",
      "Epoch 1/10, Batch 2710/4401, Batch Loss: 1.0781, Total Loss: 2743.8350\n",
      "Epoch 1/10, Batch 2720/4401, Batch Loss: 0.5495, Total Loss: 2749.0110\n",
      "Epoch 1/10, Batch 2730/4401, Batch Loss: 0.3304, Total Loss: 2754.0562\n",
      "Epoch 1/10, Batch 2740/4401, Batch Loss: 0.2750, Total Loss: 2760.0066\n",
      "Epoch 1/10, Batch 2750/4401, Batch Loss: 1.1045, Total Loss: 2765.8504\n",
      "Epoch 1/10, Batch 2760/4401, Batch Loss: 0.1511, Total Loss: 2772.5608\n",
      "Epoch 1/10, Batch 2770/4401, Batch Loss: 0.5031, Total Loss: 2778.1121\n",
      "Epoch 1/10, Batch 2780/4401, Batch Loss: 0.7918, Total Loss: 2784.6843\n",
      "Epoch 1/10, Batch 2790/4401, Batch Loss: 0.3826, Total Loss: 2789.3142\n",
      "Epoch 1/10, Batch 2800/4401, Batch Loss: 0.3198, Total Loss: 2794.5081\n",
      "Epoch 1/10, Batch 2810/4401, Batch Loss: 0.5881, Total Loss: 2800.1307\n",
      "Epoch 1/10, Batch 2820/4401, Batch Loss: 0.2943, Total Loss: 2805.1055\n",
      "Epoch 1/10, Batch 2830/4401, Batch Loss: 0.1159, Total Loss: 2809.6305\n",
      "Epoch 1/10, Batch 2840/4401, Batch Loss: 0.6225, Total Loss: 2815.9550\n",
      "Epoch 1/10, Batch 2850/4401, Batch Loss: 0.9614, Total Loss: 2821.9675\n",
      "Epoch 1/10, Batch 2860/4401, Batch Loss: 0.5480, Total Loss: 2827.3034\n",
      "Epoch 1/10, Batch 2870/4401, Batch Loss: 1.0281, Total Loss: 2834.2367\n",
      "Epoch 1/10, Batch 2880/4401, Batch Loss: 0.1834, Total Loss: 2838.6147\n",
      "Epoch 1/10, Batch 2890/4401, Batch Loss: 0.9183, Total Loss: 2843.9950\n",
      "Epoch 1/10, Batch 2900/4401, Batch Loss: 0.4800, Total Loss: 2848.6402\n",
      "Epoch 1/10, Batch 2910/4401, Batch Loss: 1.2122, Total Loss: 2855.1376\n",
      "Epoch 1/10, Batch 2920/4401, Batch Loss: 0.4655, Total Loss: 2861.0333\n",
      "Epoch 1/10, Batch 2930/4401, Batch Loss: 0.3743, Total Loss: 2866.9810\n",
      "Epoch 1/10, Batch 2940/4401, Batch Loss: 0.3190, Total Loss: 2872.2290\n",
      "Epoch 1/10, Batch 2950/4401, Batch Loss: 0.5977, Total Loss: 2877.0199\n",
      "Epoch 1/10, Batch 2960/4401, Batch Loss: 0.7424, Total Loss: 2880.8781\n",
      "Epoch 1/10, Batch 2970/4401, Batch Loss: 0.1407, Total Loss: 2886.7935\n",
      "Epoch 1/10, Batch 2980/4401, Batch Loss: 0.7769, Total Loss: 2891.7186\n",
      "Epoch 1/10, Batch 2990/4401, Batch Loss: 0.1504, Total Loss: 2897.0943\n",
      "Epoch 1/10, Batch 3000/4401, Batch Loss: 0.4403, Total Loss: 2901.7884\n",
      "Epoch 1/10, Batch 3010/4401, Batch Loss: 0.4072, Total Loss: 2907.4253\n",
      "Epoch 1/10, Batch 3020/4401, Batch Loss: 0.5701, Total Loss: 2912.6063\n",
      "Epoch 1/10, Batch 3030/4401, Batch Loss: 0.3798, Total Loss: 2920.2042\n",
      "Epoch 1/10, Batch 3040/4401, Batch Loss: 0.5143, Total Loss: 2925.0505\n",
      "Epoch 1/10, Batch 3050/4401, Batch Loss: 0.6146, Total Loss: 2929.8767\n",
      "Epoch 1/10, Batch 3060/4401, Batch Loss: 0.3601, Total Loss: 2933.4109\n",
      "Epoch 1/10, Batch 3070/4401, Batch Loss: 0.2294, Total Loss: 2938.7339\n",
      "Epoch 1/10, Batch 3080/4401, Batch Loss: 0.4477, Total Loss: 2944.4821\n",
      "Epoch 1/10, Batch 3090/4401, Batch Loss: 1.0663, Total Loss: 2950.1373\n",
      "Epoch 1/10, Batch 3100/4401, Batch Loss: 0.1008, Total Loss: 2954.7821\n",
      "Epoch 1/10, Batch 3110/4401, Batch Loss: 0.6884, Total Loss: 2958.8885\n",
      "Epoch 1/10, Batch 3120/4401, Batch Loss: 0.2988, Total Loss: 2964.0837\n",
      "Epoch 1/10, Batch 3130/4401, Batch Loss: 1.1499, Total Loss: 2969.9493\n",
      "Epoch 1/10, Batch 3140/4401, Batch Loss: 0.6330, Total Loss: 2974.8641\n",
      "Epoch 1/10, Batch 3150/4401, Batch Loss: 0.7188, Total Loss: 2979.8037\n",
      "Epoch 1/10, Batch 3160/4401, Batch Loss: 0.1196, Total Loss: 2983.4469\n",
      "Epoch 1/10, Batch 3170/4401, Batch Loss: 0.6668, Total Loss: 2988.6677\n",
      "Epoch 1/10, Batch 3180/4401, Batch Loss: 0.2452, Total Loss: 2992.9249\n",
      "Epoch 1/10, Batch 3190/4401, Batch Loss: 0.2125, Total Loss: 2998.3481\n",
      "Epoch 1/10, Batch 3200/4401, Batch Loss: 0.2994, Total Loss: 3003.2719\n",
      "Epoch 1/10, Batch 3210/4401, Batch Loss: 0.7290, Total Loss: 3008.5961\n",
      "Epoch 1/10, Batch 3220/4401, Batch Loss: 0.2094, Total Loss: 3013.9459\n",
      "Epoch 1/10, Batch 3230/4401, Batch Loss: 0.1643, Total Loss: 3019.4095\n",
      "Epoch 1/10, Batch 3240/4401, Batch Loss: 0.6653, Total Loss: 3025.2752\n",
      "Epoch 1/10, Batch 3250/4401, Batch Loss: 0.5826, Total Loss: 3029.5227\n",
      "Epoch 1/10, Batch 3260/4401, Batch Loss: 0.4758, Total Loss: 3034.1305\n",
      "Epoch 1/10, Batch 3270/4401, Batch Loss: 0.1589, Total Loss: 3037.9639\n",
      "Epoch 1/10, Batch 3280/4401, Batch Loss: 0.3476, Total Loss: 3044.2229\n",
      "Epoch 1/10, Batch 3290/4401, Batch Loss: 1.0216, Total Loss: 3049.6091\n",
      "Epoch 1/10, Batch 3300/4401, Batch Loss: 0.9383, Total Loss: 3054.4024\n",
      "Epoch 1/10, Batch 3310/4401, Batch Loss: 0.3795, Total Loss: 3059.2900\n",
      "Epoch 1/10, Batch 3320/4401, Batch Loss: 0.2167, Total Loss: 3064.5892\n",
      "Epoch 1/10, Batch 3330/4401, Batch Loss: 0.4768, Total Loss: 3069.7014\n",
      "Epoch 1/10, Batch 3340/4401, Batch Loss: 0.5330, Total Loss: 3075.7223\n",
      "Epoch 1/10, Batch 3350/4401, Batch Loss: 0.6037, Total Loss: 3080.8168\n",
      "Epoch 1/10, Batch 3360/4401, Batch Loss: 0.6509, Total Loss: 3085.8640\n",
      "Epoch 1/10, Batch 3370/4401, Batch Loss: 0.3880, Total Loss: 3090.5413\n",
      "Epoch 1/10, Batch 3380/4401, Batch Loss: 0.4826, Total Loss: 3094.7582\n",
      "Epoch 1/10, Batch 3390/4401, Batch Loss: 0.8928, Total Loss: 3099.9671\n",
      "Epoch 1/10, Batch 3400/4401, Batch Loss: 0.3120, Total Loss: 3103.6534\n",
      "Epoch 1/10, Batch 3410/4401, Batch Loss: 0.3077, Total Loss: 3109.6551\n",
      "Epoch 1/10, Batch 3420/4401, Batch Loss: 0.4645, Total Loss: 3114.4310\n",
      "Epoch 1/10, Batch 3430/4401, Batch Loss: 0.2013, Total Loss: 3118.6495\n",
      "Epoch 1/10, Batch 3440/4401, Batch Loss: 0.1457, Total Loss: 3121.6074\n",
      "Epoch 1/10, Batch 3450/4401, Batch Loss: 1.1898, Total Loss: 3127.8153\n",
      "Epoch 1/10, Batch 3460/4401, Batch Loss: 0.1537, Total Loss: 3133.9416\n",
      "Epoch 1/10, Batch 3470/4401, Batch Loss: 0.6480, Total Loss: 3138.5591\n",
      "Epoch 1/10, Batch 3480/4401, Batch Loss: 0.1661, Total Loss: 3142.9777\n",
      "Epoch 1/10, Batch 3490/4401, Batch Loss: 0.4902, Total Loss: 3147.7433\n",
      "Epoch 1/10, Batch 3500/4401, Batch Loss: 0.4789, Total Loss: 3151.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 3510/4401, Batch Loss: 0.2160, Total Loss: 3155.2697\n",
      "Epoch 1/10, Batch 3520/4401, Batch Loss: 0.6482, Total Loss: 3161.6730\n",
      "Epoch 1/10, Batch 3530/4401, Batch Loss: 0.5626, Total Loss: 3167.2420\n",
      "Epoch 1/10, Batch 3540/4401, Batch Loss: 0.3590, Total Loss: 3172.2534\n",
      "Epoch 1/10, Batch 3550/4401, Batch Loss: 0.4169, Total Loss: 3176.6699\n",
      "Epoch 1/10, Batch 3560/4401, Batch Loss: 0.6284, Total Loss: 3183.0706\n",
      "Epoch 1/10, Batch 3570/4401, Batch Loss: 0.7763, Total Loss: 3188.5537\n",
      "Epoch 1/10, Batch 3580/4401, Batch Loss: 0.3783, Total Loss: 3193.3408\n",
      "Epoch 1/10, Batch 3590/4401, Batch Loss: 0.6844, Total Loss: 3198.4681\n",
      "Epoch 1/10, Batch 3600/4401, Batch Loss: 0.2418, Total Loss: 3203.1715\n",
      "Epoch 1/10, Batch 3610/4401, Batch Loss: 0.7544, Total Loss: 3207.8128\n",
      "Epoch 1/10, Batch 3620/4401, Batch Loss: 0.2714, Total Loss: 3212.8123\n",
      "Epoch 1/10, Batch 3630/4401, Batch Loss: 0.3796, Total Loss: 3217.0974\n",
      "Epoch 1/10, Batch 3640/4401, Batch Loss: 1.1580, Total Loss: 3223.0698\n",
      "Epoch 1/10, Batch 3650/4401, Batch Loss: 0.8421, Total Loss: 3227.4140\n",
      "Epoch 1/10, Batch 3660/4401, Batch Loss: 0.7781, Total Loss: 3233.5861\n",
      "Epoch 1/10, Batch 3670/4401, Batch Loss: 1.0384, Total Loss: 3239.5807\n",
      "Epoch 1/10, Batch 3680/4401, Batch Loss: 0.5544, Total Loss: 3244.5076\n",
      "Epoch 1/10, Batch 3690/4401, Batch Loss: 0.3842, Total Loss: 3249.3259\n",
      "Epoch 1/10, Batch 3700/4401, Batch Loss: 0.6385, Total Loss: 3253.9673\n",
      "Epoch 1/10, Batch 3710/4401, Batch Loss: 0.5587, Total Loss: 3259.3913\n",
      "Epoch 1/10, Batch 3720/4401, Batch Loss: 0.2021, Total Loss: 3264.6581\n",
      "Epoch 1/10, Batch 3730/4401, Batch Loss: 0.3997, Total Loss: 3269.7999\n",
      "Epoch 1/10, Batch 3740/4401, Batch Loss: 0.2594, Total Loss: 3273.0677\n",
      "Epoch 1/10, Batch 3750/4401, Batch Loss: 0.3548, Total Loss: 3277.5933\n",
      "Epoch 1/10, Batch 3760/4401, Batch Loss: 0.0807, Total Loss: 3282.8384\n",
      "Epoch 1/10, Batch 3770/4401, Batch Loss: 0.4357, Total Loss: 3287.7737\n",
      "Epoch 1/10, Batch 3780/4401, Batch Loss: 0.8521, Total Loss: 3294.3239\n",
      "Epoch 1/10, Batch 3790/4401, Batch Loss: 0.6773, Total Loss: 3298.7233\n",
      "Epoch 1/10, Batch 3800/4401, Batch Loss: 1.0148, Total Loss: 3304.4661\n",
      "Epoch 1/10, Batch 3810/4401, Batch Loss: 0.3790, Total Loss: 3308.8247\n",
      "Epoch 1/10, Batch 3820/4401, Batch Loss: 0.2803, Total Loss: 3314.2398\n",
      "Epoch 1/10, Batch 3830/4401, Batch Loss: 0.7327, Total Loss: 3318.5858\n",
      "Epoch 1/10, Batch 3840/4401, Batch Loss: 0.6142, Total Loss: 3324.3014\n",
      "Epoch 1/10, Batch 3850/4401, Batch Loss: 0.5316, Total Loss: 3328.6178\n",
      "Epoch 1/10, Batch 3860/4401, Batch Loss: 1.0424, Total Loss: 3334.1184\n",
      "Epoch 1/10, Batch 3870/4401, Batch Loss: 0.2623, Total Loss: 3338.2471\n",
      "Epoch 1/10, Batch 3880/4401, Batch Loss: 0.3166, Total Loss: 3342.4010\n",
      "Epoch 1/10, Batch 3890/4401, Batch Loss: 0.9791, Total Loss: 3348.7513\n",
      "Epoch 1/10, Batch 3900/4401, Batch Loss: 0.2431, Total Loss: 3353.8329\n",
      "Epoch 1/10, Batch 3910/4401, Batch Loss: 0.3085, Total Loss: 3358.0486\n",
      "Epoch 1/10, Batch 3920/4401, Batch Loss: 0.1909, Total Loss: 3363.8817\n",
      "Epoch 1/10, Batch 3930/4401, Batch Loss: 0.6445, Total Loss: 3369.9906\n",
      "Epoch 1/10, Batch 3940/4401, Batch Loss: 0.5478, Total Loss: 3374.0510\n",
      "Epoch 1/10, Batch 3950/4401, Batch Loss: 0.2970, Total Loss: 3378.9570\n",
      "Epoch 1/10, Batch 3960/4401, Batch Loss: 0.4135, Total Loss: 3385.1234\n",
      "Epoch 1/10, Batch 3970/4401, Batch Loss: 0.2352, Total Loss: 3390.4120\n",
      "Epoch 1/10, Batch 3980/4401, Batch Loss: 0.4231, Total Loss: 3395.2452\n",
      "Epoch 1/10, Batch 3990/4401, Batch Loss: 0.4674, Total Loss: 3400.1583\n",
      "Epoch 1/10, Batch 4000/4401, Batch Loss: 0.6817, Total Loss: 3405.3606\n",
      "Epoch 1/10, Batch 4010/4401, Batch Loss: 0.9209, Total Loss: 3410.7314\n",
      "Epoch 1/10, Batch 4020/4401, Batch Loss: 0.2265, Total Loss: 3417.5073\n",
      "Epoch 1/10, Batch 4030/4401, Batch Loss: 1.2392, Total Loss: 3421.8270\n",
      "Epoch 1/10, Batch 4040/4401, Batch Loss: 0.4719, Total Loss: 3427.8825\n",
      "Epoch 1/10, Batch 4050/4401, Batch Loss: 0.4545, Total Loss: 3432.1320\n",
      "Epoch 1/10, Batch 4060/4401, Batch Loss: 0.6353, Total Loss: 3436.5185\n",
      "Epoch 1/10, Batch 4070/4401, Batch Loss: 0.0865, Total Loss: 3440.2199\n",
      "Epoch 1/10, Batch 4080/4401, Batch Loss: 0.7278, Total Loss: 3443.2279\n",
      "Epoch 1/10, Batch 4090/4401, Batch Loss: 0.2520, Total Loss: 3448.6311\n",
      "Epoch 1/10, Batch 4100/4401, Batch Loss: 0.2957, Total Loss: 3453.4512\n",
      "Epoch 1/10, Batch 4110/4401, Batch Loss: 0.9649, Total Loss: 3458.5914\n",
      "Epoch 1/10, Batch 4120/4401, Batch Loss: 0.7541, Total Loss: 3463.5565\n",
      "Epoch 1/10, Batch 4130/4401, Batch Loss: 0.3232, Total Loss: 3468.2528\n",
      "Epoch 1/10, Batch 4140/4401, Batch Loss: 0.2747, Total Loss: 3472.2802\n",
      "Epoch 1/10, Batch 4150/4401, Batch Loss: 0.4430, Total Loss: 3477.4007\n",
      "Epoch 1/10, Batch 4160/4401, Batch Loss: 0.5222, Total Loss: 3480.8842\n",
      "Epoch 1/10, Batch 4170/4401, Batch Loss: 0.5147, Total Loss: 3486.0946\n",
      "Epoch 1/10, Batch 4180/4401, Batch Loss: 0.4210, Total Loss: 3489.9186\n",
      "Epoch 1/10, Batch 4190/4401, Batch Loss: 0.5035, Total Loss: 3494.9968\n",
      "Epoch 1/10, Batch 4200/4401, Batch Loss: 0.8972, Total Loss: 3499.6574\n",
      "Epoch 1/10, Batch 4210/4401, Batch Loss: 1.4111, Total Loss: 3505.6127\n",
      "Epoch 1/10, Batch 4220/4401, Batch Loss: 0.2914, Total Loss: 3511.8499\n",
      "Epoch 1/10, Batch 4230/4401, Batch Loss: 0.2250, Total Loss: 3514.9636\n",
      "Epoch 1/10, Batch 4240/4401, Batch Loss: 0.6390, Total Loss: 3519.5467\n",
      "Epoch 1/10, Batch 4250/4401, Batch Loss: 1.1207, Total Loss: 3524.4604\n",
      "Epoch 1/10, Batch 4260/4401, Batch Loss: 0.1671, Total Loss: 3529.1714\n",
      "Epoch 1/10, Batch 4270/4401, Batch Loss: 0.2605, Total Loss: 3534.5548\n",
      "Epoch 1/10, Batch 4280/4401, Batch Loss: 0.1682, Total Loss: 3537.7680\n",
      "Epoch 1/10, Batch 4290/4401, Batch Loss: 0.5954, Total Loss: 3541.8332\n",
      "Epoch 1/10, Batch 4300/4401, Batch Loss: 0.5792, Total Loss: 3547.2637\n",
      "Epoch 1/10, Batch 4310/4401, Batch Loss: 0.4043, Total Loss: 3552.0619\n",
      "Epoch 1/10, Batch 4320/4401, Batch Loss: 0.1679, Total Loss: 3556.6978\n",
      "Epoch 1/10, Batch 4330/4401, Batch Loss: 0.4200, Total Loss: 3562.4750\n",
      "Epoch 1/10, Batch 4340/4401, Batch Loss: 0.3762, Total Loss: 3567.0382\n",
      "Epoch 1/10, Batch 4350/4401, Batch Loss: 0.4418, Total Loss: 3572.3236\n",
      "Epoch 1/10, Batch 4360/4401, Batch Loss: 0.3107, Total Loss: 3576.3588\n",
      "Epoch 1/10, Batch 4370/4401, Batch Loss: 0.2947, Total Loss: 3581.6805\n",
      "Epoch 1/10, Batch 4380/4401, Batch Loss: 0.3217, Total Loss: 3585.8315\n",
      "Epoch 1/10, Batch 4390/4401, Batch Loss: 0.0528, Total Loss: 3589.0877\n",
      "Epoch 1/10, Batch 4400/4401, Batch Loss: 0.0621, Total Loss: 3594.3589\n",
      "Epoch 1/10, Batch 4401/4401, Batch Loss: 0.3143, Total Loss: 3594.6732\n",
      "Epoch 1/10 completed. Total Loss: 3594.6732\n",
      "\n",
      "Epoch 2/10 running...\n",
      "cuda:0\n",
      "Epoch 2/10, Batch 10/4401, Batch Loss: 0.1165, Total Loss: 3.8200\n",
      "Epoch 2/10, Batch 20/4401, Batch Loss: 0.4723, Total Loss: 7.5722\n",
      "Epoch 2/10, Batch 30/4401, Batch Loss: 0.2252, Total Loss: 11.2044\n",
      "Epoch 2/10, Batch 40/4401, Batch Loss: 0.5088, Total Loss: 15.8262\n",
      "Epoch 2/10, Batch 50/4401, Batch Loss: 0.3368, Total Loss: 21.1432\n",
      "Epoch 2/10, Batch 60/4401, Batch Loss: 0.5447, Total Loss: 25.8872\n",
      "Epoch 2/10, Batch 70/4401, Batch Loss: 0.2713, Total Loss: 30.3796\n",
      "Epoch 2/10, Batch 80/4401, Batch Loss: 0.0585, Total Loss: 33.7501\n",
      "Epoch 2/10, Batch 90/4401, Batch Loss: 0.2234, Total Loss: 37.9159\n",
      "Epoch 2/10, Batch 100/4401, Batch Loss: 0.6017, Total Loss: 43.9871\n",
      "Epoch 2/10, Batch 110/4401, Batch Loss: 0.1565, Total Loss: 48.0151\n",
      "Epoch 2/10, Batch 120/4401, Batch Loss: 0.3695, Total Loss: 52.0153\n",
      "Epoch 2/10, Batch 130/4401, Batch Loss: 1.1707, Total Loss: 56.7278\n",
      "Epoch 2/10, Batch 140/4401, Batch Loss: 0.5721, Total Loss: 61.0421\n",
      "Epoch 2/10, Batch 150/4401, Batch Loss: 0.9019, Total Loss: 64.9776\n",
      "Epoch 2/10, Batch 160/4401, Batch Loss: 0.1759, Total Loss: 68.9882\n",
      "Epoch 2/10, Batch 170/4401, Batch Loss: 0.2962, Total Loss: 72.7639\n",
      "Epoch 2/10, Batch 180/4401, Batch Loss: 0.6617, Total Loss: 76.8653\n",
      "Epoch 2/10, Batch 190/4401, Batch Loss: 0.2750, Total Loss: 79.9980\n",
      "Epoch 2/10, Batch 200/4401, Batch Loss: 0.9584, Total Loss: 83.5226\n",
      "Epoch 2/10, Batch 210/4401, Batch Loss: 0.3374, Total Loss: 87.9752\n",
      "Epoch 2/10, Batch 220/4401, Batch Loss: 0.1990, Total Loss: 91.9089\n",
      "Epoch 2/10, Batch 230/4401, Batch Loss: 0.2670, Total Loss: 96.1967\n",
      "Epoch 2/10, Batch 240/4401, Batch Loss: 0.4629, Total Loss: 102.2426\n",
      "Epoch 2/10, Batch 250/4401, Batch Loss: 0.2459, Total Loss: 108.1139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 260/4401, Batch Loss: 0.2477, Total Loss: 112.1588\n",
      "Epoch 2/10, Batch 270/4401, Batch Loss: 0.0643, Total Loss: 116.2274\n",
      "Epoch 2/10, Batch 280/4401, Batch Loss: 0.4034, Total Loss: 120.5972\n",
      "Epoch 2/10, Batch 290/4401, Batch Loss: 0.1887, Total Loss: 124.9541\n",
      "Epoch 2/10, Batch 300/4401, Batch Loss: 0.2368, Total Loss: 127.8217\n",
      "Epoch 2/10, Batch 310/4401, Batch Loss: 1.0694, Total Loss: 133.3650\n",
      "Epoch 2/10, Batch 320/4401, Batch Loss: 0.3978, Total Loss: 137.0220\n",
      "Epoch 2/10, Batch 330/4401, Batch Loss: 0.7110, Total Loss: 140.5694\n",
      "Epoch 2/10, Batch 340/4401, Batch Loss: 0.5041, Total Loss: 144.1177\n",
      "Epoch 2/10, Batch 350/4401, Batch Loss: 0.7220, Total Loss: 150.3328\n",
      "Epoch 2/10, Batch 360/4401, Batch Loss: 0.2578, Total Loss: 154.4793\n",
      "Epoch 2/10, Batch 370/4401, Batch Loss: 0.6086, Total Loss: 159.2111\n",
      "Epoch 2/10, Batch 380/4401, Batch Loss: 0.2452, Total Loss: 163.6078\n",
      "Epoch 2/10, Batch 390/4401, Batch Loss: 0.2513, Total Loss: 168.5643\n",
      "Epoch 2/10, Batch 400/4401, Batch Loss: 0.5693, Total Loss: 172.8320\n",
      "Epoch 2/10, Batch 410/4401, Batch Loss: 0.1159, Total Loss: 177.7595\n",
      "Epoch 2/10, Batch 420/4401, Batch Loss: 1.0528, Total Loss: 181.6433\n",
      "Epoch 2/10, Batch 430/4401, Batch Loss: 0.5933, Total Loss: 186.7332\n",
      "Epoch 2/10, Batch 440/4401, Batch Loss: 0.4766, Total Loss: 190.7004\n",
      "Epoch 2/10, Batch 450/4401, Batch Loss: 0.7396, Total Loss: 194.6003\n",
      "Epoch 2/10, Batch 460/4401, Batch Loss: 0.5441, Total Loss: 198.4751\n",
      "Epoch 2/10, Batch 470/4401, Batch Loss: 0.3365, Total Loss: 202.1694\n",
      "Epoch 2/10, Batch 480/4401, Batch Loss: 0.2343, Total Loss: 206.8689\n",
      "Epoch 2/10, Batch 490/4401, Batch Loss: 0.5208, Total Loss: 211.3101\n",
      "Epoch 2/10, Batch 500/4401, Batch Loss: 0.9776, Total Loss: 215.3726\n",
      "Epoch 2/10, Batch 510/4401, Batch Loss: 0.4145, Total Loss: 221.9430\n",
      "Epoch 2/10, Batch 520/4401, Batch Loss: 0.2424, Total Loss: 226.0050\n",
      "Epoch 2/10, Batch 530/4401, Batch Loss: 0.6530, Total Loss: 231.7284\n",
      "Epoch 2/10, Batch 540/4401, Batch Loss: 0.6013, Total Loss: 234.6099\n",
      "Epoch 2/10, Batch 550/4401, Batch Loss: 0.0636, Total Loss: 237.5886\n",
      "Epoch 2/10, Batch 560/4401, Batch Loss: 0.1639, Total Loss: 242.7065\n",
      "Epoch 2/10, Batch 570/4401, Batch Loss: 0.3925, Total Loss: 246.5417\n",
      "Epoch 2/10, Batch 580/4401, Batch Loss: 0.1108, Total Loss: 250.7984\n",
      "Epoch 2/10, Batch 590/4401, Batch Loss: 0.4159, Total Loss: 254.0217\n",
      "Epoch 2/10, Batch 600/4401, Batch Loss: 0.6620, Total Loss: 258.1359\n",
      "Epoch 2/10, Batch 610/4401, Batch Loss: 0.6290, Total Loss: 262.7943\n",
      "Epoch 2/10, Batch 620/4401, Batch Loss: 0.1062, Total Loss: 266.6136\n",
      "Epoch 2/10, Batch 630/4401, Batch Loss: 0.2852, Total Loss: 270.8278\n",
      "Epoch 2/10, Batch 640/4401, Batch Loss: 0.8220, Total Loss: 275.9311\n",
      "Epoch 2/10, Batch 650/4401, Batch Loss: 0.1638, Total Loss: 280.8950\n",
      "Epoch 2/10, Batch 660/4401, Batch Loss: 0.4486, Total Loss: 285.5100\n",
      "Epoch 2/10, Batch 670/4401, Batch Loss: 0.8839, Total Loss: 289.8546\n",
      "Epoch 2/10, Batch 680/4401, Batch Loss: 0.6763, Total Loss: 294.0757\n",
      "Epoch 2/10, Batch 690/4401, Batch Loss: 0.7731, Total Loss: 298.3407\n",
      "Epoch 2/10, Batch 700/4401, Batch Loss: 0.6581, Total Loss: 302.5804\n",
      "Epoch 2/10, Batch 710/4401, Batch Loss: 0.2233, Total Loss: 307.0771\n",
      "Epoch 2/10, Batch 720/4401, Batch Loss: 0.4695, Total Loss: 311.6264\n",
      "Epoch 2/10, Batch 730/4401, Batch Loss: 0.7279, Total Loss: 316.8863\n",
      "Epoch 2/10, Batch 740/4401, Batch Loss: 0.4633, Total Loss: 320.3082\n",
      "Epoch 2/10, Batch 750/4401, Batch Loss: 0.1990, Total Loss: 324.3633\n",
      "Epoch 2/10, Batch 760/4401, Batch Loss: 0.6347, Total Loss: 328.3635\n",
      "Epoch 2/10, Batch 770/4401, Batch Loss: 0.2420, Total Loss: 330.9925\n",
      "Epoch 2/10, Batch 780/4401, Batch Loss: 0.7907, Total Loss: 337.4688\n",
      "Epoch 2/10, Batch 790/4401, Batch Loss: 0.1469, Total Loss: 340.5947\n",
      "Epoch 2/10, Batch 800/4401, Batch Loss: 0.6663, Total Loss: 344.8100\n",
      "Epoch 2/10, Batch 810/4401, Batch Loss: 0.2308, Total Loss: 347.5028\n",
      "Epoch 2/10, Batch 820/4401, Batch Loss: 0.3081, Total Loss: 351.7634\n",
      "Epoch 2/10, Batch 830/4401, Batch Loss: 0.2247, Total Loss: 355.3565\n",
      "Epoch 2/10, Batch 840/4401, Batch Loss: 0.3388, Total Loss: 359.1088\n",
      "Epoch 2/10, Batch 850/4401, Batch Loss: 0.1890, Total Loss: 362.3462\n",
      "Epoch 2/10, Batch 860/4401, Batch Loss: 0.7969, Total Loss: 366.9055\n",
      "Epoch 2/10, Batch 870/4401, Batch Loss: 0.1602, Total Loss: 372.3608\n",
      "Epoch 2/10, Batch 880/4401, Batch Loss: 0.2370, Total Loss: 378.0541\n",
      "Epoch 2/10, Batch 890/4401, Batch Loss: 0.3467, Total Loss: 383.1910\n",
      "Epoch 2/10, Batch 900/4401, Batch Loss: 0.5289, Total Loss: 388.2146\n",
      "Epoch 2/10, Batch 910/4401, Batch Loss: 0.4244, Total Loss: 393.4881\n",
      "Epoch 2/10, Batch 920/4401, Batch Loss: 0.6590, Total Loss: 397.8334\n",
      "Epoch 2/10, Batch 930/4401, Batch Loss: 0.8919, Total Loss: 401.9664\n",
      "Epoch 2/10, Batch 940/4401, Batch Loss: 0.2148, Total Loss: 405.4693\n",
      "Epoch 2/10, Batch 950/4401, Batch Loss: 0.4362, Total Loss: 408.9063\n",
      "Epoch 2/10, Batch 960/4401, Batch Loss: 0.1596, Total Loss: 412.4914\n",
      "Epoch 2/10, Batch 970/4401, Batch Loss: 0.3116, Total Loss: 417.0552\n",
      "Epoch 2/10, Batch 980/4401, Batch Loss: 0.5238, Total Loss: 421.9581\n",
      "Epoch 2/10, Batch 990/4401, Batch Loss: 0.5859, Total Loss: 425.6355\n",
      "Epoch 2/10, Batch 1000/4401, Batch Loss: 0.8666, Total Loss: 430.4632\n",
      "Epoch 2/10, Batch 1010/4401, Batch Loss: 0.6120, Total Loss: 434.1161\n",
      "Epoch 2/10, Batch 1020/4401, Batch Loss: 0.5416, Total Loss: 437.2961\n",
      "Epoch 2/10, Batch 1030/4401, Batch Loss: 0.4899, Total Loss: 441.6096\n",
      "Epoch 2/10, Batch 1040/4401, Batch Loss: 0.1288, Total Loss: 446.3303\n",
      "Epoch 2/10, Batch 1050/4401, Batch Loss: 0.2266, Total Loss: 450.8530\n",
      "Epoch 2/10, Batch 1060/4401, Batch Loss: 0.4086, Total Loss: 454.8637\n",
      "Epoch 2/10, Batch 1070/4401, Batch Loss: 0.2665, Total Loss: 459.4154\n",
      "Epoch 2/10, Batch 1080/4401, Batch Loss: 0.1241, Total Loss: 463.2874\n",
      "Epoch 2/10, Batch 1090/4401, Batch Loss: 0.2460, Total Loss: 466.4034\n",
      "Epoch 2/10, Batch 1100/4401, Batch Loss: 0.8387, Total Loss: 472.6690\n",
      "Epoch 2/10, Batch 1110/4401, Batch Loss: 0.1961, Total Loss: 477.5480\n",
      "Epoch 2/10, Batch 1120/4401, Batch Loss: 0.6171, Total Loss: 482.0380\n",
      "Epoch 2/10, Batch 1130/4401, Batch Loss: 0.0726, Total Loss: 485.6726\n",
      "Epoch 2/10, Batch 1140/4401, Batch Loss: 0.3256, Total Loss: 489.5767\n",
      "Epoch 2/10, Batch 1150/4401, Batch Loss: 0.6487, Total Loss: 495.6149\n",
      "Epoch 2/10, Batch 1160/4401, Batch Loss: 0.3355, Total Loss: 500.7442\n",
      "Epoch 2/10, Batch 1170/4401, Batch Loss: 0.4633, Total Loss: 505.9091\n",
      "Epoch 2/10, Batch 1180/4401, Batch Loss: 0.3841, Total Loss: 511.0890\n",
      "Epoch 2/10, Batch 1190/4401, Batch Loss: 0.3000, Total Loss: 515.6614\n",
      "Epoch 2/10, Batch 1200/4401, Batch Loss: 0.4229, Total Loss: 519.2090\n",
      "Epoch 2/10, Batch 1210/4401, Batch Loss: 0.1559, Total Loss: 523.0969\n",
      "Epoch 2/10, Batch 1220/4401, Batch Loss: 0.4713, Total Loss: 528.0254\n",
      "Epoch 2/10, Batch 1230/4401, Batch Loss: 0.2250, Total Loss: 532.0639\n",
      "Epoch 2/10, Batch 1240/4401, Batch Loss: 0.4565, Total Loss: 536.0361\n",
      "Epoch 2/10, Batch 1250/4401, Batch Loss: 0.7706, Total Loss: 539.9084\n",
      "Epoch 2/10, Batch 1260/4401, Batch Loss: 0.4877, Total Loss: 545.0953\n",
      "Epoch 2/10, Batch 1270/4401, Batch Loss: 0.2615, Total Loss: 549.0289\n",
      "Epoch 2/10, Batch 1280/4401, Batch Loss: 0.1064, Total Loss: 552.8239\n",
      "Epoch 2/10, Batch 1290/4401, Batch Loss: 0.8565, Total Loss: 557.0571\n",
      "Epoch 2/10, Batch 1300/4401, Batch Loss: 0.6515, Total Loss: 563.5311\n",
      "Epoch 2/10, Batch 1310/4401, Batch Loss: 0.3045, Total Loss: 566.7867\n",
      "Epoch 2/10, Batch 1320/4401, Batch Loss: 0.5639, Total Loss: 569.5297\n",
      "Epoch 2/10, Batch 1330/4401, Batch Loss: 0.6953, Total Loss: 574.5694\n",
      "Epoch 2/10, Batch 1340/4401, Batch Loss: 0.9808, Total Loss: 579.4001\n",
      "Epoch 2/10, Batch 1350/4401, Batch Loss: 0.2663, Total Loss: 583.8263\n",
      "Epoch 2/10, Batch 1360/4401, Batch Loss: 0.5842, Total Loss: 588.0633\n",
      "Epoch 2/10, Batch 1370/4401, Batch Loss: 0.7644, Total Loss: 592.2959\n",
      "Epoch 2/10, Batch 1380/4401, Batch Loss: 0.3586, Total Loss: 597.0571\n",
      "Epoch 2/10, Batch 1390/4401, Batch Loss: 0.3496, Total Loss: 601.0852\n",
      "Epoch 2/10, Batch 1400/4401, Batch Loss: 0.3217, Total Loss: 605.1755\n",
      "Epoch 2/10, Batch 1410/4401, Batch Loss: 0.3434, Total Loss: 609.1299\n",
      "Epoch 2/10, Batch 1420/4401, Batch Loss: 0.1870, Total Loss: 612.9818\n",
      "Epoch 2/10, Batch 1430/4401, Batch Loss: 0.4318, Total Loss: 617.5219\n",
      "Epoch 2/10, Batch 1440/4401, Batch Loss: 0.1864, Total Loss: 621.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1450/4401, Batch Loss: 0.9032, Total Loss: 626.5300\n",
      "Epoch 2/10, Batch 1460/4401, Batch Loss: 0.3509, Total Loss: 631.5623\n",
      "Epoch 2/10, Batch 1470/4401, Batch Loss: 0.6946, Total Loss: 634.9610\n",
      "Epoch 2/10, Batch 1480/4401, Batch Loss: 0.9070, Total Loss: 638.8130\n",
      "Epoch 2/10, Batch 1490/4401, Batch Loss: 0.1829, Total Loss: 643.8338\n",
      "Epoch 2/10, Batch 1500/4401, Batch Loss: 0.4502, Total Loss: 647.1138\n",
      "Epoch 2/10, Batch 1510/4401, Batch Loss: 0.2862, Total Loss: 650.4448\n",
      "Epoch 2/10, Batch 1520/4401, Batch Loss: 0.3702, Total Loss: 654.9229\n",
      "Epoch 2/10, Batch 1530/4401, Batch Loss: 0.3735, Total Loss: 659.2315\n",
      "Epoch 2/10, Batch 1540/4401, Batch Loss: 0.5545, Total Loss: 663.4789\n",
      "Epoch 2/10, Batch 1550/4401, Batch Loss: 0.4150, Total Loss: 668.0257\n",
      "Epoch 2/10, Batch 1560/4401, Batch Loss: 0.1179, Total Loss: 671.2545\n",
      "Epoch 2/10, Batch 1570/4401, Batch Loss: 0.6992, Total Loss: 675.5978\n",
      "Epoch 2/10, Batch 1580/4401, Batch Loss: 0.0456, Total Loss: 680.4532\n",
      "Epoch 2/10, Batch 1590/4401, Batch Loss: 0.7219, Total Loss: 684.4908\n",
      "Epoch 2/10, Batch 1600/4401, Batch Loss: 0.7141, Total Loss: 689.9253\n",
      "Epoch 2/10, Batch 1610/4401, Batch Loss: 0.2889, Total Loss: 693.5451\n",
      "Epoch 2/10, Batch 1620/4401, Batch Loss: 0.5105, Total Loss: 696.4066\n",
      "Epoch 2/10, Batch 1630/4401, Batch Loss: 0.2964, Total Loss: 700.0484\n",
      "Epoch 2/10, Batch 1640/4401, Batch Loss: 0.3935, Total Loss: 703.6160\n",
      "Epoch 2/10, Batch 1650/4401, Batch Loss: 1.1506, Total Loss: 709.4078\n",
      "Epoch 2/10, Batch 1660/4401, Batch Loss: 0.4593, Total Loss: 712.9443\n",
      "Epoch 2/10, Batch 1670/4401, Batch Loss: 0.4614, Total Loss: 716.7516\n",
      "Epoch 2/10, Batch 1680/4401, Batch Loss: 0.3518, Total Loss: 720.3952\n",
      "Epoch 2/10, Batch 1690/4401, Batch Loss: 0.2442, Total Loss: 724.5409\n",
      "Epoch 2/10, Batch 1700/4401, Batch Loss: 0.5064, Total Loss: 728.0329\n",
      "Epoch 2/10, Batch 1710/4401, Batch Loss: 0.6722, Total Loss: 732.9220\n",
      "Epoch 2/10, Batch 1720/4401, Batch Loss: 0.3848, Total Loss: 735.9760\n",
      "Epoch 2/10, Batch 1730/4401, Batch Loss: 0.5194, Total Loss: 739.0796\n",
      "Epoch 2/10, Batch 1740/4401, Batch Loss: 0.0600, Total Loss: 743.7076\n",
      "Epoch 2/10, Batch 1750/4401, Batch Loss: 0.7729, Total Loss: 749.6428\n",
      "Epoch 2/10, Batch 1760/4401, Batch Loss: 0.2632, Total Loss: 754.2928\n",
      "Epoch 2/10, Batch 1770/4401, Batch Loss: 0.1973, Total Loss: 757.1336\n",
      "Epoch 2/10, Batch 1780/4401, Batch Loss: 0.7214, Total Loss: 761.3290\n",
      "Epoch 2/10, Batch 1790/4401, Batch Loss: 0.1653, Total Loss: 764.1684\n",
      "Epoch 2/10, Batch 1800/4401, Batch Loss: 0.3446, Total Loss: 768.4032\n",
      "Epoch 2/10, Batch 1810/4401, Batch Loss: 0.7818, Total Loss: 772.5361\n",
      "Epoch 2/10, Batch 1820/4401, Batch Loss: 0.1957, Total Loss: 778.8880\n",
      "Epoch 2/10, Batch 1830/4401, Batch Loss: 0.1711, Total Loss: 783.3922\n",
      "Epoch 2/10, Batch 1840/4401, Batch Loss: 0.3407, Total Loss: 786.9823\n",
      "Epoch 2/10, Batch 1850/4401, Batch Loss: 0.3486, Total Loss: 792.2994\n",
      "Epoch 2/10, Batch 1860/4401, Batch Loss: 0.4084, Total Loss: 796.3875\n",
      "Epoch 2/10, Batch 1870/4401, Batch Loss: 0.2664, Total Loss: 800.1789\n",
      "Epoch 2/10, Batch 1880/4401, Batch Loss: 0.1547, Total Loss: 804.2589\n",
      "Epoch 2/10, Batch 1890/4401, Batch Loss: 0.1769, Total Loss: 809.4705\n",
      "Epoch 2/10, Batch 1900/4401, Batch Loss: 0.3428, Total Loss: 813.7649\n",
      "Epoch 2/10, Batch 1910/4401, Batch Loss: 0.2274, Total Loss: 818.5382\n",
      "Epoch 2/10, Batch 1920/4401, Batch Loss: 0.2801, Total Loss: 822.4324\n",
      "Epoch 2/10, Batch 1930/4401, Batch Loss: 0.5680, Total Loss: 825.8895\n",
      "Epoch 2/10, Batch 1940/4401, Batch Loss: 0.7300, Total Loss: 830.0209\n",
      "Epoch 2/10, Batch 1950/4401, Batch Loss: 0.6796, Total Loss: 833.4778\n",
      "Epoch 2/10, Batch 1960/4401, Batch Loss: 0.5372, Total Loss: 836.8699\n",
      "Epoch 2/10, Batch 1970/4401, Batch Loss: 0.7262, Total Loss: 840.7836\n",
      "Epoch 2/10, Batch 1980/4401, Batch Loss: 0.3221, Total Loss: 845.7625\n",
      "Epoch 2/10, Batch 1990/4401, Batch Loss: 0.3173, Total Loss: 849.9104\n",
      "Epoch 2/10, Batch 2000/4401, Batch Loss: 0.8061, Total Loss: 854.8242\n",
      "Epoch 2/10, Batch 2010/4401, Batch Loss: 0.1844, Total Loss: 858.8286\n",
      "Epoch 2/10, Batch 2020/4401, Batch Loss: 0.8763, Total Loss: 863.5010\n",
      "Epoch 2/10, Batch 2030/4401, Batch Loss: 0.4003, Total Loss: 867.8600\n",
      "Epoch 2/10, Batch 2040/4401, Batch Loss: 0.2961, Total Loss: 871.5191\n",
      "Epoch 2/10, Batch 2050/4401, Batch Loss: 0.3831, Total Loss: 877.1627\n",
      "Epoch 2/10, Batch 2060/4401, Batch Loss: 0.2864, Total Loss: 881.2267\n",
      "Epoch 2/10, Batch 2070/4401, Batch Loss: 0.2118, Total Loss: 884.3791\n",
      "Epoch 2/10, Batch 2080/4401, Batch Loss: 0.2448, Total Loss: 888.4142\n",
      "Epoch 2/10, Batch 2090/4401, Batch Loss: 0.9981, Total Loss: 892.9633\n",
      "Epoch 2/10, Batch 2100/4401, Batch Loss: 1.0893, Total Loss: 898.9114\n",
      "Epoch 2/10, Batch 2110/4401, Batch Loss: 0.4925, Total Loss: 902.9099\n",
      "Epoch 2/10, Batch 2120/4401, Batch Loss: 0.4912, Total Loss: 906.9661\n",
      "Epoch 2/10, Batch 2130/4401, Batch Loss: 0.4158, Total Loss: 911.5506\n",
      "Epoch 2/10, Batch 2140/4401, Batch Loss: 0.3564, Total Loss: 914.9775\n",
      "Epoch 2/10, Batch 2150/4401, Batch Loss: 0.2699, Total Loss: 919.3156\n",
      "Epoch 2/10, Batch 2160/4401, Batch Loss: 0.4957, Total Loss: 924.5787\n",
      "Epoch 2/10, Batch 2170/4401, Batch Loss: 0.1376, Total Loss: 928.7048\n",
      "Epoch 2/10, Batch 2180/4401, Batch Loss: 0.1670, Total Loss: 932.1524\n",
      "Epoch 2/10, Batch 2190/4401, Batch Loss: 0.5105, Total Loss: 936.6281\n",
      "Epoch 2/10, Batch 2200/4401, Batch Loss: 0.0113, Total Loss: 940.9160\n",
      "Epoch 2/10, Batch 2210/4401, Batch Loss: 0.0244, Total Loss: 945.5714\n",
      "Epoch 2/10, Batch 2220/4401, Batch Loss: 0.5225, Total Loss: 951.1621\n",
      "Epoch 2/10, Batch 2230/4401, Batch Loss: 0.6108, Total Loss: 957.9895\n",
      "Epoch 2/10, Batch 2240/4401, Batch Loss: 0.1487, Total Loss: 962.8940\n",
      "Epoch 2/10, Batch 2250/4401, Batch Loss: 0.2540, Total Loss: 967.2303\n",
      "Epoch 2/10, Batch 2260/4401, Batch Loss: 0.3288, Total Loss: 971.3490\n",
      "Epoch 2/10, Batch 2270/4401, Batch Loss: 0.2249, Total Loss: 974.6259\n",
      "Epoch 2/10, Batch 2280/4401, Batch Loss: 0.8013, Total Loss: 977.2923\n",
      "Epoch 2/10, Batch 2290/4401, Batch Loss: 0.0713, Total Loss: 980.1946\n",
      "Epoch 2/10, Batch 2300/4401, Batch Loss: 0.2920, Total Loss: 984.5553\n",
      "Epoch 2/10, Batch 2310/4401, Batch Loss: 0.3610, Total Loss: 989.7498\n",
      "Epoch 2/10, Batch 2320/4401, Batch Loss: 0.8677, Total Loss: 995.7319\n",
      "Epoch 2/10, Batch 2330/4401, Batch Loss: 0.4177, Total Loss: 1000.3787\n",
      "Epoch 2/10, Batch 2340/4401, Batch Loss: 0.8937, Total Loss: 1005.3086\n",
      "Epoch 2/10, Batch 2350/4401, Batch Loss: 0.2741, Total Loss: 1008.8145\n",
      "Epoch 2/10, Batch 2360/4401, Batch Loss: 0.5823, Total Loss: 1012.6736\n",
      "Epoch 2/10, Batch 2370/4401, Batch Loss: 0.4953, Total Loss: 1017.6187\n",
      "Epoch 2/10, Batch 2380/4401, Batch Loss: 0.8316, Total Loss: 1022.8517\n",
      "Epoch 2/10, Batch 2390/4401, Batch Loss: 0.7938, Total Loss: 1027.3839\n",
      "Epoch 2/10, Batch 2400/4401, Batch Loss: 0.1474, Total Loss: 1030.7851\n",
      "Epoch 2/10, Batch 2410/4401, Batch Loss: 0.6312, Total Loss: 1034.5850\n",
      "Epoch 2/10, Batch 2420/4401, Batch Loss: 0.0560, Total Loss: 1037.0264\n",
      "Epoch 2/10, Batch 2430/4401, Batch Loss: 0.1392, Total Loss: 1041.7257\n",
      "Epoch 2/10, Batch 2440/4401, Batch Loss: 0.2337, Total Loss: 1044.7512\n",
      "Epoch 2/10, Batch 2450/4401, Batch Loss: 0.1260, Total Loss: 1048.7590\n",
      "Epoch 2/10, Batch 2460/4401, Batch Loss: 0.2188, Total Loss: 1051.5162\n",
      "Epoch 2/10, Batch 2470/4401, Batch Loss: 0.1047, Total Loss: 1056.5026\n",
      "Epoch 2/10, Batch 2480/4401, Batch Loss: 0.2243, Total Loss: 1060.0134\n",
      "Epoch 2/10, Batch 2490/4401, Batch Loss: 0.3059, Total Loss: 1064.6117\n",
      "Epoch 2/10, Batch 2500/4401, Batch Loss: 0.0510, Total Loss: 1067.7574\n",
      "Epoch 2/10, Batch 2510/4401, Batch Loss: 0.3194, Total Loss: 1071.7803\n",
      "Epoch 2/10, Batch 2520/4401, Batch Loss: 0.0973, Total Loss: 1075.3778\n",
      "Epoch 2/10, Batch 2530/4401, Batch Loss: 0.1603, Total Loss: 1080.1191\n",
      "Epoch 2/10, Batch 2540/4401, Batch Loss: 0.7537, Total Loss: 1084.6633\n",
      "Epoch 2/10, Batch 2550/4401, Batch Loss: 0.3954, Total Loss: 1090.2912\n",
      "Epoch 2/10, Batch 2560/4401, Batch Loss: 0.0835, Total Loss: 1093.5478\n",
      "Epoch 2/10, Batch 2570/4401, Batch Loss: 0.3816, Total Loss: 1096.9296\n",
      "Epoch 2/10, Batch 2580/4401, Batch Loss: 0.3925, Total Loss: 1100.5007\n",
      "Epoch 2/10, Batch 2590/4401, Batch Loss: 0.1608, Total Loss: 1103.8545\n",
      "Epoch 2/10, Batch 2600/4401, Batch Loss: 0.3796, Total Loss: 1108.0530\n",
      "Epoch 2/10, Batch 2610/4401, Batch Loss: 0.1133, Total Loss: 1112.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 2620/4401, Batch Loss: 0.3654, Total Loss: 1114.9584\n",
      "Epoch 2/10, Batch 2630/4401, Batch Loss: 0.8767, Total Loss: 1120.6857\n",
      "Epoch 2/10, Batch 2640/4401, Batch Loss: 0.0662, Total Loss: 1123.9691\n",
      "Epoch 2/10, Batch 2650/4401, Batch Loss: 0.1978, Total Loss: 1127.7132\n",
      "Epoch 2/10, Batch 2660/4401, Batch Loss: 0.4363, Total Loss: 1132.1043\n",
      "Epoch 2/10, Batch 2670/4401, Batch Loss: 0.3028, Total Loss: 1135.7161\n",
      "Epoch 2/10, Batch 2680/4401, Batch Loss: 0.4568, Total Loss: 1139.8451\n",
      "Epoch 2/10, Batch 2690/4401, Batch Loss: 0.5595, Total Loss: 1143.2343\n",
      "Epoch 2/10, Batch 2700/4401, Batch Loss: 0.0611, Total Loss: 1147.5592\n",
      "Epoch 2/10, Batch 2710/4401, Batch Loss: 0.1890, Total Loss: 1151.8996\n",
      "Epoch 2/10, Batch 2720/4401, Batch Loss: 0.2457, Total Loss: 1156.0012\n",
      "Epoch 2/10, Batch 2730/4401, Batch Loss: 0.2147, Total Loss: 1159.3883\n",
      "Epoch 2/10, Batch 2740/4401, Batch Loss: 0.1899, Total Loss: 1162.4248\n",
      "Epoch 2/10, Batch 2750/4401, Batch Loss: 0.2246, Total Loss: 1166.4481\n",
      "Epoch 2/10, Batch 2760/4401, Batch Loss: 0.5035, Total Loss: 1170.2578\n",
      "Epoch 2/10, Batch 2770/4401, Batch Loss: 0.7182, Total Loss: 1174.0381\n",
      "Epoch 2/10, Batch 2780/4401, Batch Loss: 0.2141, Total Loss: 1179.1134\n",
      "Epoch 2/10, Batch 2790/4401, Batch Loss: 0.3725, Total Loss: 1182.2497\n",
      "Epoch 2/10, Batch 2800/4401, Batch Loss: 0.2588, Total Loss: 1185.8016\n",
      "Epoch 2/10, Batch 2810/4401, Batch Loss: 0.2535, Total Loss: 1189.4389\n",
      "Epoch 2/10, Batch 2820/4401, Batch Loss: 0.5701, Total Loss: 1192.6469\n",
      "Epoch 2/10, Batch 2830/4401, Batch Loss: 0.3673, Total Loss: 1196.8184\n",
      "Epoch 2/10, Batch 2840/4401, Batch Loss: 0.0724, Total Loss: 1201.6627\n",
      "Epoch 2/10, Batch 2850/4401, Batch Loss: 0.3872, Total Loss: 1204.9427\n",
      "Epoch 2/10, Batch 2860/4401, Batch Loss: 0.4712, Total Loss: 1207.3225\n",
      "Epoch 2/10, Batch 2870/4401, Batch Loss: 0.3519, Total Loss: 1211.0640\n",
      "Epoch 2/10, Batch 2880/4401, Batch Loss: 0.2284, Total Loss: 1215.2179\n",
      "Epoch 2/10, Batch 2890/4401, Batch Loss: 0.2137, Total Loss: 1219.0214\n",
      "Epoch 2/10, Batch 2900/4401, Batch Loss: 0.4662, Total Loss: 1224.9783\n",
      "Epoch 2/10, Batch 2910/4401, Batch Loss: 0.2068, Total Loss: 1228.7606\n",
      "Epoch 2/10, Batch 2920/4401, Batch Loss: 0.5782, Total Loss: 1232.5866\n",
      "Epoch 2/10, Batch 2930/4401, Batch Loss: 0.4080, Total Loss: 1236.9455\n",
      "Epoch 2/10, Batch 2940/4401, Batch Loss: 0.0957, Total Loss: 1239.9859\n",
      "Epoch 2/10, Batch 2950/4401, Batch Loss: 0.1459, Total Loss: 1243.7806\n",
      "Epoch 2/10, Batch 2960/4401, Batch Loss: 0.1955, Total Loss: 1250.5588\n",
      "Epoch 2/10, Batch 2970/4401, Batch Loss: 0.9804, Total Loss: 1255.3995\n",
      "Epoch 2/10, Batch 2980/4401, Batch Loss: 0.4178, Total Loss: 1259.7811\n",
      "Epoch 2/10, Batch 2990/4401, Batch Loss: 0.5686, Total Loss: 1264.2364\n",
      "Epoch 2/10, Batch 3000/4401, Batch Loss: 0.2591, Total Loss: 1268.4026\n",
      "Epoch 2/10, Batch 3010/4401, Batch Loss: 0.2046, Total Loss: 1272.8736\n",
      "Epoch 2/10, Batch 3020/4401, Batch Loss: 0.2149, Total Loss: 1276.5064\n",
      "Epoch 2/10, Batch 3030/4401, Batch Loss: 0.1709, Total Loss: 1278.5880\n",
      "Epoch 2/10, Batch 3040/4401, Batch Loss: 0.6478, Total Loss: 1283.8080\n",
      "Epoch 2/10, Batch 3050/4401, Batch Loss: 0.1576, Total Loss: 1288.0591\n",
      "Epoch 2/10, Batch 3060/4401, Batch Loss: 0.1878, Total Loss: 1291.0859\n",
      "Epoch 2/10, Batch 3070/4401, Batch Loss: 0.1701, Total Loss: 1294.6911\n",
      "Epoch 2/10, Batch 3080/4401, Batch Loss: 0.8182, Total Loss: 1297.8541\n",
      "Epoch 2/10, Batch 3090/4401, Batch Loss: 0.6129, Total Loss: 1303.1629\n",
      "Epoch 2/10, Batch 3100/4401, Batch Loss: 0.6419, Total Loss: 1307.2452\n",
      "Epoch 2/10, Batch 3110/4401, Batch Loss: 0.0538, Total Loss: 1309.8673\n",
      "Epoch 2/10, Batch 3120/4401, Batch Loss: 0.2908, Total Loss: 1313.0187\n",
      "Epoch 2/10, Batch 3130/4401, Batch Loss: 0.2642, Total Loss: 1317.3239\n",
      "Epoch 2/10, Batch 3140/4401, Batch Loss: 0.2756, Total Loss: 1320.9662\n",
      "Epoch 2/10, Batch 3150/4401, Batch Loss: 0.0881, Total Loss: 1323.8317\n",
      "Epoch 2/10, Batch 3160/4401, Batch Loss: 0.3091, Total Loss: 1326.7128\n",
      "Epoch 2/10, Batch 3170/4401, Batch Loss: 0.1679, Total Loss: 1330.7336\n",
      "Epoch 2/10, Batch 3180/4401, Batch Loss: 0.5684, Total Loss: 1335.3263\n",
      "Epoch 2/10, Batch 3190/4401, Batch Loss: 0.1417, Total Loss: 1338.4131\n",
      "Epoch 2/10, Batch 3200/4401, Batch Loss: 0.4058, Total Loss: 1341.9881\n",
      "Epoch 2/10, Batch 3210/4401, Batch Loss: 0.6268, Total Loss: 1346.1731\n",
      "Epoch 2/10, Batch 3220/4401, Batch Loss: 0.0666, Total Loss: 1350.5066\n",
      "Epoch 2/10, Batch 3230/4401, Batch Loss: 0.3124, Total Loss: 1353.5553\n",
      "Epoch 2/10, Batch 3240/4401, Batch Loss: 0.1630, Total Loss: 1357.4893\n",
      "Epoch 2/10, Batch 3250/4401, Batch Loss: 0.5346, Total Loss: 1361.1379\n",
      "Epoch 2/10, Batch 3260/4401, Batch Loss: 0.2609, Total Loss: 1364.6410\n",
      "Epoch 2/10, Batch 3270/4401, Batch Loss: 0.2592, Total Loss: 1367.9948\n",
      "Epoch 2/10, Batch 3280/4401, Batch Loss: 0.4784, Total Loss: 1372.6504\n",
      "Epoch 2/10, Batch 3290/4401, Batch Loss: 0.7247, Total Loss: 1376.8544\n",
      "Epoch 2/10, Batch 3300/4401, Batch Loss: 0.5346, Total Loss: 1383.3350\n",
      "Epoch 2/10, Batch 3310/4401, Batch Loss: 0.3407, Total Loss: 1388.8568\n",
      "Epoch 2/10, Batch 3320/4401, Batch Loss: 0.1195, Total Loss: 1391.9214\n",
      "Epoch 2/10, Batch 3330/4401, Batch Loss: 0.2257, Total Loss: 1396.7379\n",
      "Epoch 2/10, Batch 3340/4401, Batch Loss: 0.7086, Total Loss: 1401.5523\n",
      "Epoch 2/10, Batch 3350/4401, Batch Loss: 0.4758, Total Loss: 1404.4364\n",
      "Epoch 2/10, Batch 3360/4401, Batch Loss: 0.4357, Total Loss: 1409.7366\n",
      "Epoch 2/10, Batch 3370/4401, Batch Loss: 0.6962, Total Loss: 1414.3061\n",
      "Epoch 2/10, Batch 3380/4401, Batch Loss: 0.2450, Total Loss: 1417.4943\n",
      "Epoch 2/10, Batch 3390/4401, Batch Loss: 0.4405, Total Loss: 1421.1106\n",
      "Epoch 2/10, Batch 3400/4401, Batch Loss: 0.2376, Total Loss: 1425.3491\n",
      "Epoch 2/10, Batch 3410/4401, Batch Loss: 0.5639, Total Loss: 1429.6820\n",
      "Epoch 2/10, Batch 3420/4401, Batch Loss: 0.2582, Total Loss: 1433.0131\n",
      "Epoch 2/10, Batch 3430/4401, Batch Loss: 0.0759, Total Loss: 1436.3473\n",
      "Epoch 2/10, Batch 3440/4401, Batch Loss: 0.5893, Total Loss: 1439.8884\n",
      "Epoch 2/10, Batch 3450/4401, Batch Loss: 0.3853, Total Loss: 1445.0192\n",
      "Epoch 2/10, Batch 3460/4401, Batch Loss: 0.4667, Total Loss: 1448.7288\n",
      "Epoch 2/10, Batch 3470/4401, Batch Loss: 0.1963, Total Loss: 1451.7541\n",
      "Epoch 2/10, Batch 3480/4401, Batch Loss: 0.3056, Total Loss: 1456.7636\n",
      "Epoch 2/10, Batch 3490/4401, Batch Loss: 0.5537, Total Loss: 1462.4159\n",
      "Epoch 2/10, Batch 3500/4401, Batch Loss: 0.1133, Total Loss: 1465.5766\n",
      "Epoch 2/10, Batch 3510/4401, Batch Loss: 0.0746, Total Loss: 1467.9726\n",
      "Epoch 2/10, Batch 3520/4401, Batch Loss: 0.4058, Total Loss: 1472.8725\n",
      "Epoch 2/10, Batch 3530/4401, Batch Loss: 0.3971, Total Loss: 1477.5925\n",
      "Epoch 2/10, Batch 3540/4401, Batch Loss: 0.3924, Total Loss: 1482.1117\n",
      "Epoch 2/10, Batch 3550/4401, Batch Loss: 0.2130, Total Loss: 1485.8935\n",
      "Epoch 2/10, Batch 3560/4401, Batch Loss: 0.3228, Total Loss: 1490.9583\n",
      "Epoch 2/10, Batch 3570/4401, Batch Loss: 1.0368, Total Loss: 1496.2323\n",
      "Epoch 2/10, Batch 3580/4401, Batch Loss: 0.3497, Total Loss: 1500.0325\n",
      "Epoch 2/10, Batch 3590/4401, Batch Loss: 0.1305, Total Loss: 1504.3197\n",
      "Epoch 2/10, Batch 3600/4401, Batch Loss: 0.2120, Total Loss: 1507.9090\n",
      "Epoch 2/10, Batch 3610/4401, Batch Loss: 0.3306, Total Loss: 1512.8354\n",
      "Epoch 2/10, Batch 3620/4401, Batch Loss: 0.2935, Total Loss: 1516.3096\n",
      "Epoch 2/10, Batch 3630/4401, Batch Loss: 0.4767, Total Loss: 1519.4190\n",
      "Epoch 2/10, Batch 3640/4401, Batch Loss: 0.3085, Total Loss: 1524.1223\n",
      "Epoch 2/10, Batch 3650/4401, Batch Loss: 1.1922, Total Loss: 1528.8866\n",
      "Epoch 2/10, Batch 3660/4401, Batch Loss: 0.2894, Total Loss: 1531.1494\n",
      "Epoch 2/10, Batch 3670/4401, Batch Loss: 0.3793, Total Loss: 1534.2532\n",
      "Epoch 2/10, Batch 3680/4401, Batch Loss: 0.3534, Total Loss: 1538.8954\n",
      "Epoch 2/10, Batch 3690/4401, Batch Loss: 0.5667, Total Loss: 1542.4153\n",
      "Epoch 2/10, Batch 3700/4401, Batch Loss: 0.4573, Total Loss: 1548.2558\n",
      "Epoch 2/10, Batch 3710/4401, Batch Loss: 1.0925, Total Loss: 1552.5697\n",
      "Epoch 2/10, Batch 3720/4401, Batch Loss: 0.4686, Total Loss: 1557.1064\n",
      "Epoch 2/10, Batch 3730/4401, Batch Loss: 0.2896, Total Loss: 1560.9704\n",
      "Epoch 2/10, Batch 3740/4401, Batch Loss: 0.6085, Total Loss: 1564.8513\n",
      "Epoch 2/10, Batch 3750/4401, Batch Loss: 0.0993, Total Loss: 1568.8504\n",
      "Epoch 2/10, Batch 3760/4401, Batch Loss: 0.2357, Total Loss: 1572.9648\n",
      "Epoch 2/10, Batch 3770/4401, Batch Loss: 0.9980, Total Loss: 1577.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 3780/4401, Batch Loss: 0.0242, Total Loss: 1582.3755\n",
      "Epoch 2/10, Batch 3790/4401, Batch Loss: 0.1481, Total Loss: 1585.7139\n",
      "Epoch 2/10, Batch 3800/4401, Batch Loss: 0.4528, Total Loss: 1588.9577\n",
      "Epoch 2/10, Batch 3810/4401, Batch Loss: 0.9036, Total Loss: 1593.2653\n",
      "Epoch 2/10, Batch 3820/4401, Batch Loss: 0.2373, Total Loss: 1598.5926\n",
      "Epoch 2/10, Batch 3830/4401, Batch Loss: 0.2272, Total Loss: 1602.6990\n",
      "Epoch 2/10, Batch 3840/4401, Batch Loss: 0.4868, Total Loss: 1606.6567\n",
      "Epoch 2/10, Batch 3850/4401, Batch Loss: 1.4167, Total Loss: 1612.8978\n",
      "Epoch 2/10, Batch 3860/4401, Batch Loss: 0.3484, Total Loss: 1618.1916\n",
      "Epoch 2/10, Batch 3870/4401, Batch Loss: 0.3601, Total Loss: 1621.9093\n",
      "Epoch 2/10, Batch 3880/4401, Batch Loss: 0.1378, Total Loss: 1625.1401\n",
      "Epoch 2/10, Batch 3890/4401, Batch Loss: 1.5025, Total Loss: 1631.1053\n",
      "Epoch 2/10, Batch 3900/4401, Batch Loss: 0.1673, Total Loss: 1635.2127\n",
      "Epoch 2/10, Batch 3910/4401, Batch Loss: 0.2662, Total Loss: 1640.0405\n",
      "Epoch 2/10, Batch 3920/4401, Batch Loss: 0.2764, Total Loss: 1644.4540\n",
      "Epoch 2/10, Batch 3930/4401, Batch Loss: 0.2893, Total Loss: 1648.3207\n",
      "Epoch 2/10, Batch 3940/4401, Batch Loss: 0.2527, Total Loss: 1652.1671\n",
      "Epoch 2/10, Batch 3950/4401, Batch Loss: 0.3180, Total Loss: 1656.2967\n",
      "Epoch 2/10, Batch 3960/4401, Batch Loss: 0.2812, Total Loss: 1660.3299\n",
      "Epoch 2/10, Batch 3970/4401, Batch Loss: 0.2980, Total Loss: 1663.5895\n",
      "Epoch 2/10, Batch 3980/4401, Batch Loss: 0.1403, Total Loss: 1666.7638\n",
      "Epoch 2/10, Batch 3990/4401, Batch Loss: 0.3446, Total Loss: 1669.7541\n",
      "Epoch 2/10, Batch 4000/4401, Batch Loss: 0.4039, Total Loss: 1673.8482\n",
      "Epoch 2/10, Batch 4010/4401, Batch Loss: 0.0974, Total Loss: 1677.5483\n",
      "Epoch 2/10, Batch 4020/4401, Batch Loss: 0.2421, Total Loss: 1680.9469\n",
      "Epoch 2/10, Batch 4030/4401, Batch Loss: 1.0693, Total Loss: 1685.6131\n",
      "Epoch 2/10, Batch 4040/4401, Batch Loss: 0.1918, Total Loss: 1690.2027\n",
      "Epoch 2/10, Batch 4050/4401, Batch Loss: 0.3297, Total Loss: 1695.0729\n",
      "Epoch 2/10, Batch 4060/4401, Batch Loss: 0.2441, Total Loss: 1698.6043\n",
      "Epoch 2/10, Batch 4070/4401, Batch Loss: 0.2575, Total Loss: 1703.1806\n",
      "Epoch 2/10, Batch 4080/4401, Batch Loss: 0.6520, Total Loss: 1707.5359\n",
      "Epoch 2/10, Batch 4090/4401, Batch Loss: 0.1322, Total Loss: 1711.2106\n",
      "Epoch 2/10, Batch 4100/4401, Batch Loss: 0.6309, Total Loss: 1714.2319\n",
      "Epoch 2/10, Batch 4110/4401, Batch Loss: 0.4179, Total Loss: 1718.1508\n",
      "Epoch 2/10, Batch 4120/4401, Batch Loss: 1.2690, Total Loss: 1724.0117\n",
      "Epoch 2/10, Batch 4130/4401, Batch Loss: 0.2855, Total Loss: 1727.8242\n",
      "Epoch 2/10, Batch 4140/4401, Batch Loss: 0.3806, Total Loss: 1730.6355\n",
      "Epoch 2/10, Batch 4150/4401, Batch Loss: 0.4150, Total Loss: 1735.4499\n",
      "Epoch 2/10, Batch 4160/4401, Batch Loss: 0.5431, Total Loss: 1738.9774\n",
      "Epoch 2/10, Batch 4170/4401, Batch Loss: 0.2405, Total Loss: 1741.7618\n",
      "Epoch 2/10, Batch 4180/4401, Batch Loss: 0.3507, Total Loss: 1745.0786\n",
      "Epoch 2/10, Batch 4190/4401, Batch Loss: 0.7387, Total Loss: 1750.1478\n",
      "Epoch 2/10, Batch 4200/4401, Batch Loss: 0.3089, Total Loss: 1753.3254\n",
      "Epoch 2/10, Batch 4210/4401, Batch Loss: 0.1857, Total Loss: 1755.9926\n",
      "Epoch 2/10, Batch 4220/4401, Batch Loss: 0.3770, Total Loss: 1760.8174\n",
      "Epoch 2/10, Batch 4230/4401, Batch Loss: 0.3111, Total Loss: 1764.3232\n",
      "Epoch 2/10, Batch 4240/4401, Batch Loss: 0.3410, Total Loss: 1768.2855\n",
      "Epoch 2/10, Batch 4250/4401, Batch Loss: 0.1564, Total Loss: 1772.4384\n",
      "Epoch 2/10, Batch 4260/4401, Batch Loss: 0.2202, Total Loss: 1776.5453\n",
      "Epoch 2/10, Batch 4270/4401, Batch Loss: 0.0670, Total Loss: 1780.2373\n",
      "Epoch 2/10, Batch 4280/4401, Batch Loss: 0.0805, Total Loss: 1783.4164\n",
      "Epoch 2/10, Batch 4290/4401, Batch Loss: 0.8362, Total Loss: 1788.1185\n",
      "Epoch 2/10, Batch 4300/4401, Batch Loss: 0.1913, Total Loss: 1791.4074\n",
      "Epoch 2/10, Batch 4310/4401, Batch Loss: 0.0732, Total Loss: 1794.3451\n",
      "Epoch 2/10, Batch 4320/4401, Batch Loss: 0.1058, Total Loss: 1798.6578\n",
      "Epoch 2/10, Batch 4330/4401, Batch Loss: 0.3258, Total Loss: 1802.4266\n",
      "Epoch 2/10, Batch 4340/4401, Batch Loss: 0.2357, Total Loss: 1806.1857\n",
      "Epoch 2/10, Batch 4350/4401, Batch Loss: 0.2363, Total Loss: 1807.8650\n",
      "Epoch 2/10, Batch 4360/4401, Batch Loss: 0.3739, Total Loss: 1812.0575\n",
      "Epoch 2/10, Batch 4370/4401, Batch Loss: 0.6391, Total Loss: 1815.9027\n",
      "Epoch 2/10, Batch 4380/4401, Batch Loss: 0.2483, Total Loss: 1821.0133\n",
      "Epoch 2/10, Batch 4390/4401, Batch Loss: 0.5042, Total Loss: 1824.4235\n",
      "Epoch 2/10, Batch 4400/4401, Batch Loss: 0.4792, Total Loss: 1829.2334\n",
      "Epoch 2/10, Batch 4401/4401, Batch Loss: 0.0071, Total Loss: 1829.2405\n",
      "Epoch 2/10 completed. Total Loss: 1829.2405\n",
      "\n",
      "Epoch 3/10 running...\n",
      "cuda:0\n",
      "Epoch 3/10, Batch 10/4401, Batch Loss: 0.2081, Total Loss: 3.6460\n",
      "Epoch 3/10, Batch 20/4401, Batch Loss: 0.2024, Total Loss: 7.4639\n",
      "Epoch 3/10, Batch 30/4401, Batch Loss: 0.3272, Total Loss: 11.4164\n",
      "Epoch 3/10, Batch 40/4401, Batch Loss: 0.1418, Total Loss: 14.7340\n",
      "Epoch 3/10, Batch 50/4401, Batch Loss: 0.2915, Total Loss: 19.1433\n",
      "Epoch 3/10, Batch 60/4401, Batch Loss: 1.1082, Total Loss: 22.6387\n",
      "Epoch 3/10, Batch 70/4401, Batch Loss: 0.7439, Total Loss: 25.5061\n",
      "Epoch 3/10, Batch 80/4401, Batch Loss: 0.2402, Total Loss: 29.3583\n",
      "Epoch 3/10, Batch 90/4401, Batch Loss: 0.1821, Total Loss: 32.9146\n",
      "Epoch 3/10, Batch 100/4401, Batch Loss: 0.1995, Total Loss: 36.0709\n",
      "Epoch 3/10, Batch 110/4401, Batch Loss: 0.4894, Total Loss: 40.0503\n",
      "Epoch 3/10, Batch 120/4401, Batch Loss: 0.2090, Total Loss: 43.7745\n",
      "Epoch 3/10, Batch 130/4401, Batch Loss: 0.2474, Total Loss: 47.2259\n",
      "Epoch 3/10, Batch 140/4401, Batch Loss: 0.1681, Total Loss: 50.8370\n",
      "Epoch 3/10, Batch 150/4401, Batch Loss: 0.2672, Total Loss: 53.9364\n",
      "Epoch 3/10, Batch 160/4401, Batch Loss: 0.3309, Total Loss: 57.5114\n",
      "Epoch 3/10, Batch 170/4401, Batch Loss: 0.0560, Total Loss: 59.9807\n",
      "Epoch 3/10, Batch 180/4401, Batch Loss: 0.9856, Total Loss: 65.2455\n",
      "Epoch 3/10, Batch 190/4401, Batch Loss: 0.3827, Total Loss: 68.8680\n",
      "Epoch 3/10, Batch 200/4401, Batch Loss: 0.4248, Total Loss: 72.3334\n",
      "Epoch 3/10, Batch 210/4401, Batch Loss: 0.3818, Total Loss: 76.3759\n",
      "Epoch 3/10, Batch 220/4401, Batch Loss: 0.5947, Total Loss: 80.2924\n",
      "Epoch 3/10, Batch 230/4401, Batch Loss: 0.5232, Total Loss: 84.9995\n",
      "Epoch 3/10, Batch 240/4401, Batch Loss: 0.3193, Total Loss: 88.5662\n",
      "Epoch 3/10, Batch 250/4401, Batch Loss: 0.2566, Total Loss: 92.5604\n",
      "Epoch 3/10, Batch 260/4401, Batch Loss: 0.1816, Total Loss: 95.8560\n",
      "Epoch 3/10, Batch 270/4401, Batch Loss: 0.4554, Total Loss: 100.3015\n",
      "Epoch 3/10, Batch 280/4401, Batch Loss: 0.3993, Total Loss: 104.5062\n",
      "Epoch 3/10, Batch 290/4401, Batch Loss: 0.2369, Total Loss: 106.7589\n",
      "Epoch 3/10, Batch 300/4401, Batch Loss: 0.3040, Total Loss: 110.7775\n",
      "Epoch 3/10, Batch 310/4401, Batch Loss: 0.4267, Total Loss: 114.6678\n",
      "Epoch 3/10, Batch 320/4401, Batch Loss: 0.8839, Total Loss: 119.3764\n",
      "Epoch 3/10, Batch 330/4401, Batch Loss: 0.0983, Total Loss: 121.7716\n",
      "Epoch 3/10, Batch 340/4401, Batch Loss: 0.3497, Total Loss: 125.1443\n",
      "Epoch 3/10, Batch 350/4401, Batch Loss: 0.2232, Total Loss: 128.9903\n",
      "Epoch 3/10, Batch 360/4401, Batch Loss: 0.2171, Total Loss: 133.6017\n",
      "Epoch 3/10, Batch 370/4401, Batch Loss: 0.1605, Total Loss: 136.8320\n",
      "Epoch 3/10, Batch 380/4401, Batch Loss: 0.1662, Total Loss: 140.5487\n",
      "Epoch 3/10, Batch 390/4401, Batch Loss: 0.5657, Total Loss: 143.9496\n",
      "Epoch 3/10, Batch 400/4401, Batch Loss: 0.2708, Total Loss: 147.3865\n",
      "Epoch 3/10, Batch 410/4401, Batch Loss: 0.2570, Total Loss: 151.4153\n",
      "Epoch 3/10, Batch 420/4401, Batch Loss: 0.0474, Total Loss: 154.4320\n",
      "Epoch 3/10, Batch 430/4401, Batch Loss: 0.5275, Total Loss: 158.3447\n",
      "Epoch 3/10, Batch 440/4401, Batch Loss: 0.0495, Total Loss: 160.4434\n",
      "Epoch 3/10, Batch 450/4401, Batch Loss: 0.1086, Total Loss: 163.4689\n",
      "Epoch 3/10, Batch 460/4401, Batch Loss: 0.1685, Total Loss: 166.4589\n",
      "Epoch 3/10, Batch 470/4401, Batch Loss: 0.2549, Total Loss: 169.3858\n",
      "Epoch 3/10, Batch 480/4401, Batch Loss: 0.1327, Total Loss: 173.8910\n",
      "Epoch 3/10, Batch 490/4401, Batch Loss: 0.1067, Total Loss: 178.1894\n",
      "Epoch 3/10, Batch 500/4401, Batch Loss: 0.2785, Total Loss: 181.2466\n",
      "Epoch 3/10, Batch 510/4401, Batch Loss: 0.2005, Total Loss: 185.6982\n",
      "Epoch 3/10, Batch 520/4401, Batch Loss: 0.1180, Total Loss: 188.9908\n",
      "Epoch 3/10, Batch 530/4401, Batch Loss: 0.3984, Total Loss: 192.8248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 540/4401, Batch Loss: 0.4139, Total Loss: 195.9830\n",
      "Epoch 3/10, Batch 550/4401, Batch Loss: 0.3608, Total Loss: 199.2892\n",
      "Epoch 3/10, Batch 560/4401, Batch Loss: 0.2235, Total Loss: 204.2987\n",
      "Epoch 3/10, Batch 570/4401, Batch Loss: 0.3421, Total Loss: 207.7300\n",
      "Epoch 3/10, Batch 580/4401, Batch Loss: 0.0065, Total Loss: 211.0861\n",
      "Epoch 3/10, Batch 590/4401, Batch Loss: 0.1521, Total Loss: 214.1618\n",
      "Epoch 3/10, Batch 600/4401, Batch Loss: 0.1965, Total Loss: 218.5587\n",
      "Epoch 3/10, Batch 610/4401, Batch Loss: 0.0827, Total Loss: 221.5476\n",
      "Epoch 3/10, Batch 620/4401, Batch Loss: 0.0790, Total Loss: 224.5297\n",
      "Epoch 3/10, Batch 630/4401, Batch Loss: 0.2050, Total Loss: 227.9108\n",
      "Epoch 3/10, Batch 640/4401, Batch Loss: 0.2210, Total Loss: 232.4530\n",
      "Epoch 3/10, Batch 650/4401, Batch Loss: 0.1488, Total Loss: 236.2333\n",
      "Epoch 3/10, Batch 660/4401, Batch Loss: 0.4879, Total Loss: 238.9758\n",
      "Epoch 3/10, Batch 670/4401, Batch Loss: 0.9142, Total Loss: 242.2463\n",
      "Epoch 3/10, Batch 680/4401, Batch Loss: 0.0310, Total Loss: 245.0479\n",
      "Epoch 3/10, Batch 690/4401, Batch Loss: 0.6215, Total Loss: 247.9843\n",
      "Epoch 3/10, Batch 700/4401, Batch Loss: 0.8327, Total Loss: 251.4794\n",
      "Epoch 3/10, Batch 710/4401, Batch Loss: 0.5538, Total Loss: 254.0233\n",
      "Epoch 3/10, Batch 720/4401, Batch Loss: 0.7309, Total Loss: 259.1143\n",
      "Epoch 3/10, Batch 730/4401, Batch Loss: 0.0898, Total Loss: 262.1810\n",
      "Epoch 3/10, Batch 740/4401, Batch Loss: 0.4321, Total Loss: 266.6520\n",
      "Epoch 3/10, Batch 750/4401, Batch Loss: 0.4198, Total Loss: 269.8623\n",
      "Epoch 3/10, Batch 760/4401, Batch Loss: 0.4642, Total Loss: 273.2061\n",
      "Epoch 3/10, Batch 770/4401, Batch Loss: 0.3982, Total Loss: 277.2922\n",
      "Epoch 3/10, Batch 780/4401, Batch Loss: 0.5306, Total Loss: 281.2180\n",
      "Epoch 3/10, Batch 790/4401, Batch Loss: 0.5541, Total Loss: 285.5988\n",
      "Epoch 3/10, Batch 800/4401, Batch Loss: 0.4069, Total Loss: 288.9185\n",
      "Epoch 3/10, Batch 810/4401, Batch Loss: 1.0190, Total Loss: 292.8970\n",
      "Epoch 3/10, Batch 820/4401, Batch Loss: 0.1246, Total Loss: 295.3128\n",
      "Epoch 3/10, Batch 830/4401, Batch Loss: 0.0921, Total Loss: 299.8837\n",
      "Epoch 3/10, Batch 840/4401, Batch Loss: 0.9367, Total Loss: 304.6631\n",
      "Epoch 3/10, Batch 850/4401, Batch Loss: 0.4189, Total Loss: 307.5362\n",
      "Epoch 3/10, Batch 860/4401, Batch Loss: 0.0959, Total Loss: 312.0743\n",
      "Epoch 3/10, Batch 870/4401, Batch Loss: 0.5377, Total Loss: 317.3198\n",
      "Epoch 3/10, Batch 880/4401, Batch Loss: 0.3508, Total Loss: 321.0696\n",
      "Epoch 3/10, Batch 890/4401, Batch Loss: 0.3316, Total Loss: 324.4192\n",
      "Epoch 3/10, Batch 900/4401, Batch Loss: 0.1070, Total Loss: 328.0560\n",
      "Epoch 3/10, Batch 910/4401, Batch Loss: 0.5264, Total Loss: 331.2337\n",
      "Epoch 3/10, Batch 920/4401, Batch Loss: 0.4816, Total Loss: 335.5087\n",
      "Epoch 3/10, Batch 930/4401, Batch Loss: 0.0751, Total Loss: 338.5862\n",
      "Epoch 3/10, Batch 940/4401, Batch Loss: 0.2474, Total Loss: 342.5422\n",
      "Epoch 3/10, Batch 950/4401, Batch Loss: 0.2930, Total Loss: 345.8668\n",
      "Epoch 3/10, Batch 960/4401, Batch Loss: 0.2389, Total Loss: 348.1840\n",
      "Epoch 3/10, Batch 970/4401, Batch Loss: 0.0821, Total Loss: 351.9502\n",
      "Epoch 3/10, Batch 980/4401, Batch Loss: 0.1158, Total Loss: 355.2345\n",
      "Epoch 3/10, Batch 990/4401, Batch Loss: 0.2950, Total Loss: 358.3456\n",
      "Epoch 3/10, Batch 1000/4401, Batch Loss: 0.6418, Total Loss: 363.2566\n",
      "Epoch 3/10, Batch 1010/4401, Batch Loss: 0.6370, Total Loss: 366.2726\n",
      "Epoch 3/10, Batch 1020/4401, Batch Loss: 0.1509, Total Loss: 370.4265\n",
      "Epoch 3/10, Batch 1030/4401, Batch Loss: 0.5018, Total Loss: 373.2058\n",
      "Epoch 3/10, Batch 1040/4401, Batch Loss: 0.2376, Total Loss: 375.9180\n",
      "Epoch 3/10, Batch 1050/4401, Batch Loss: 0.2265, Total Loss: 379.2187\n",
      "Epoch 3/10, Batch 1060/4401, Batch Loss: 0.1997, Total Loss: 382.2561\n",
      "Epoch 3/10, Batch 1070/4401, Batch Loss: 1.2400, Total Loss: 388.1309\n",
      "Epoch 3/10, Batch 1080/4401, Batch Loss: 0.4069, Total Loss: 391.3528\n",
      "Epoch 3/10, Batch 1090/4401, Batch Loss: 0.3090, Total Loss: 397.6635\n",
      "Epoch 3/10, Batch 1100/4401, Batch Loss: 0.4227, Total Loss: 401.8125\n",
      "Epoch 3/10, Batch 1110/4401, Batch Loss: 0.2900, Total Loss: 405.4404\n",
      "Epoch 3/10, Batch 1120/4401, Batch Loss: 0.4009, Total Loss: 408.8968\n",
      "Epoch 3/10, Batch 1130/4401, Batch Loss: 0.2849, Total Loss: 411.7813\n",
      "Epoch 3/10, Batch 1140/4401, Batch Loss: 0.3522, Total Loss: 414.7703\n",
      "Epoch 3/10, Batch 1150/4401, Batch Loss: 0.2472, Total Loss: 418.6696\n",
      "Epoch 3/10, Batch 1160/4401, Batch Loss: 0.2398, Total Loss: 421.6177\n",
      "Epoch 3/10, Batch 1170/4401, Batch Loss: 0.9984, Total Loss: 425.3244\n",
      "Epoch 3/10, Batch 1180/4401, Batch Loss: 0.2538, Total Loss: 428.6063\n",
      "Epoch 3/10, Batch 1190/4401, Batch Loss: 0.7385, Total Loss: 432.6731\n",
      "Epoch 3/10, Batch 1200/4401, Batch Loss: 0.3694, Total Loss: 435.1588\n",
      "Epoch 3/10, Batch 1210/4401, Batch Loss: 0.1854, Total Loss: 439.2848\n",
      "Epoch 3/10, Batch 1220/4401, Batch Loss: 0.2859, Total Loss: 443.1783\n",
      "Epoch 3/10, Batch 1230/4401, Batch Loss: 0.3151, Total Loss: 447.3423\n",
      "Epoch 3/10, Batch 1240/4401, Batch Loss: 0.2603, Total Loss: 450.5888\n",
      "Epoch 3/10, Batch 1250/4401, Batch Loss: 0.4389, Total Loss: 453.6647\n",
      "Epoch 3/10, Batch 1260/4401, Batch Loss: 0.3486, Total Loss: 457.6539\n",
      "Epoch 3/10, Batch 1270/4401, Batch Loss: 0.3857, Total Loss: 460.7584\n",
      "Epoch 3/10, Batch 1280/4401, Batch Loss: 0.3360, Total Loss: 465.3960\n",
      "Epoch 3/10, Batch 1290/4401, Batch Loss: 0.3280, Total Loss: 468.3825\n",
      "Epoch 3/10, Batch 1300/4401, Batch Loss: 0.3853, Total Loss: 471.5321\n",
      "Epoch 3/10, Batch 1310/4401, Batch Loss: 0.3143, Total Loss: 474.4189\n",
      "Epoch 3/10, Batch 1320/4401, Batch Loss: 0.0712, Total Loss: 478.1817\n",
      "Epoch 3/10, Batch 1330/4401, Batch Loss: 0.2293, Total Loss: 480.8218\n",
      "Epoch 3/10, Batch 1340/4401, Batch Loss: 0.1635, Total Loss: 485.0487\n",
      "Epoch 3/10, Batch 1350/4401, Batch Loss: 0.1214, Total Loss: 490.3123\n",
      "Epoch 3/10, Batch 1360/4401, Batch Loss: 0.0655, Total Loss: 493.5892\n",
      "Epoch 3/10, Batch 1370/4401, Batch Loss: 0.2608, Total Loss: 497.2688\n",
      "Epoch 3/10, Batch 1380/4401, Batch Loss: 0.2232, Total Loss: 501.2762\n",
      "Epoch 3/10, Batch 1390/4401, Batch Loss: 0.3338, Total Loss: 504.7267\n",
      "Epoch 3/10, Batch 1400/4401, Batch Loss: 0.6100, Total Loss: 507.9038\n",
      "Epoch 3/10, Batch 1410/4401, Batch Loss: 0.3816, Total Loss: 512.7452\n",
      "Epoch 3/10, Batch 1420/4401, Batch Loss: 0.2949, Total Loss: 516.9988\n",
      "Epoch 3/10, Batch 1430/4401, Batch Loss: 0.2842, Total Loss: 519.5172\n",
      "Epoch 3/10, Batch 1440/4401, Batch Loss: 0.2172, Total Loss: 522.2176\n",
      "Epoch 3/10, Batch 1450/4401, Batch Loss: 0.3990, Total Loss: 527.2483\n",
      "Epoch 3/10, Batch 1460/4401, Batch Loss: 0.2712, Total Loss: 530.9870\n",
      "Epoch 3/10, Batch 1470/4401, Batch Loss: 0.9038, Total Loss: 535.2279\n",
      "Epoch 3/10, Batch 1480/4401, Batch Loss: 0.0850, Total Loss: 538.5842\n",
      "Epoch 3/10, Batch 1490/4401, Batch Loss: 0.1681, Total Loss: 541.3878\n",
      "Epoch 3/10, Batch 1500/4401, Batch Loss: 0.5239, Total Loss: 545.1598\n",
      "Epoch 3/10, Batch 1510/4401, Batch Loss: 0.2164, Total Loss: 549.0520\n",
      "Epoch 3/10, Batch 1520/4401, Batch Loss: 0.4041, Total Loss: 551.9509\n",
      "Epoch 3/10, Batch 1530/4401, Batch Loss: 0.3051, Total Loss: 556.8772\n",
      "Epoch 3/10, Batch 1540/4401, Batch Loss: 0.4185, Total Loss: 560.2035\n",
      "Epoch 3/10, Batch 1550/4401, Batch Loss: 1.1269, Total Loss: 563.8358\n",
      "Epoch 3/10, Batch 1560/4401, Batch Loss: 0.2456, Total Loss: 568.2066\n",
      "Epoch 3/10, Batch 1570/4401, Batch Loss: 0.4135, Total Loss: 570.7068\n",
      "Epoch 3/10, Batch 1580/4401, Batch Loss: 0.2216, Total Loss: 574.8585\n",
      "Epoch 3/10, Batch 1590/4401, Batch Loss: 0.2707, Total Loss: 579.0262\n",
      "Epoch 3/10, Batch 1600/4401, Batch Loss: 0.2660, Total Loss: 582.6665\n",
      "Epoch 3/10, Batch 1610/4401, Batch Loss: 0.0671, Total Loss: 584.6717\n",
      "Epoch 3/10, Batch 1620/4401, Batch Loss: 0.2628, Total Loss: 587.9200\n",
      "Epoch 3/10, Batch 1630/4401, Batch Loss: 0.2509, Total Loss: 591.0591\n",
      "Epoch 3/10, Batch 1640/4401, Batch Loss: 0.3994, Total Loss: 593.9943\n",
      "Epoch 3/10, Batch 1650/4401, Batch Loss: 0.2564, Total Loss: 597.7236\n",
      "Epoch 3/10, Batch 1660/4401, Batch Loss: 0.3392, Total Loss: 600.7779\n",
      "Epoch 3/10, Batch 1670/4401, Batch Loss: 0.2032, Total Loss: 604.6606\n",
      "Epoch 3/10, Batch 1680/4401, Batch Loss: 0.2525, Total Loss: 607.6482\n",
      "Epoch 3/10, Batch 1690/4401, Batch Loss: 0.0987, Total Loss: 610.7910\n",
      "Epoch 3/10, Batch 1700/4401, Batch Loss: 0.1294, Total Loss: 614.3124\n",
      "Epoch 3/10, Batch 1710/4401, Batch Loss: 0.3126, Total Loss: 618.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1720/4401, Batch Loss: 0.6809, Total Loss: 621.1301\n",
      "Epoch 3/10, Batch 1730/4401, Batch Loss: 0.5441, Total Loss: 624.6954\n",
      "Epoch 3/10, Batch 1740/4401, Batch Loss: 0.1649, Total Loss: 628.2329\n",
      "Epoch 3/10, Batch 1750/4401, Batch Loss: 0.1839, Total Loss: 632.0314\n",
      "Epoch 3/10, Batch 1760/4401, Batch Loss: 0.5756, Total Loss: 635.3049\n",
      "Epoch 3/10, Batch 1770/4401, Batch Loss: 0.4938, Total Loss: 639.3763\n",
      "Epoch 3/10, Batch 1780/4401, Batch Loss: 0.3361, Total Loss: 642.1432\n",
      "Epoch 3/10, Batch 1790/4401, Batch Loss: 0.3209, Total Loss: 645.7656\n",
      "Epoch 3/10, Batch 1800/4401, Batch Loss: 0.1452, Total Loss: 649.0789\n",
      "Epoch 3/10, Batch 1810/4401, Batch Loss: 0.5987, Total Loss: 653.0947\n",
      "Epoch 3/10, Batch 1820/4401, Batch Loss: 0.5521, Total Loss: 657.1182\n",
      "Epoch 3/10, Batch 1830/4401, Batch Loss: 0.2086, Total Loss: 660.5419\n",
      "Epoch 3/10, Batch 1840/4401, Batch Loss: 0.0828, Total Loss: 663.2446\n",
      "Epoch 3/10, Batch 1850/4401, Batch Loss: 0.1982, Total Loss: 666.6226\n",
      "Epoch 3/10, Batch 1860/4401, Batch Loss: 0.4489, Total Loss: 670.3382\n",
      "Epoch 3/10, Batch 1870/4401, Batch Loss: 0.4540, Total Loss: 673.5198\n",
      "Epoch 3/10, Batch 1880/4401, Batch Loss: 0.5889, Total Loss: 677.1428\n",
      "Epoch 3/10, Batch 1890/4401, Batch Loss: 0.4452, Total Loss: 680.2188\n",
      "Epoch 3/10, Batch 1900/4401, Batch Loss: 0.8388, Total Loss: 683.5711\n",
      "Epoch 3/10, Batch 1910/4401, Batch Loss: 0.0572, Total Loss: 687.7226\n",
      "Epoch 3/10, Batch 1920/4401, Batch Loss: 0.2049, Total Loss: 690.4790\n",
      "Epoch 3/10, Batch 1930/4401, Batch Loss: 0.4768, Total Loss: 694.0159\n",
      "Epoch 3/10, Batch 1940/4401, Batch Loss: 0.3570, Total Loss: 697.8264\n",
      "Epoch 3/10, Batch 1950/4401, Batch Loss: 0.2493, Total Loss: 700.6210\n",
      "Epoch 3/10, Batch 1960/4401, Batch Loss: 0.0592, Total Loss: 704.7658\n",
      "Epoch 3/10, Batch 1970/4401, Batch Loss: 0.1729, Total Loss: 707.8427\n",
      "Epoch 3/10, Batch 1980/4401, Batch Loss: 0.0751, Total Loss: 709.9092\n",
      "Epoch 3/10, Batch 1990/4401, Batch Loss: 0.1886, Total Loss: 712.3455\n",
      "Epoch 3/10, Batch 2000/4401, Batch Loss: 0.4556, Total Loss: 717.5506\n",
      "Epoch 3/10, Batch 2010/4401, Batch Loss: 0.2516, Total Loss: 720.8416\n",
      "Epoch 3/10, Batch 2020/4401, Batch Loss: 0.9713, Total Loss: 725.2289\n",
      "Epoch 3/10, Batch 2030/4401, Batch Loss: 0.1100, Total Loss: 727.4466\n",
      "Epoch 3/10, Batch 2040/4401, Batch Loss: 0.8236, Total Loss: 731.3469\n",
      "Epoch 3/10, Batch 2050/4401, Batch Loss: 0.0315, Total Loss: 735.4288\n",
      "Epoch 3/10, Batch 2060/4401, Batch Loss: 0.1452, Total Loss: 738.6142\n",
      "Epoch 3/10, Batch 2070/4401, Batch Loss: 0.2337, Total Loss: 743.7333\n",
      "Epoch 3/10, Batch 2080/4401, Batch Loss: 0.6228, Total Loss: 748.1460\n",
      "Epoch 3/10, Batch 2090/4401, Batch Loss: 0.4812, Total Loss: 752.0978\n",
      "Epoch 3/10, Batch 2100/4401, Batch Loss: 0.4259, Total Loss: 756.2517\n",
      "Epoch 3/10, Batch 2110/4401, Batch Loss: 0.5104, Total Loss: 759.6377\n",
      "Epoch 3/10, Batch 2120/4401, Batch Loss: 0.6410, Total Loss: 763.4463\n",
      "Epoch 3/10, Batch 2130/4401, Batch Loss: 0.1540, Total Loss: 767.4071\n",
      "Epoch 3/10, Batch 2140/4401, Batch Loss: 0.2942, Total Loss: 772.9327\n",
      "Epoch 3/10, Batch 2150/4401, Batch Loss: 0.3914, Total Loss: 776.2257\n",
      "Epoch 3/10, Batch 2160/4401, Batch Loss: 0.1192, Total Loss: 780.1186\n",
      "Epoch 3/10, Batch 2170/4401, Batch Loss: 0.3839, Total Loss: 782.8224\n",
      "Epoch 3/10, Batch 2180/4401, Batch Loss: 0.1306, Total Loss: 786.5082\n",
      "Epoch 3/10, Batch 2190/4401, Batch Loss: 0.2856, Total Loss: 789.4664\n",
      "Epoch 3/10, Batch 2200/4401, Batch Loss: 0.2493, Total Loss: 792.6276\n",
      "Epoch 3/10, Batch 2210/4401, Batch Loss: 0.2566, Total Loss: 795.9653\n",
      "Epoch 3/10, Batch 2220/4401, Batch Loss: 0.2062, Total Loss: 799.2492\n",
      "Epoch 3/10, Batch 2230/4401, Batch Loss: 0.2630, Total Loss: 801.6835\n",
      "Epoch 3/10, Batch 2240/4401, Batch Loss: 0.0894, Total Loss: 804.0162\n",
      "Epoch 3/10, Batch 2250/4401, Batch Loss: 0.1689, Total Loss: 806.5691\n",
      "Epoch 3/10, Batch 2260/4401, Batch Loss: 0.6528, Total Loss: 809.8311\n",
      "Epoch 3/10, Batch 2270/4401, Batch Loss: 0.3231, Total Loss: 814.6777\n",
      "Epoch 3/10, Batch 2280/4401, Batch Loss: 0.3978, Total Loss: 818.6768\n",
      "Epoch 3/10, Batch 2290/4401, Batch Loss: 1.0426, Total Loss: 822.1740\n",
      "Epoch 3/10, Batch 2300/4401, Batch Loss: 0.2341, Total Loss: 829.0647\n",
      "Epoch 3/10, Batch 2310/4401, Batch Loss: 0.6159, Total Loss: 833.2823\n",
      "Epoch 3/10, Batch 2320/4401, Batch Loss: 0.3844, Total Loss: 836.5752\n",
      "Epoch 3/10, Batch 2330/4401, Batch Loss: 0.1826, Total Loss: 839.1448\n",
      "Epoch 3/10, Batch 2340/4401, Batch Loss: 0.2458, Total Loss: 842.2461\n",
      "Epoch 3/10, Batch 2350/4401, Batch Loss: 0.3207, Total Loss: 845.5812\n",
      "Epoch 3/10, Batch 2360/4401, Batch Loss: 0.1398, Total Loss: 847.8837\n",
      "Epoch 3/10, Batch 2370/4401, Batch Loss: 0.1335, Total Loss: 850.1936\n",
      "Epoch 3/10, Batch 2380/4401, Batch Loss: 0.3256, Total Loss: 853.2133\n",
      "Epoch 3/10, Batch 2390/4401, Batch Loss: 0.2627, Total Loss: 856.1882\n",
      "Epoch 3/10, Batch 2400/4401, Batch Loss: 0.3436, Total Loss: 858.9438\n",
      "Epoch 3/10, Batch 2410/4401, Batch Loss: 0.2294, Total Loss: 863.8188\n",
      "Epoch 3/10, Batch 2420/4401, Batch Loss: 0.6746, Total Loss: 869.1419\n",
      "Epoch 3/10, Batch 2430/4401, Batch Loss: 0.3896, Total Loss: 872.4933\n",
      "Epoch 3/10, Batch 2440/4401, Batch Loss: 0.8651, Total Loss: 875.8365\n",
      "Epoch 3/10, Batch 2450/4401, Batch Loss: 0.2927, Total Loss: 878.9374\n",
      "Epoch 3/10, Batch 2460/4401, Batch Loss: 0.2357, Total Loss: 880.8302\n",
      "Epoch 3/10, Batch 2470/4401, Batch Loss: 0.2575, Total Loss: 884.0328\n",
      "Epoch 3/10, Batch 2480/4401, Batch Loss: 0.5056, Total Loss: 886.5999\n",
      "Epoch 3/10, Batch 2490/4401, Batch Loss: 0.5981, Total Loss: 889.9930\n",
      "Epoch 3/10, Batch 2500/4401, Batch Loss: 0.2439, Total Loss: 893.8445\n",
      "Epoch 3/10, Batch 2510/4401, Batch Loss: 0.3216, Total Loss: 896.6918\n",
      "Epoch 3/10, Batch 2520/4401, Batch Loss: 0.4641, Total Loss: 901.6721\n",
      "Epoch 3/10, Batch 2530/4401, Batch Loss: 0.9333, Total Loss: 905.4469\n",
      "Epoch 3/10, Batch 2540/4401, Batch Loss: 0.2169, Total Loss: 908.4384\n",
      "Epoch 3/10, Batch 2550/4401, Batch Loss: 0.4172, Total Loss: 912.1282\n",
      "Epoch 3/10, Batch 2560/4401, Batch Loss: 0.2856, Total Loss: 915.4241\n",
      "Epoch 3/10, Batch 2570/4401, Batch Loss: 0.1604, Total Loss: 919.8985\n",
      "Epoch 3/10, Batch 2580/4401, Batch Loss: 0.2268, Total Loss: 922.8713\n",
      "Epoch 3/10, Batch 2590/4401, Batch Loss: 0.1794, Total Loss: 926.6404\n",
      "Epoch 3/10, Batch 2600/4401, Batch Loss: 0.2479, Total Loss: 929.7147\n",
      "Epoch 3/10, Batch 2610/4401, Batch Loss: 0.4569, Total Loss: 933.3419\n",
      "Epoch 3/10, Batch 2620/4401, Batch Loss: 0.3492, Total Loss: 936.9749\n",
      "Epoch 3/10, Batch 2630/4401, Batch Loss: 0.4866, Total Loss: 939.2798\n",
      "Epoch 3/10, Batch 2640/4401, Batch Loss: 0.2479, Total Loss: 942.3701\n",
      "Epoch 3/10, Batch 2650/4401, Batch Loss: 0.0889, Total Loss: 944.2778\n",
      "Epoch 3/10, Batch 2660/4401, Batch Loss: 0.1738, Total Loss: 947.4553\n",
      "Epoch 3/10, Batch 2670/4401, Batch Loss: 1.2790, Total Loss: 950.8770\n",
      "Epoch 3/10, Batch 2680/4401, Batch Loss: 0.0089, Total Loss: 952.8626\n",
      "Epoch 3/10, Batch 2690/4401, Batch Loss: 0.0981, Total Loss: 956.2613\n",
      "Epoch 3/10, Batch 2700/4401, Batch Loss: 0.0899, Total Loss: 958.6980\n",
      "Epoch 3/10, Batch 2710/4401, Batch Loss: 0.3223, Total Loss: 962.8335\n",
      "Epoch 3/10, Batch 2720/4401, Batch Loss: 0.4803, Total Loss: 966.4727\n",
      "Epoch 3/10, Batch 2730/4401, Batch Loss: 0.2224, Total Loss: 970.7971\n",
      "Epoch 3/10, Batch 2740/4401, Batch Loss: 0.3098, Total Loss: 973.9631\n",
      "Epoch 3/10, Batch 2750/4401, Batch Loss: 0.1039, Total Loss: 977.4206\n",
      "Epoch 3/10, Batch 2760/4401, Batch Loss: 0.0717, Total Loss: 980.7291\n",
      "Epoch 3/10, Batch 2770/4401, Batch Loss: 0.2761, Total Loss: 984.6497\n",
      "Epoch 3/10, Batch 2780/4401, Batch Loss: 0.4205, Total Loss: 989.2524\n",
      "Epoch 3/10, Batch 2790/4401, Batch Loss: 0.2786, Total Loss: 994.3017\n",
      "Epoch 3/10, Batch 2800/4401, Batch Loss: 0.5194, Total Loss: 998.9693\n",
      "Epoch 3/10, Batch 2810/4401, Batch Loss: 0.6300, Total Loss: 1002.0062\n",
      "Epoch 3/10, Batch 2820/4401, Batch Loss: 0.3653, Total Loss: 1005.8499\n",
      "Epoch 3/10, Batch 2830/4401, Batch Loss: 0.4357, Total Loss: 1011.7359\n",
      "Epoch 3/10, Batch 2840/4401, Batch Loss: 0.2704, Total Loss: 1016.5953\n",
      "Epoch 3/10, Batch 2850/4401, Batch Loss: 0.2128, Total Loss: 1020.9878\n",
      "Epoch 3/10, Batch 2860/4401, Batch Loss: 0.2334, Total Loss: 1023.2875\n",
      "Epoch 3/10, Batch 2870/4401, Batch Loss: 0.0552, Total Loss: 1027.7368\n",
      "Epoch 3/10, Batch 2880/4401, Batch Loss: 0.3031, Total Loss: 1031.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 2890/4401, Batch Loss: 0.1712, Total Loss: 1034.1323\n",
      "Epoch 3/10, Batch 2900/4401, Batch Loss: 0.1846, Total Loss: 1038.7316\n",
      "Epoch 3/10, Batch 2910/4401, Batch Loss: 0.3611, Total Loss: 1042.1728\n",
      "Epoch 3/10, Batch 2920/4401, Batch Loss: 0.3013, Total Loss: 1045.0071\n",
      "Epoch 3/10, Batch 2930/4401, Batch Loss: 0.5579, Total Loss: 1048.2198\n",
      "Epoch 3/10, Batch 2940/4401, Batch Loss: 0.5638, Total Loss: 1053.3849\n",
      "Epoch 3/10, Batch 2950/4401, Batch Loss: 0.2468, Total Loss: 1056.9828\n",
      "Epoch 3/10, Batch 2960/4401, Batch Loss: 0.7673, Total Loss: 1061.5293\n",
      "Epoch 3/10, Batch 2970/4401, Batch Loss: 0.3073, Total Loss: 1064.3781\n",
      "Epoch 3/10, Batch 2980/4401, Batch Loss: 0.4264, Total Loss: 1068.2971\n",
      "Epoch 3/10, Batch 2990/4401, Batch Loss: 0.1712, Total Loss: 1071.4011\n",
      "Epoch 3/10, Batch 3000/4401, Batch Loss: 0.2133, Total Loss: 1074.6570\n",
      "Epoch 3/10, Batch 3010/4401, Batch Loss: 0.3205, Total Loss: 1077.4004\n",
      "Epoch 3/10, Batch 3020/4401, Batch Loss: 0.2911, Total Loss: 1080.2927\n",
      "Epoch 3/10, Batch 3030/4401, Batch Loss: 0.0910, Total Loss: 1084.8185\n",
      "Epoch 3/10, Batch 3040/4401, Batch Loss: 0.1687, Total Loss: 1087.8383\n",
      "Epoch 3/10, Batch 3050/4401, Batch Loss: 0.7122, Total Loss: 1090.9483\n",
      "Epoch 3/10, Batch 3060/4401, Batch Loss: 0.4869, Total Loss: 1094.7646\n",
      "Epoch 3/10, Batch 3070/4401, Batch Loss: 0.6210, Total Loss: 1098.9731\n",
      "Epoch 3/10, Batch 3080/4401, Batch Loss: 0.5428, Total Loss: 1102.3513\n",
      "Epoch 3/10, Batch 3090/4401, Batch Loss: 0.4184, Total Loss: 1106.3482\n",
      "Epoch 3/10, Batch 3100/4401, Batch Loss: 0.3462, Total Loss: 1109.5597\n",
      "Epoch 3/10, Batch 3110/4401, Batch Loss: 0.3031, Total Loss: 1113.9727\n",
      "Epoch 3/10, Batch 3120/4401, Batch Loss: 0.4029, Total Loss: 1116.6000\n",
      "Epoch 3/10, Batch 3130/4401, Batch Loss: 0.3725, Total Loss: 1120.1502\n",
      "Epoch 3/10, Batch 3140/4401, Batch Loss: 1.2860, Total Loss: 1124.6744\n",
      "Epoch 3/10, Batch 3150/4401, Batch Loss: 0.3155, Total Loss: 1129.0172\n",
      "Epoch 3/10, Batch 3160/4401, Batch Loss: 1.0786, Total Loss: 1133.3263\n",
      "Epoch 3/10, Batch 3170/4401, Batch Loss: 0.2313, Total Loss: 1136.4674\n",
      "Epoch 3/10, Batch 3180/4401, Batch Loss: 0.4239, Total Loss: 1140.0280\n",
      "Epoch 3/10, Batch 3190/4401, Batch Loss: 0.2764, Total Loss: 1142.9451\n",
      "Epoch 3/10, Batch 3200/4401, Batch Loss: 0.2389, Total Loss: 1146.1829\n",
      "Epoch 3/10, Batch 3210/4401, Batch Loss: 0.2507, Total Loss: 1149.9322\n",
      "Epoch 3/10, Batch 3220/4401, Batch Loss: 0.1533, Total Loss: 1152.8014\n",
      "Epoch 3/10, Batch 3230/4401, Batch Loss: 0.3529, Total Loss: 1156.3403\n",
      "Epoch 3/10, Batch 3240/4401, Batch Loss: 0.2452, Total Loss: 1159.3346\n",
      "Epoch 3/10, Batch 3250/4401, Batch Loss: 0.2781, Total Loss: 1162.7106\n",
      "Epoch 3/10, Batch 3260/4401, Batch Loss: 0.4215, Total Loss: 1167.2670\n",
      "Epoch 3/10, Batch 3270/4401, Batch Loss: 0.6938, Total Loss: 1172.4982\n",
      "Epoch 3/10, Batch 3280/4401, Batch Loss: 0.3589, Total Loss: 1177.0544\n",
      "Epoch 3/10, Batch 3290/4401, Batch Loss: 0.3125, Total Loss: 1180.4612\n",
      "Epoch 3/10, Batch 3300/4401, Batch Loss: 0.3240, Total Loss: 1184.0671\n",
      "Epoch 3/10, Batch 3310/4401, Batch Loss: 0.0538, Total Loss: 1187.9372\n",
      "Epoch 3/10, Batch 3320/4401, Batch Loss: 0.5362, Total Loss: 1191.7709\n",
      "Epoch 3/10, Batch 3330/4401, Batch Loss: 0.6954, Total Loss: 1196.9505\n",
      "Epoch 3/10, Batch 3340/4401, Batch Loss: 0.2230, Total Loss: 1199.3155\n",
      "Epoch 3/10, Batch 3350/4401, Batch Loss: 0.1210, Total Loss: 1203.3837\n",
      "Epoch 3/10, Batch 3360/4401, Batch Loss: 0.1306, Total Loss: 1206.8879\n",
      "Epoch 3/10, Batch 3370/4401, Batch Loss: 0.4424, Total Loss: 1211.6808\n",
      "Epoch 3/10, Batch 3380/4401, Batch Loss: 0.3553, Total Loss: 1214.9449\n",
      "Epoch 3/10, Batch 3390/4401, Batch Loss: 0.3900, Total Loss: 1219.1460\n",
      "Epoch 3/10, Batch 3400/4401, Batch Loss: 0.4003, Total Loss: 1223.2085\n",
      "Epoch 3/10, Batch 3410/4401, Batch Loss: 0.1395, Total Loss: 1226.4101\n",
      "Epoch 3/10, Batch 3420/4401, Batch Loss: 0.2647, Total Loss: 1229.8341\n",
      "Epoch 3/10, Batch 3430/4401, Batch Loss: 0.4787, Total Loss: 1233.6320\n",
      "Epoch 3/10, Batch 3440/4401, Batch Loss: 0.4401, Total Loss: 1237.3649\n",
      "Epoch 3/10, Batch 3450/4401, Batch Loss: 0.2603, Total Loss: 1241.1126\n",
      "Epoch 3/10, Batch 3460/4401, Batch Loss: 0.3311, Total Loss: 1244.0778\n",
      "Epoch 3/10, Batch 3470/4401, Batch Loss: 0.3185, Total Loss: 1247.1744\n",
      "Epoch 3/10, Batch 3480/4401, Batch Loss: 0.2098, Total Loss: 1250.7330\n",
      "Epoch 3/10, Batch 3490/4401, Batch Loss: 0.2107, Total Loss: 1253.4690\n",
      "Epoch 3/10, Batch 3500/4401, Batch Loss: 0.4404, Total Loss: 1256.7210\n",
      "Epoch 3/10, Batch 3510/4401, Batch Loss: 0.4117, Total Loss: 1259.0643\n",
      "Epoch 3/10, Batch 3520/4401, Batch Loss: 0.3316, Total Loss: 1262.7947\n",
      "Epoch 3/10, Batch 3530/4401, Batch Loss: 0.0930, Total Loss: 1265.0826\n",
      "Epoch 3/10, Batch 3540/4401, Batch Loss: 0.1039, Total Loss: 1268.2477\n",
      "Epoch 3/10, Batch 3550/4401, Batch Loss: 2.0318, Total Loss: 1273.7813\n",
      "Epoch 3/10, Batch 3560/4401, Batch Loss: 0.4749, Total Loss: 1277.7776\n",
      "Epoch 3/10, Batch 3570/4401, Batch Loss: 0.1449, Total Loss: 1281.1036\n",
      "Epoch 3/10, Batch 3580/4401, Batch Loss: 0.3737, Total Loss: 1283.2065\n",
      "Epoch 3/10, Batch 3590/4401, Batch Loss: 0.5115, Total Loss: 1286.6108\n",
      "Epoch 3/10, Batch 3600/4401, Batch Loss: 0.2738, Total Loss: 1290.6330\n",
      "Epoch 3/10, Batch 3610/4401, Batch Loss: 0.2114, Total Loss: 1293.8124\n",
      "Epoch 3/10, Batch 3620/4401, Batch Loss: 0.3377, Total Loss: 1297.6606\n",
      "Epoch 3/10, Batch 3630/4401, Batch Loss: 1.3391, Total Loss: 1302.2380\n",
      "Epoch 3/10, Batch 3640/4401, Batch Loss: 0.1911, Total Loss: 1305.1498\n",
      "Epoch 3/10, Batch 3650/4401, Batch Loss: 0.3339, Total Loss: 1308.2279\n",
      "Epoch 3/10, Batch 3660/4401, Batch Loss: 0.3287, Total Loss: 1311.3888\n",
      "Epoch 3/10, Batch 3670/4401, Batch Loss: 0.1601, Total Loss: 1314.2006\n",
      "Epoch 3/10, Batch 3680/4401, Batch Loss: 0.4038, Total Loss: 1317.7943\n",
      "Epoch 3/10, Batch 3690/4401, Batch Loss: 0.1392, Total Loss: 1321.3950\n",
      "Epoch 3/10, Batch 3700/4401, Batch Loss: 0.1994, Total Loss: 1324.8569\n",
      "Epoch 3/10, Batch 3710/4401, Batch Loss: 0.2149, Total Loss: 1328.1919\n",
      "Epoch 3/10, Batch 3720/4401, Batch Loss: 0.2491, Total Loss: 1332.3565\n",
      "Epoch 3/10, Batch 3730/4401, Batch Loss: 0.0663, Total Loss: 1334.9166\n",
      "Epoch 3/10, Batch 3740/4401, Batch Loss: 0.5061, Total Loss: 1339.2400\n",
      "Epoch 3/10, Batch 3750/4401, Batch Loss: 0.9478, Total Loss: 1342.7093\n",
      "Epoch 3/10, Batch 3760/4401, Batch Loss: 0.3819, Total Loss: 1346.9044\n",
      "Epoch 3/10, Batch 3770/4401, Batch Loss: 0.2771, Total Loss: 1349.9456\n",
      "Epoch 3/10, Batch 3780/4401, Batch Loss: 0.6221, Total Loss: 1353.5716\n",
      "Epoch 3/10, Batch 3790/4401, Batch Loss: 0.4164, Total Loss: 1357.0628\n",
      "Epoch 3/10, Batch 3800/4401, Batch Loss: 0.3460, Total Loss: 1360.4717\n",
      "Epoch 3/10, Batch 3810/4401, Batch Loss: 0.0995, Total Loss: 1363.2235\n",
      "Epoch 3/10, Batch 3820/4401, Batch Loss: 0.1831, Total Loss: 1366.5487\n",
      "Epoch 3/10, Batch 3830/4401, Batch Loss: 0.3761, Total Loss: 1369.5993\n",
      "Epoch 3/10, Batch 3840/4401, Batch Loss: 0.2985, Total Loss: 1371.9958\n",
      "Epoch 3/10, Batch 3850/4401, Batch Loss: 0.1049, Total Loss: 1375.0953\n",
      "Epoch 3/10, Batch 3860/4401, Batch Loss: 0.0417, Total Loss: 1377.6950\n",
      "Epoch 3/10, Batch 3870/4401, Batch Loss: 0.4093, Total Loss: 1380.6762\n",
      "Epoch 3/10, Batch 3880/4401, Batch Loss: 0.0455, Total Loss: 1384.6713\n",
      "Epoch 3/10, Batch 3890/4401, Batch Loss: 0.1729, Total Loss: 1388.0798\n",
      "Epoch 3/10, Batch 3900/4401, Batch Loss: 0.1625, Total Loss: 1390.7675\n",
      "Epoch 3/10, Batch 3910/4401, Batch Loss: 0.0618, Total Loss: 1393.4756\n",
      "Epoch 3/10, Batch 3920/4401, Batch Loss: 0.0843, Total Loss: 1396.3024\n",
      "Epoch 3/10, Batch 3930/4401, Batch Loss: 0.3671, Total Loss: 1400.5879\n",
      "Epoch 3/10, Batch 3940/4401, Batch Loss: 0.1153, Total Loss: 1403.8397\n",
      "Epoch 3/10, Batch 3950/4401, Batch Loss: 0.0655, Total Loss: 1406.4761\n",
      "Epoch 3/10, Batch 3960/4401, Batch Loss: 0.1530, Total Loss: 1409.8226\n",
      "Epoch 3/10, Batch 3970/4401, Batch Loss: 0.8286, Total Loss: 1413.6831\n",
      "Epoch 3/10, Batch 3980/4401, Batch Loss: 0.1479, Total Loss: 1416.1010\n",
      "Epoch 3/10, Batch 3990/4401, Batch Loss: 0.9531, Total Loss: 1421.2646\n",
      "Epoch 3/10, Batch 4000/4401, Batch Loss: 0.7156, Total Loss: 1424.6361\n",
      "Epoch 3/10, Batch 4010/4401, Batch Loss: 0.0834, Total Loss: 1428.8409\n",
      "Epoch 3/10, Batch 4020/4401, Batch Loss: 0.2041, Total Loss: 1432.4387\n",
      "Epoch 3/10, Batch 4030/4401, Batch Loss: 0.4791, Total Loss: 1435.2201\n",
      "Epoch 3/10, Batch 4040/4401, Batch Loss: 0.2263, Total Loss: 1438.5378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 4050/4401, Batch Loss: 0.1375, Total Loss: 1441.8037\n",
      "Epoch 3/10, Batch 4060/4401, Batch Loss: 0.1655, Total Loss: 1445.1289\n",
      "Epoch 3/10, Batch 4070/4401, Batch Loss: 0.0517, Total Loss: 1449.4922\n",
      "Epoch 3/10, Batch 4080/4401, Batch Loss: 0.6394, Total Loss: 1452.8505\n",
      "Epoch 3/10, Batch 4090/4401, Batch Loss: 0.3850, Total Loss: 1456.1882\n",
      "Epoch 3/10, Batch 4100/4401, Batch Loss: 0.1321, Total Loss: 1459.0027\n",
      "Epoch 3/10, Batch 4110/4401, Batch Loss: 0.5926, Total Loss: 1463.3099\n",
      "Epoch 3/10, Batch 4120/4401, Batch Loss: 0.3023, Total Loss: 1465.3076\n",
      "Epoch 3/10, Batch 4130/4401, Batch Loss: 0.6633, Total Loss: 1470.0742\n",
      "Epoch 3/10, Batch 4140/4401, Batch Loss: 0.1024, Total Loss: 1473.4647\n",
      "Epoch 3/10, Batch 4150/4401, Batch Loss: 0.4784, Total Loss: 1477.0733\n",
      "Epoch 3/10, Batch 4160/4401, Batch Loss: 0.3864, Total Loss: 1481.4001\n",
      "Epoch 3/10, Batch 4170/4401, Batch Loss: 0.8298, Total Loss: 1485.2093\n",
      "Epoch 3/10, Batch 4180/4401, Batch Loss: 0.5275, Total Loss: 1488.1870\n",
      "Epoch 3/10, Batch 4190/4401, Batch Loss: 0.2780, Total Loss: 1491.6886\n",
      "Epoch 3/10, Batch 4200/4401, Batch Loss: 0.6558, Total Loss: 1496.0765\n",
      "Epoch 3/10, Batch 4210/4401, Batch Loss: 0.1469, Total Loss: 1498.5163\n",
      "Epoch 3/10, Batch 4220/4401, Batch Loss: 0.1277, Total Loss: 1502.4723\n",
      "Epoch 3/10, Batch 4230/4401, Batch Loss: 0.2478, Total Loss: 1505.4004\n",
      "Epoch 3/10, Batch 4240/4401, Batch Loss: 0.1945, Total Loss: 1508.0082\n",
      "Epoch 3/10, Batch 4250/4401, Batch Loss: 0.2866, Total Loss: 1511.5150\n",
      "Epoch 3/10, Batch 4260/4401, Batch Loss: 0.0826, Total Loss: 1514.4388\n",
      "Epoch 3/10, Batch 4270/4401, Batch Loss: 0.3184, Total Loss: 1519.2595\n",
      "Epoch 3/10, Batch 4280/4401, Batch Loss: 0.3706, Total Loss: 1522.6500\n",
      "Epoch 3/10, Batch 4290/4401, Batch Loss: 1.0611, Total Loss: 1527.1535\n",
      "Epoch 3/10, Batch 4300/4401, Batch Loss: 0.2897, Total Loss: 1530.9497\n",
      "Epoch 3/10, Batch 4310/4401, Batch Loss: 0.6064, Total Loss: 1534.0988\n",
      "Epoch 3/10, Batch 4320/4401, Batch Loss: 0.2652, Total Loss: 1539.3474\n",
      "Epoch 3/10, Batch 4330/4401, Batch Loss: 0.3060, Total Loss: 1544.0774\n",
      "Epoch 3/10, Batch 4340/4401, Batch Loss: 0.5642, Total Loss: 1548.2242\n",
      "Epoch 3/10, Batch 4350/4401, Batch Loss: 0.2321, Total Loss: 1552.0714\n",
      "Epoch 3/10, Batch 4360/4401, Batch Loss: 0.2201, Total Loss: 1554.7543\n",
      "Epoch 3/10, Batch 4370/4401, Batch Loss: 0.3946, Total Loss: 1558.2821\n",
      "Epoch 3/10, Batch 4380/4401, Batch Loss: 0.5707, Total Loss: 1561.0850\n",
      "Epoch 3/10, Batch 4390/4401, Batch Loss: 0.1414, Total Loss: 1564.7218\n",
      "Epoch 3/10, Batch 4400/4401, Batch Loss: 0.9128, Total Loss: 1568.0916\n",
      "Epoch 3/10, Batch 4401/4401, Batch Loss: 0.0301, Total Loss: 1568.1217\n",
      "Epoch 3/10 completed. Total Loss: 1568.1217\n",
      "\n",
      "Epoch 4/10 running...\n",
      "cuda:0\n",
      "Epoch 4/10, Batch 10/4401, Batch Loss: 0.3053, Total Loss: 2.9711\n",
      "Epoch 4/10, Batch 20/4401, Batch Loss: 0.0509, Total Loss: 7.1914\n",
      "Epoch 4/10, Batch 30/4401, Batch Loss: 0.2721, Total Loss: 10.2722\n",
      "Epoch 4/10, Batch 40/4401, Batch Loss: 0.1417, Total Loss: 11.7771\n",
      "Epoch 4/10, Batch 50/4401, Batch Loss: 0.2708, Total Loss: 15.0870\n",
      "Epoch 4/10, Batch 60/4401, Batch Loss: 0.5431, Total Loss: 19.7994\n",
      "Epoch 4/10, Batch 70/4401, Batch Loss: 0.2928, Total Loss: 22.6597\n",
      "Epoch 4/10, Batch 80/4401, Batch Loss: 0.1573, Total Loss: 25.5470\n",
      "Epoch 4/10, Batch 90/4401, Batch Loss: 0.1308, Total Loss: 27.5791\n",
      "Epoch 4/10, Batch 100/4401, Batch Loss: 0.5467, Total Loss: 31.2480\n",
      "Epoch 4/10, Batch 110/4401, Batch Loss: 0.2298, Total Loss: 34.0269\n",
      "Epoch 4/10, Batch 120/4401, Batch Loss: 0.1956, Total Loss: 37.4392\n",
      "Epoch 4/10, Batch 130/4401, Batch Loss: 0.3073, Total Loss: 40.4803\n",
      "Epoch 4/10, Batch 140/4401, Batch Loss: 0.3884, Total Loss: 43.1235\n",
      "Epoch 4/10, Batch 150/4401, Batch Loss: 0.3540, Total Loss: 46.2112\n",
      "Epoch 4/10, Batch 160/4401, Batch Loss: 0.3604, Total Loss: 49.7184\n",
      "Epoch 4/10, Batch 170/4401, Batch Loss: 0.3012, Total Loss: 52.0347\n",
      "Epoch 4/10, Batch 180/4401, Batch Loss: 0.2367, Total Loss: 54.2897\n",
      "Epoch 4/10, Batch 190/4401, Batch Loss: 0.2441, Total Loss: 56.5052\n",
      "Epoch 4/10, Batch 200/4401, Batch Loss: 0.1069, Total Loss: 58.2433\n",
      "Epoch 4/10, Batch 210/4401, Batch Loss: 0.2029, Total Loss: 61.0344\n",
      "Epoch 4/10, Batch 220/4401, Batch Loss: 0.1146, Total Loss: 65.0654\n",
      "Epoch 4/10, Batch 230/4401, Batch Loss: 0.1383, Total Loss: 68.4113\n",
      "Epoch 4/10, Batch 240/4401, Batch Loss: 0.2647, Total Loss: 71.9667\n",
      "Epoch 4/10, Batch 250/4401, Batch Loss: 0.2136, Total Loss: 75.5303\n",
      "Epoch 4/10, Batch 260/4401, Batch Loss: 0.4217, Total Loss: 78.7401\n",
      "Epoch 4/10, Batch 270/4401, Batch Loss: 0.4468, Total Loss: 82.3244\n",
      "Epoch 4/10, Batch 280/4401, Batch Loss: 0.3787, Total Loss: 85.7634\n",
      "Epoch 4/10, Batch 290/4401, Batch Loss: 0.0666, Total Loss: 88.6870\n",
      "Epoch 4/10, Batch 300/4401, Batch Loss: 0.2959, Total Loss: 91.2101\n",
      "Epoch 4/10, Batch 310/4401, Batch Loss: 0.2177, Total Loss: 94.4188\n",
      "Epoch 4/10, Batch 320/4401, Batch Loss: 0.1664, Total Loss: 97.3882\n",
      "Epoch 4/10, Batch 330/4401, Batch Loss: 1.0227, Total Loss: 100.4856\n",
      "Epoch 4/10, Batch 340/4401, Batch Loss: 0.3780, Total Loss: 103.8050\n",
      "Epoch 4/10, Batch 350/4401, Batch Loss: 0.5661, Total Loss: 108.6200\n",
      "Epoch 4/10, Batch 360/4401, Batch Loss: 0.3813, Total Loss: 111.0785\n",
      "Epoch 4/10, Batch 370/4401, Batch Loss: 0.8580, Total Loss: 115.2417\n",
      "Epoch 4/10, Batch 380/4401, Batch Loss: 0.3914, Total Loss: 117.9444\n",
      "Epoch 4/10, Batch 390/4401, Batch Loss: 0.0460, Total Loss: 120.6555\n",
      "Epoch 4/10, Batch 400/4401, Batch Loss: 0.2619, Total Loss: 125.4332\n",
      "Epoch 4/10, Batch 410/4401, Batch Loss: 0.2306, Total Loss: 129.9697\n",
      "Epoch 4/10, Batch 420/4401, Batch Loss: 0.3391, Total Loss: 133.6441\n",
      "Epoch 4/10, Batch 430/4401, Batch Loss: 0.2368, Total Loss: 137.1550\n",
      "Epoch 4/10, Batch 440/4401, Batch Loss: 0.0737, Total Loss: 139.9825\n",
      "Epoch 4/10, Batch 450/4401, Batch Loss: 0.3943, Total Loss: 142.6871\n",
      "Epoch 4/10, Batch 460/4401, Batch Loss: 0.2840, Total Loss: 146.2439\n",
      "Epoch 4/10, Batch 470/4401, Batch Loss: 0.2371, Total Loss: 149.7392\n",
      "Epoch 4/10, Batch 480/4401, Batch Loss: 0.2615, Total Loss: 151.6341\n",
      "Epoch 4/10, Batch 490/4401, Batch Loss: 0.2901, Total Loss: 155.2137\n",
      "Epoch 4/10, Batch 500/4401, Batch Loss: 0.3255, Total Loss: 158.5446\n",
      "Epoch 4/10, Batch 510/4401, Batch Loss: 0.0602, Total Loss: 162.0839\n",
      "Epoch 4/10, Batch 520/4401, Batch Loss: 0.4863, Total Loss: 164.3544\n",
      "Epoch 4/10, Batch 530/4401, Batch Loss: 0.1068, Total Loss: 166.5936\n",
      "Epoch 4/10, Batch 540/4401, Batch Loss: 0.0130, Total Loss: 169.3339\n",
      "Epoch 4/10, Batch 550/4401, Batch Loss: 0.2500, Total Loss: 172.5365\n",
      "Epoch 4/10, Batch 560/4401, Batch Loss: 0.2109, Total Loss: 175.3289\n",
      "Epoch 4/10, Batch 570/4401, Batch Loss: 0.4228, Total Loss: 178.3057\n",
      "Epoch 4/10, Batch 580/4401, Batch Loss: 0.5752, Total Loss: 182.0104\n",
      "Epoch 4/10, Batch 590/4401, Batch Loss: 1.0658, Total Loss: 185.0445\n",
      "Epoch 4/10, Batch 600/4401, Batch Loss: 0.0768, Total Loss: 187.0077\n",
      "Epoch 4/10, Batch 610/4401, Batch Loss: 0.4222, Total Loss: 190.8804\n",
      "Epoch 4/10, Batch 620/4401, Batch Loss: 0.4328, Total Loss: 192.7179\n",
      "Epoch 4/10, Batch 630/4401, Batch Loss: 0.1292, Total Loss: 194.8012\n",
      "Epoch 4/10, Batch 640/4401, Batch Loss: 0.5927, Total Loss: 198.2578\n",
      "Epoch 4/10, Batch 650/4401, Batch Loss: 0.2108, Total Loss: 201.5572\n",
      "Epoch 4/10, Batch 660/4401, Batch Loss: 0.1902, Total Loss: 203.6553\n",
      "Epoch 4/10, Batch 670/4401, Batch Loss: 0.3488, Total Loss: 205.7742\n",
      "Epoch 4/10, Batch 680/4401, Batch Loss: 0.2517, Total Loss: 208.8202\n",
      "Epoch 4/10, Batch 690/4401, Batch Loss: 0.0688, Total Loss: 211.4003\n",
      "Epoch 4/10, Batch 700/4401, Batch Loss: 0.3846, Total Loss: 216.5883\n",
      "Epoch 4/10, Batch 710/4401, Batch Loss: 0.1475, Total Loss: 219.6992\n",
      "Epoch 4/10, Batch 720/4401, Batch Loss: 0.2649, Total Loss: 222.7535\n",
      "Epoch 4/10, Batch 730/4401, Batch Loss: 0.5668, Total Loss: 225.8247\n",
      "Epoch 4/10, Batch 740/4401, Batch Loss: 0.2629, Total Loss: 228.7452\n",
      "Epoch 4/10, Batch 750/4401, Batch Loss: 0.3776, Total Loss: 232.5408\n",
      "Epoch 4/10, Batch 760/4401, Batch Loss: 0.5054, Total Loss: 235.8722\n",
      "Epoch 4/10, Batch 770/4401, Batch Loss: 0.2896, Total Loss: 238.0480\n",
      "Epoch 4/10, Batch 780/4401, Batch Loss: 0.5723, Total Loss: 242.0530\n",
      "Epoch 4/10, Batch 790/4401, Batch Loss: 0.0733, Total Loss: 245.2855\n",
      "Epoch 4/10, Batch 800/4401, Batch Loss: 0.9339, Total Loss: 249.0766\n",
      "Epoch 4/10, Batch 810/4401, Batch Loss: 0.2936, Total Loss: 251.4326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 820/4401, Batch Loss: 0.3797, Total Loss: 254.4605\n",
      "Epoch 4/10, Batch 830/4401, Batch Loss: 0.3094, Total Loss: 257.1836\n",
      "Epoch 4/10, Batch 840/4401, Batch Loss: 0.3273, Total Loss: 260.0497\n",
      "Epoch 4/10, Batch 850/4401, Batch Loss: 0.0812, Total Loss: 263.5646\n",
      "Epoch 4/10, Batch 860/4401, Batch Loss: 0.2702, Total Loss: 268.1366\n",
      "Epoch 4/10, Batch 870/4401, Batch Loss: 0.3278, Total Loss: 271.2206\n",
      "Epoch 4/10, Batch 880/4401, Batch Loss: 0.0390, Total Loss: 273.7364\n",
      "Epoch 4/10, Batch 890/4401, Batch Loss: 0.6335, Total Loss: 278.1106\n",
      "Epoch 4/10, Batch 900/4401, Batch Loss: 1.0758, Total Loss: 282.2577\n",
      "Epoch 4/10, Batch 910/4401, Batch Loss: 0.1886, Total Loss: 285.0703\n",
      "Epoch 4/10, Batch 920/4401, Batch Loss: 0.2531, Total Loss: 287.4740\n",
      "Epoch 4/10, Batch 930/4401, Batch Loss: 0.1832, Total Loss: 290.0663\n",
      "Epoch 4/10, Batch 940/4401, Batch Loss: 0.2047, Total Loss: 292.8101\n",
      "Epoch 4/10, Batch 950/4401, Batch Loss: 0.2201, Total Loss: 296.6178\n",
      "Epoch 4/10, Batch 960/4401, Batch Loss: 0.1792, Total Loss: 300.2658\n",
      "Epoch 4/10, Batch 970/4401, Batch Loss: 0.1441, Total Loss: 303.9674\n",
      "Epoch 4/10, Batch 980/4401, Batch Loss: 0.1672, Total Loss: 307.4755\n",
      "Epoch 4/10, Batch 990/4401, Batch Loss: 0.3857, Total Loss: 310.4413\n",
      "Epoch 4/10, Batch 1000/4401, Batch Loss: 0.5938, Total Loss: 314.1878\n",
      "Epoch 4/10, Batch 1010/4401, Batch Loss: 0.3929, Total Loss: 316.7126\n",
      "Epoch 4/10, Batch 1020/4401, Batch Loss: 0.1269, Total Loss: 320.4575\n",
      "Epoch 4/10, Batch 1030/4401, Batch Loss: 0.2904, Total Loss: 323.9805\n",
      "Epoch 4/10, Batch 1040/4401, Batch Loss: 0.3430, Total Loss: 327.2485\n",
      "Epoch 4/10, Batch 1050/4401, Batch Loss: 0.2299, Total Loss: 329.3041\n",
      "Epoch 4/10, Batch 1060/4401, Batch Loss: 0.3078, Total Loss: 332.3352\n",
      "Epoch 4/10, Batch 1070/4401, Batch Loss: 0.2213, Total Loss: 336.1321\n",
      "Epoch 4/10, Batch 1080/4401, Batch Loss: 0.1859, Total Loss: 340.0452\n",
      "Epoch 4/10, Batch 1090/4401, Batch Loss: 0.6451, Total Loss: 343.4407\n",
      "Epoch 4/10, Batch 1100/4401, Batch Loss: 0.3424, Total Loss: 346.7804\n",
      "Epoch 4/10, Batch 1110/4401, Batch Loss: 0.0635, Total Loss: 348.9901\n",
      "Epoch 4/10, Batch 1120/4401, Batch Loss: 0.2894, Total Loss: 351.5819\n",
      "Epoch 4/10, Batch 1130/4401, Batch Loss: 0.3522, Total Loss: 353.8630\n",
      "Epoch 4/10, Batch 1140/4401, Batch Loss: 0.0352, Total Loss: 356.1134\n",
      "Epoch 4/10, Batch 1150/4401, Batch Loss: 0.2305, Total Loss: 357.8173\n",
      "Epoch 4/10, Batch 1160/4401, Batch Loss: 0.0687, Total Loss: 360.6260\n",
      "Epoch 4/10, Batch 1170/4401, Batch Loss: 0.0781, Total Loss: 364.4780\n",
      "Epoch 4/10, Batch 1180/4401, Batch Loss: 0.2458, Total Loss: 368.0593\n",
      "Epoch 4/10, Batch 1190/4401, Batch Loss: 0.1889, Total Loss: 371.9895\n",
      "Epoch 4/10, Batch 1200/4401, Batch Loss: 0.2752, Total Loss: 375.5746\n",
      "Epoch 4/10, Batch 1210/4401, Batch Loss: 0.1335, Total Loss: 380.3758\n",
      "Epoch 4/10, Batch 1220/4401, Batch Loss: 0.4254, Total Loss: 384.6683\n",
      "Epoch 4/10, Batch 1230/4401, Batch Loss: 0.2739, Total Loss: 387.8150\n",
      "Epoch 4/10, Batch 1240/4401, Batch Loss: 1.1620, Total Loss: 392.7797\n",
      "Epoch 4/10, Batch 1250/4401, Batch Loss: 0.1095, Total Loss: 394.5912\n",
      "Epoch 4/10, Batch 1260/4401, Batch Loss: 0.6646, Total Loss: 399.2771\n",
      "Epoch 4/10, Batch 1270/4401, Batch Loss: 0.2235, Total Loss: 402.7231\n",
      "Epoch 4/10, Batch 1280/4401, Batch Loss: 0.3051, Total Loss: 405.9212\n",
      "Epoch 4/10, Batch 1290/4401, Batch Loss: 0.3733, Total Loss: 408.6291\n",
      "Epoch 4/10, Batch 1300/4401, Batch Loss: 0.0565, Total Loss: 411.3149\n",
      "Epoch 4/10, Batch 1310/4401, Batch Loss: 0.2173, Total Loss: 415.3296\n",
      "Epoch 4/10, Batch 1320/4401, Batch Loss: 0.3185, Total Loss: 418.8901\n",
      "Epoch 4/10, Batch 1330/4401, Batch Loss: 0.0716, Total Loss: 422.3351\n",
      "Epoch 4/10, Batch 1340/4401, Batch Loss: 0.2222, Total Loss: 425.5944\n",
      "Epoch 4/10, Batch 1350/4401, Batch Loss: 0.7912, Total Loss: 429.5069\n",
      "Epoch 4/10, Batch 1360/4401, Batch Loss: 0.1211, Total Loss: 431.8541\n",
      "Epoch 4/10, Batch 1370/4401, Batch Loss: 0.3530, Total Loss: 435.2400\n",
      "Epoch 4/10, Batch 1380/4401, Batch Loss: 0.1562, Total Loss: 438.6263\n",
      "Epoch 4/10, Batch 1390/4401, Batch Loss: 0.2578, Total Loss: 442.0026\n",
      "Epoch 4/10, Batch 1400/4401, Batch Loss: 0.3339, Total Loss: 445.7477\n",
      "Epoch 4/10, Batch 1410/4401, Batch Loss: 0.1228, Total Loss: 448.8023\n",
      "Epoch 4/10, Batch 1420/4401, Batch Loss: 0.4433, Total Loss: 451.1590\n",
      "Epoch 4/10, Batch 1430/4401, Batch Loss: 0.1866, Total Loss: 454.1805\n",
      "Epoch 4/10, Batch 1440/4401, Batch Loss: 0.1493, Total Loss: 457.5275\n",
      "Epoch 4/10, Batch 1450/4401, Batch Loss: 0.6391, Total Loss: 461.2242\n",
      "Epoch 4/10, Batch 1460/4401, Batch Loss: 0.8123, Total Loss: 464.7974\n",
      "Epoch 4/10, Batch 1470/4401, Batch Loss: 0.1800, Total Loss: 467.4115\n",
      "Epoch 4/10, Batch 1480/4401, Batch Loss: 0.1107, Total Loss: 469.2413\n",
      "Epoch 4/10, Batch 1490/4401, Batch Loss: 0.2130, Total Loss: 472.8990\n",
      "Epoch 4/10, Batch 1500/4401, Batch Loss: 0.0992, Total Loss: 475.9898\n",
      "Epoch 4/10, Batch 1510/4401, Batch Loss: 1.2824, Total Loss: 480.3338\n",
      "Epoch 4/10, Batch 1520/4401, Batch Loss: 0.1881, Total Loss: 484.1642\n",
      "Epoch 4/10, Batch 1530/4401, Batch Loss: 0.3785, Total Loss: 487.1264\n",
      "Epoch 4/10, Batch 1540/4401, Batch Loss: 0.4317, Total Loss: 489.2850\n",
      "Epoch 4/10, Batch 1550/4401, Batch Loss: 0.1595, Total Loss: 492.0192\n",
      "Epoch 4/10, Batch 1560/4401, Batch Loss: 0.3623, Total Loss: 495.7712\n",
      "Epoch 4/10, Batch 1570/4401, Batch Loss: 0.1255, Total Loss: 498.7895\n",
      "Epoch 4/10, Batch 1580/4401, Batch Loss: 0.1936, Total Loss: 502.3544\n",
      "Epoch 4/10, Batch 1590/4401, Batch Loss: 0.3600, Total Loss: 504.8640\n",
      "Epoch 4/10, Batch 1600/4401, Batch Loss: 0.4203, Total Loss: 507.4129\n",
      "Epoch 4/10, Batch 1610/4401, Batch Loss: 0.1870, Total Loss: 509.8102\n",
      "Epoch 4/10, Batch 1620/4401, Batch Loss: 0.0030, Total Loss: 512.6708\n",
      "Epoch 4/10, Batch 1630/4401, Batch Loss: 1.0429, Total Loss: 516.3177\n",
      "Epoch 4/10, Batch 1640/4401, Batch Loss: 0.0338, Total Loss: 519.5010\n",
      "Epoch 4/10, Batch 1650/4401, Batch Loss: 0.5259, Total Loss: 522.0621\n",
      "Epoch 4/10, Batch 1660/4401, Batch Loss: 0.1157, Total Loss: 523.9775\n",
      "Epoch 4/10, Batch 1670/4401, Batch Loss: 0.7745, Total Loss: 527.3737\n",
      "Epoch 4/10, Batch 1680/4401, Batch Loss: 0.1540, Total Loss: 529.9941\n",
      "Epoch 4/10, Batch 1690/4401, Batch Loss: 0.1648, Total Loss: 532.1097\n",
      "Epoch 4/10, Batch 1700/4401, Batch Loss: 0.3989, Total Loss: 534.5194\n",
      "Epoch 4/10, Batch 1710/4401, Batch Loss: 0.1543, Total Loss: 537.2409\n",
      "Epoch 4/10, Batch 1720/4401, Batch Loss: 0.2871, Total Loss: 541.1519\n",
      "Epoch 4/10, Batch 1730/4401, Batch Loss: 0.0707, Total Loss: 544.0547\n",
      "Epoch 4/10, Batch 1740/4401, Batch Loss: 0.0532, Total Loss: 546.9108\n",
      "Epoch 4/10, Batch 1750/4401, Batch Loss: 0.1494, Total Loss: 550.3918\n",
      "Epoch 4/10, Batch 1760/4401, Batch Loss: 0.2344, Total Loss: 553.8331\n",
      "Epoch 4/10, Batch 1770/4401, Batch Loss: 0.3005, Total Loss: 557.1739\n",
      "Epoch 4/10, Batch 1780/4401, Batch Loss: 0.6434, Total Loss: 560.5351\n",
      "Epoch 4/10, Batch 1790/4401, Batch Loss: 0.2107, Total Loss: 564.2174\n",
      "Epoch 4/10, Batch 1800/4401, Batch Loss: 0.0734, Total Loss: 566.8249\n",
      "Epoch 4/10, Batch 1810/4401, Batch Loss: 0.6563, Total Loss: 570.7975\n",
      "Epoch 4/10, Batch 1820/4401, Batch Loss: 1.1232, Total Loss: 575.2305\n",
      "Epoch 4/10, Batch 1830/4401, Batch Loss: 0.2258, Total Loss: 578.0942\n",
      "Epoch 4/10, Batch 1840/4401, Batch Loss: 0.8747, Total Loss: 581.5459\n",
      "Epoch 4/10, Batch 1850/4401, Batch Loss: 0.4752, Total Loss: 585.3852\n",
      "Epoch 4/10, Batch 1860/4401, Batch Loss: 0.4286, Total Loss: 589.4537\n",
      "Epoch 4/10, Batch 1870/4401, Batch Loss: 0.2114, Total Loss: 592.1389\n",
      "Epoch 4/10, Batch 1880/4401, Batch Loss: 0.3924, Total Loss: 594.9924\n",
      "Epoch 4/10, Batch 1890/4401, Batch Loss: 0.4702, Total Loss: 597.1032\n",
      "Epoch 4/10, Batch 1900/4401, Batch Loss: 0.2818, Total Loss: 599.4952\n",
      "Epoch 4/10, Batch 1910/4401, Batch Loss: 0.6661, Total Loss: 602.9748\n",
      "Epoch 4/10, Batch 1920/4401, Batch Loss: 0.4843, Total Loss: 605.2458\n",
      "Epoch 4/10, Batch 1930/4401, Batch Loss: 0.1100, Total Loss: 607.8344\n",
      "Epoch 4/10, Batch 1940/4401, Batch Loss: 0.2465, Total Loss: 611.5931\n",
      "Epoch 4/10, Batch 1950/4401, Batch Loss: 0.5038, Total Loss: 615.0931\n",
      "Epoch 4/10, Batch 1960/4401, Batch Loss: 0.0707, Total Loss: 618.1084\n",
      "Epoch 4/10, Batch 1970/4401, Batch Loss: 0.5798, Total Loss: 621.3668\n",
      "Epoch 4/10, Batch 1980/4401, Batch Loss: 0.2227, Total Loss: 625.9072\n",
      "Epoch 4/10, Batch 1990/4401, Batch Loss: 0.4536, Total Loss: 628.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 2000/4401, Batch Loss: 0.0889, Total Loss: 632.1813\n",
      "Epoch 4/10, Batch 2010/4401, Batch Loss: 0.3458, Total Loss: 635.9763\n",
      "Epoch 4/10, Batch 2020/4401, Batch Loss: 0.2681, Total Loss: 638.6118\n",
      "Epoch 4/10, Batch 2030/4401, Batch Loss: 0.9246, Total Loss: 642.9874\n",
      "Epoch 4/10, Batch 2040/4401, Batch Loss: 0.1635, Total Loss: 647.0517\n",
      "Epoch 4/10, Batch 2050/4401, Batch Loss: 0.2627, Total Loss: 649.7410\n",
      "Epoch 4/10, Batch 2060/4401, Batch Loss: 0.6030, Total Loss: 653.4107\n",
      "Epoch 4/10, Batch 2070/4401, Batch Loss: 0.3506, Total Loss: 656.4939\n",
      "Epoch 4/10, Batch 2080/4401, Batch Loss: 0.1137, Total Loss: 659.9855\n",
      "Epoch 4/10, Batch 2090/4401, Batch Loss: 0.2858, Total Loss: 663.4509\n",
      "Epoch 4/10, Batch 2100/4401, Batch Loss: 0.5067, Total Loss: 666.5601\n",
      "Epoch 4/10, Batch 2110/4401, Batch Loss: 0.4476, Total Loss: 669.3746\n",
      "Epoch 4/10, Batch 2120/4401, Batch Loss: 0.4151, Total Loss: 673.6956\n",
      "Epoch 4/10, Batch 2130/4401, Batch Loss: 0.0642, Total Loss: 677.2230\n",
      "Epoch 4/10, Batch 2140/4401, Batch Loss: 0.7525, Total Loss: 680.2275\n",
      "Epoch 4/10, Batch 2150/4401, Batch Loss: 0.2684, Total Loss: 683.8200\n",
      "Epoch 4/10, Batch 2160/4401, Batch Loss: 0.4664, Total Loss: 687.2398\n",
      "Epoch 4/10, Batch 2170/4401, Batch Loss: 0.1971, Total Loss: 690.4898\n",
      "Epoch 4/10, Batch 2180/4401, Batch Loss: 0.3437, Total Loss: 693.3253\n",
      "Epoch 4/10, Batch 2190/4401, Batch Loss: 0.0541, Total Loss: 695.8385\n",
      "Epoch 4/10, Batch 2200/4401, Batch Loss: 0.3999, Total Loss: 698.8733\n",
      "Epoch 4/10, Batch 2210/4401, Batch Loss: 0.1301, Total Loss: 702.2537\n",
      "Epoch 4/10, Batch 2220/4401, Batch Loss: 0.2830, Total Loss: 705.7280\n",
      "Epoch 4/10, Batch 2230/4401, Batch Loss: 0.0034, Total Loss: 708.8587\n",
      "Epoch 4/10, Batch 2240/4401, Batch Loss: 0.1757, Total Loss: 711.6181\n",
      "Epoch 4/10, Batch 2250/4401, Batch Loss: 0.3897, Total Loss: 714.3197\n",
      "Epoch 4/10, Batch 2260/4401, Batch Loss: 0.1987, Total Loss: 717.2927\n",
      "Epoch 4/10, Batch 2270/4401, Batch Loss: 0.1492, Total Loss: 720.4229\n",
      "Epoch 4/10, Batch 2280/4401, Batch Loss: 0.3243, Total Loss: 723.3632\n",
      "Epoch 4/10, Batch 2290/4401, Batch Loss: 1.0264, Total Loss: 727.2082\n",
      "Epoch 4/10, Batch 2300/4401, Batch Loss: 0.0054, Total Loss: 730.3647\n",
      "Epoch 4/10, Batch 2310/4401, Batch Loss: 0.0598, Total Loss: 732.9446\n",
      "Epoch 4/10, Batch 2320/4401, Batch Loss: 0.1302, Total Loss: 735.2755\n",
      "Epoch 4/10, Batch 2330/4401, Batch Loss: 0.5398, Total Loss: 738.8748\n",
      "Epoch 4/10, Batch 2340/4401, Batch Loss: 0.1107, Total Loss: 741.7025\n",
      "Epoch 4/10, Batch 2350/4401, Batch Loss: 0.4517, Total Loss: 746.2219\n",
      "Epoch 4/10, Batch 2360/4401, Batch Loss: 0.4493, Total Loss: 749.1011\n",
      "Epoch 4/10, Batch 2370/4401, Batch Loss: 0.1506, Total Loss: 752.2992\n",
      "Epoch 4/10, Batch 2380/4401, Batch Loss: 0.1406, Total Loss: 755.9972\n",
      "Epoch 4/10, Batch 2390/4401, Batch Loss: 0.1301, Total Loss: 757.7888\n",
      "Epoch 4/10, Batch 2400/4401, Batch Loss: 0.3888, Total Loss: 762.1546\n",
      "Epoch 4/10, Batch 2410/4401, Batch Loss: 0.4619, Total Loss: 765.7276\n",
      "Epoch 4/10, Batch 2420/4401, Batch Loss: 0.3245, Total Loss: 768.9310\n",
      "Epoch 4/10, Batch 2430/4401, Batch Loss: 0.4577, Total Loss: 771.7249\n",
      "Epoch 4/10, Batch 2440/4401, Batch Loss: 0.2733, Total Loss: 774.6941\n",
      "Epoch 4/10, Batch 2450/4401, Batch Loss: 0.1922, Total Loss: 776.9095\n",
      "Epoch 4/10, Batch 2460/4401, Batch Loss: 0.3350, Total Loss: 780.8959\n",
      "Epoch 4/10, Batch 2470/4401, Batch Loss: 0.2323, Total Loss: 783.6244\n",
      "Epoch 4/10, Batch 2480/4401, Batch Loss: 0.1201, Total Loss: 786.2831\n",
      "Epoch 4/10, Batch 2490/4401, Batch Loss: 0.5019, Total Loss: 789.6040\n",
      "Epoch 4/10, Batch 2500/4401, Batch Loss: 0.2823, Total Loss: 791.8852\n",
      "Epoch 4/10, Batch 2510/4401, Batch Loss: 0.0960, Total Loss: 794.0002\n",
      "Epoch 4/10, Batch 2520/4401, Batch Loss: 0.3065, Total Loss: 795.9911\n",
      "Epoch 4/10, Batch 2530/4401, Batch Loss: 0.2714, Total Loss: 798.8703\n",
      "Epoch 4/10, Batch 2540/4401, Batch Loss: 0.3576, Total Loss: 802.9624\n",
      "Epoch 4/10, Batch 2550/4401, Batch Loss: 0.1565, Total Loss: 806.6412\n",
      "Epoch 4/10, Batch 2560/4401, Batch Loss: 0.3686, Total Loss: 809.6975\n",
      "Epoch 4/10, Batch 2570/4401, Batch Loss: 0.2056, Total Loss: 812.8033\n",
      "Epoch 4/10, Batch 2580/4401, Batch Loss: 0.1860, Total Loss: 817.0914\n",
      "Epoch 4/10, Batch 2590/4401, Batch Loss: 0.3337, Total Loss: 819.8249\n",
      "Epoch 4/10, Batch 2600/4401, Batch Loss: 1.0068, Total Loss: 822.6895\n",
      "Epoch 4/10, Batch 2610/4401, Batch Loss: 0.1227, Total Loss: 825.6009\n",
      "Epoch 4/10, Batch 2620/4401, Batch Loss: 0.1796, Total Loss: 827.7585\n",
      "Epoch 4/10, Batch 2630/4401, Batch Loss: 0.4318, Total Loss: 830.4391\n",
      "Epoch 4/10, Batch 2640/4401, Batch Loss: 0.2008, Total Loss: 832.7292\n",
      "Epoch 4/10, Batch 2650/4401, Batch Loss: 0.3398, Total Loss: 835.8400\n",
      "Epoch 4/10, Batch 2660/4401, Batch Loss: 0.5719, Total Loss: 839.4230\n",
      "Epoch 4/10, Batch 2670/4401, Batch Loss: 0.5163, Total Loss: 842.3457\n",
      "Epoch 4/10, Batch 2680/4401, Batch Loss: 0.2422, Total Loss: 845.1854\n",
      "Epoch 4/10, Batch 2690/4401, Batch Loss: 0.1674, Total Loss: 848.5037\n",
      "Epoch 4/10, Batch 2700/4401, Batch Loss: 1.0645, Total Loss: 852.5998\n",
      "Epoch 4/10, Batch 2710/4401, Batch Loss: 0.2073, Total Loss: 855.4755\n",
      "Epoch 4/10, Batch 2720/4401, Batch Loss: 0.5099, Total Loss: 858.3141\n",
      "Epoch 4/10, Batch 2730/4401, Batch Loss: 0.3343, Total Loss: 861.7529\n",
      "Epoch 4/10, Batch 2740/4401, Batch Loss: 0.1337, Total Loss: 864.2318\n",
      "Epoch 4/10, Batch 2750/4401, Batch Loss: 0.2438, Total Loss: 867.9209\n",
      "Epoch 4/10, Batch 2760/4401, Batch Loss: 0.4289, Total Loss: 872.1244\n",
      "Epoch 4/10, Batch 2770/4401, Batch Loss: 0.2368, Total Loss: 874.3735\n",
      "Epoch 4/10, Batch 2780/4401, Batch Loss: 0.4150, Total Loss: 878.1269\n",
      "Epoch 4/10, Batch 2790/4401, Batch Loss: 0.3721, Total Loss: 881.0689\n",
      "Epoch 4/10, Batch 2800/4401, Batch Loss: 0.3432, Total Loss: 883.3084\n",
      "Epoch 4/10, Batch 2810/4401, Batch Loss: 0.5785, Total Loss: 887.1777\n",
      "Epoch 4/10, Batch 2820/4401, Batch Loss: 0.4853, Total Loss: 890.8071\n",
      "Epoch 4/10, Batch 2830/4401, Batch Loss: 0.1277, Total Loss: 893.9507\n",
      "Epoch 4/10, Batch 2840/4401, Batch Loss: 0.4734, Total Loss: 896.8672\n",
      "Epoch 4/10, Batch 2850/4401, Batch Loss: 0.6680, Total Loss: 900.6213\n",
      "Epoch 4/10, Batch 2860/4401, Batch Loss: 0.2362, Total Loss: 904.8511\n",
      "Epoch 4/10, Batch 2870/4401, Batch Loss: 0.1261, Total Loss: 907.3359\n",
      "Epoch 4/10, Batch 2880/4401, Batch Loss: 0.8168, Total Loss: 910.3472\n",
      "Epoch 4/10, Batch 2890/4401, Batch Loss: 0.3524, Total Loss: 913.1665\n",
      "Epoch 4/10, Batch 2900/4401, Batch Loss: 0.3003, Total Loss: 916.0257\n",
      "Epoch 4/10, Batch 2910/4401, Batch Loss: 0.2140, Total Loss: 918.1834\n",
      "Epoch 4/10, Batch 2920/4401, Batch Loss: 0.2240, Total Loss: 921.3349\n",
      "Epoch 4/10, Batch 2930/4401, Batch Loss: 0.0449, Total Loss: 924.4112\n",
      "Epoch 4/10, Batch 2940/4401, Batch Loss: 0.0615, Total Loss: 928.4682\n",
      "Epoch 4/10, Batch 2950/4401, Batch Loss: 0.1222, Total Loss: 930.2627\n",
      "Epoch 4/10, Batch 2960/4401, Batch Loss: 0.1603, Total Loss: 933.2438\n",
      "Epoch 4/10, Batch 2970/4401, Batch Loss: 0.4306, Total Loss: 936.6934\n",
      "Epoch 4/10, Batch 2980/4401, Batch Loss: 0.3233, Total Loss: 939.2868\n",
      "Epoch 4/10, Batch 2990/4401, Batch Loss: 0.6700, Total Loss: 943.3169\n",
      "Epoch 4/10, Batch 3000/4401, Batch Loss: 0.2739, Total Loss: 945.9089\n",
      "Epoch 4/10, Batch 3010/4401, Batch Loss: 0.3206, Total Loss: 949.0969\n",
      "Epoch 4/10, Batch 3020/4401, Batch Loss: 0.0925, Total Loss: 953.5643\n",
      "Epoch 4/10, Batch 3030/4401, Batch Loss: 0.0173, Total Loss: 956.0206\n",
      "Epoch 4/10, Batch 3040/4401, Batch Loss: 0.2885, Total Loss: 959.3821\n",
      "Epoch 4/10, Batch 3050/4401, Batch Loss: 0.9508, Total Loss: 962.7206\n",
      "Epoch 4/10, Batch 3060/4401, Batch Loss: 0.9902, Total Loss: 965.7326\n",
      "Epoch 4/10, Batch 3070/4401, Batch Loss: 0.4652, Total Loss: 969.0065\n",
      "Epoch 4/10, Batch 3080/4401, Batch Loss: 0.2346, Total Loss: 971.9265\n",
      "Epoch 4/10, Batch 3090/4401, Batch Loss: 0.1929, Total Loss: 975.4073\n",
      "Epoch 4/10, Batch 3100/4401, Batch Loss: 0.1791, Total Loss: 978.5380\n",
      "Epoch 4/10, Batch 3110/4401, Batch Loss: 0.3763, Total Loss: 981.3276\n",
      "Epoch 4/10, Batch 3120/4401, Batch Loss: 0.1282, Total Loss: 984.1425\n",
      "Epoch 4/10, Batch 3130/4401, Batch Loss: 0.4727, Total Loss: 988.1087\n",
      "Epoch 4/10, Batch 3140/4401, Batch Loss: 0.3459, Total Loss: 991.0566\n",
      "Epoch 4/10, Batch 3150/4401, Batch Loss: 0.4429, Total Loss: 993.8512\n",
      "Epoch 4/10, Batch 3160/4401, Batch Loss: 0.0164, Total Loss: 998.1461\n",
      "Epoch 4/10, Batch 3170/4401, Batch Loss: 0.2693, Total Loss: 1001.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 3180/4401, Batch Loss: 0.1254, Total Loss: 1004.0388\n",
      "Epoch 4/10, Batch 3190/4401, Batch Loss: 0.3141, Total Loss: 1007.5125\n",
      "Epoch 4/10, Batch 3200/4401, Batch Loss: 0.2862, Total Loss: 1009.2741\n",
      "Epoch 4/10, Batch 3210/4401, Batch Loss: 0.2653, Total Loss: 1012.2777\n",
      "Epoch 4/10, Batch 3220/4401, Batch Loss: 0.8325, Total Loss: 1015.3341\n",
      "Epoch 4/10, Batch 3230/4401, Batch Loss: 0.1566, Total Loss: 1018.3912\n",
      "Epoch 4/10, Batch 3240/4401, Batch Loss: 0.4156, Total Loss: 1021.2451\n",
      "Epoch 4/10, Batch 3250/4401, Batch Loss: 0.5552, Total Loss: 1024.5663\n",
      "Epoch 4/10, Batch 3260/4401, Batch Loss: 0.0575, Total Loss: 1026.3928\n",
      "Epoch 4/10, Batch 3270/4401, Batch Loss: 0.4983, Total Loss: 1029.4755\n",
      "Epoch 4/10, Batch 3280/4401, Batch Loss: 0.4266, Total Loss: 1032.1149\n",
      "Epoch 4/10, Batch 3290/4401, Batch Loss: 0.2186, Total Loss: 1034.2251\n",
      "Epoch 4/10, Batch 3300/4401, Batch Loss: 0.0486, Total Loss: 1037.3097\n",
      "Epoch 4/10, Batch 3310/4401, Batch Loss: 0.1364, Total Loss: 1039.6316\n",
      "Epoch 4/10, Batch 3320/4401, Batch Loss: 0.5428, Total Loss: 1043.6308\n",
      "Epoch 4/10, Batch 3330/4401, Batch Loss: 0.6314, Total Loss: 1046.1479\n",
      "Epoch 4/10, Batch 3340/4401, Batch Loss: 0.4348, Total Loss: 1049.0896\n",
      "Epoch 4/10, Batch 3350/4401, Batch Loss: 0.2527, Total Loss: 1052.4470\n",
      "Epoch 4/10, Batch 3360/4401, Batch Loss: 0.1982, Total Loss: 1055.8071\n",
      "Epoch 4/10, Batch 3370/4401, Batch Loss: 0.3291, Total Loss: 1060.8003\n",
      "Epoch 4/10, Batch 3380/4401, Batch Loss: 0.2032, Total Loss: 1063.8819\n",
      "Epoch 4/10, Batch 3390/4401, Batch Loss: 0.2051, Total Loss: 1066.3270\n",
      "Epoch 4/10, Batch 3400/4401, Batch Loss: 0.2296, Total Loss: 1069.5736\n",
      "Epoch 4/10, Batch 3410/4401, Batch Loss: 0.2294, Total Loss: 1074.0746\n",
      "Epoch 4/10, Batch 3420/4401, Batch Loss: 0.5975, Total Loss: 1078.4453\n",
      "Epoch 4/10, Batch 3430/4401, Batch Loss: 0.0437, Total Loss: 1080.7261\n",
      "Epoch 4/10, Batch 3440/4401, Batch Loss: 0.9151, Total Loss: 1085.2878\n",
      "Epoch 4/10, Batch 3450/4401, Batch Loss: 0.2367, Total Loss: 1089.1044\n",
      "Epoch 4/10, Batch 3460/4401, Batch Loss: 0.2185, Total Loss: 1092.7580\n",
      "Epoch 4/10, Batch 3470/4401, Batch Loss: 0.2168, Total Loss: 1096.6490\n",
      "Epoch 4/10, Batch 3480/4401, Batch Loss: 0.2699, Total Loss: 1098.9593\n",
      "Epoch 4/10, Batch 3490/4401, Batch Loss: 0.0919, Total Loss: 1101.6983\n",
      "Epoch 4/10, Batch 3500/4401, Batch Loss: 0.0566, Total Loss: 1103.6973\n",
      "Epoch 4/10, Batch 3510/4401, Batch Loss: 0.6839, Total Loss: 1108.1883\n",
      "Epoch 4/10, Batch 3520/4401, Batch Loss: 0.5039, Total Loss: 1111.1306\n",
      "Epoch 4/10, Batch 3530/4401, Batch Loss: 0.1616, Total Loss: 1113.4150\n",
      "Epoch 4/10, Batch 3540/4401, Batch Loss: 0.1201, Total Loss: 1116.0347\n",
      "Epoch 4/10, Batch 3550/4401, Batch Loss: 0.0469, Total Loss: 1118.5527\n",
      "Epoch 4/10, Batch 3560/4401, Batch Loss: 0.2681, Total Loss: 1121.7969\n",
      "Epoch 4/10, Batch 3570/4401, Batch Loss: 0.1578, Total Loss: 1125.9663\n",
      "Epoch 4/10, Batch 3580/4401, Batch Loss: 1.2232, Total Loss: 1129.2849\n",
      "Epoch 4/10, Batch 3590/4401, Batch Loss: 0.2962, Total Loss: 1132.2739\n",
      "Epoch 4/10, Batch 3600/4401, Batch Loss: 0.2633, Total Loss: 1135.4385\n",
      "Epoch 4/10, Batch 3610/4401, Batch Loss: 0.0886, Total Loss: 1137.3082\n",
      "Epoch 4/10, Batch 3620/4401, Batch Loss: 0.2102, Total Loss: 1140.1351\n",
      "Epoch 4/10, Batch 3630/4401, Batch Loss: 0.0854, Total Loss: 1142.8284\n",
      "Epoch 4/10, Batch 3640/4401, Batch Loss: 0.0583, Total Loss: 1145.5570\n",
      "Epoch 4/10, Batch 3650/4401, Batch Loss: 0.1566, Total Loss: 1148.7910\n",
      "Epoch 4/10, Batch 3660/4401, Batch Loss: 0.1468, Total Loss: 1152.6317\n",
      "Epoch 4/10, Batch 3670/4401, Batch Loss: 0.3183, Total Loss: 1156.8219\n",
      "Epoch 4/10, Batch 3680/4401, Batch Loss: 0.3038, Total Loss: 1160.2473\n",
      "Epoch 4/10, Batch 3690/4401, Batch Loss: 0.5632, Total Loss: 1163.7878\n",
      "Epoch 4/10, Batch 3700/4401, Batch Loss: 0.3628, Total Loss: 1166.1406\n",
      "Epoch 4/10, Batch 3710/4401, Batch Loss: 0.3117, Total Loss: 1169.7980\n",
      "Epoch 4/10, Batch 3720/4401, Batch Loss: 0.1835, Total Loss: 1172.6775\n",
      "Epoch 4/10, Batch 3730/4401, Batch Loss: 0.3718, Total Loss: 1176.1823\n",
      "Epoch 4/10, Batch 3740/4401, Batch Loss: 0.1994, Total Loss: 1179.2285\n",
      "Epoch 4/10, Batch 3750/4401, Batch Loss: 0.9565, Total Loss: 1182.4546\n",
      "Epoch 4/10, Batch 3760/4401, Batch Loss: 0.3397, Total Loss: 1184.6976\n",
      "Epoch 4/10, Batch 3770/4401, Batch Loss: 0.3609, Total Loss: 1188.3524\n",
      "Epoch 4/10, Batch 3780/4401, Batch Loss: 0.0859, Total Loss: 1192.1583\n",
      "Epoch 4/10, Batch 3790/4401, Batch Loss: 1.0096, Total Loss: 1196.7704\n",
      "Epoch 4/10, Batch 3800/4401, Batch Loss: 0.2629, Total Loss: 1199.7258\n",
      "Epoch 4/10, Batch 3810/4401, Batch Loss: 0.2754, Total Loss: 1202.9336\n",
      "Epoch 4/10, Batch 3820/4401, Batch Loss: 0.0044, Total Loss: 1205.0502\n",
      "Epoch 4/10, Batch 3830/4401, Batch Loss: 0.1301, Total Loss: 1208.2186\n",
      "Epoch 4/10, Batch 3840/4401, Batch Loss: 0.0752, Total Loss: 1211.0941\n",
      "Epoch 4/10, Batch 3850/4401, Batch Loss: 0.2809, Total Loss: 1214.8013\n",
      "Epoch 4/10, Batch 3860/4401, Batch Loss: 0.2576, Total Loss: 1218.7914\n",
      "Epoch 4/10, Batch 3870/4401, Batch Loss: 0.3135, Total Loss: 1221.3584\n",
      "Epoch 4/10, Batch 3880/4401, Batch Loss: 0.1655, Total Loss: 1223.4229\n",
      "Epoch 4/10, Batch 3890/4401, Batch Loss: 0.1572, Total Loss: 1227.0291\n",
      "Epoch 4/10, Batch 3900/4401, Batch Loss: 0.2924, Total Loss: 1229.1785\n",
      "Epoch 4/10, Batch 3910/4401, Batch Loss: 0.6663, Total Loss: 1232.6391\n",
      "Epoch 4/10, Batch 3920/4401, Batch Loss: 0.6416, Total Loss: 1235.9746\n",
      "Epoch 4/10, Batch 3930/4401, Batch Loss: 0.2092, Total Loss: 1239.8480\n",
      "Epoch 4/10, Batch 3940/4401, Batch Loss: 0.2197, Total Loss: 1242.7360\n",
      "Epoch 4/10, Batch 3950/4401, Batch Loss: 0.2045, Total Loss: 1246.9461\n",
      "Epoch 4/10, Batch 3960/4401, Batch Loss: 0.2288, Total Loss: 1249.1443\n",
      "Epoch 4/10, Batch 3970/4401, Batch Loss: 0.0507, Total Loss: 1251.3805\n",
      "Epoch 4/10, Batch 3980/4401, Batch Loss: 0.5872, Total Loss: 1256.2658\n",
      "Epoch 4/10, Batch 3990/4401, Batch Loss: 0.4576, Total Loss: 1259.9359\n",
      "Epoch 4/10, Batch 4000/4401, Batch Loss: 0.4763, Total Loss: 1264.0238\n",
      "Epoch 4/10, Batch 4010/4401, Batch Loss: 0.2887, Total Loss: 1267.4948\n",
      "Epoch 4/10, Batch 4020/4401, Batch Loss: 0.4277, Total Loss: 1270.3768\n",
      "Epoch 4/10, Batch 4030/4401, Batch Loss: 0.2414, Total Loss: 1275.4057\n",
      "Epoch 4/10, Batch 4040/4401, Batch Loss: 0.1746, Total Loss: 1277.6796\n",
      "Epoch 4/10, Batch 4050/4401, Batch Loss: 0.3666, Total Loss: 1280.1437\n",
      "Epoch 4/10, Batch 4060/4401, Batch Loss: 0.5202, Total Loss: 1284.0028\n",
      "Epoch 4/10, Batch 4070/4401, Batch Loss: 0.6561, Total Loss: 1287.5805\n",
      "Epoch 4/10, Batch 4080/4401, Batch Loss: 0.2687, Total Loss: 1290.7037\n",
      "Epoch 4/10, Batch 4090/4401, Batch Loss: 0.7898, Total Loss: 1294.3326\n",
      "Epoch 4/10, Batch 4100/4401, Batch Loss: 0.0526, Total Loss: 1296.9097\n",
      "Epoch 4/10, Batch 4110/4401, Batch Loss: 0.8408, Total Loss: 1301.2948\n",
      "Epoch 4/10, Batch 4120/4401, Batch Loss: 0.5059, Total Loss: 1305.4148\n",
      "Epoch 4/10, Batch 4130/4401, Batch Loss: 0.2657, Total Loss: 1308.7606\n",
      "Epoch 4/10, Batch 4140/4401, Batch Loss: 0.2040, Total Loss: 1312.4638\n",
      "Epoch 4/10, Batch 4150/4401, Batch Loss: 0.1574, Total Loss: 1317.3143\n",
      "Epoch 4/10, Batch 4160/4401, Batch Loss: 0.3324, Total Loss: 1319.2789\n",
      "Epoch 4/10, Batch 4170/4401, Batch Loss: 0.3474, Total Loss: 1322.5259\n",
      "Epoch 4/10, Batch 4180/4401, Batch Loss: 0.5185, Total Loss: 1327.3001\n",
      "Epoch 4/10, Batch 4190/4401, Batch Loss: 0.6227, Total Loss: 1331.4173\n",
      "Epoch 4/10, Batch 4200/4401, Batch Loss: 0.3350, Total Loss: 1335.2845\n",
      "Epoch 4/10, Batch 4210/4401, Batch Loss: 0.3765, Total Loss: 1338.8065\n",
      "Epoch 4/10, Batch 4220/4401, Batch Loss: 0.2093, Total Loss: 1342.0924\n",
      "Epoch 4/10, Batch 4230/4401, Batch Loss: 0.1993, Total Loss: 1345.6126\n",
      "Epoch 4/10, Batch 4240/4401, Batch Loss: 0.9630, Total Loss: 1348.9164\n",
      "Epoch 4/10, Batch 4250/4401, Batch Loss: 0.1153, Total Loss: 1351.5163\n",
      "Epoch 4/10, Batch 4260/4401, Batch Loss: 0.5475, Total Loss: 1354.3880\n",
      "Epoch 4/10, Batch 4270/4401, Batch Loss: 0.0947, Total Loss: 1357.4150\n",
      "Epoch 4/10, Batch 4280/4401, Batch Loss: 0.5481, Total Loss: 1360.0783\n",
      "Epoch 4/10, Batch 4290/4401, Batch Loss: 0.0401, Total Loss: 1363.4423\n",
      "Epoch 4/10, Batch 4300/4401, Batch Loss: 0.4894, Total Loss: 1366.9731\n",
      "Epoch 4/10, Batch 4310/4401, Batch Loss: 0.2981, Total Loss: 1370.2751\n",
      "Epoch 4/10, Batch 4320/4401, Batch Loss: 0.4572, Total Loss: 1372.5728\n",
      "Epoch 4/10, Batch 4330/4401, Batch Loss: 0.1279, Total Loss: 1376.6645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 4340/4401, Batch Loss: 0.3909, Total Loss: 1379.7068\n",
      "Epoch 4/10, Batch 4350/4401, Batch Loss: 0.2715, Total Loss: 1382.3848\n",
      "Epoch 4/10, Batch 4360/4401, Batch Loss: 0.8107, Total Loss: 1385.3088\n",
      "Epoch 4/10, Batch 4370/4401, Batch Loss: 0.0987, Total Loss: 1387.5362\n",
      "Epoch 4/10, Batch 4380/4401, Batch Loss: 0.6745, Total Loss: 1391.4438\n",
      "Epoch 4/10, Batch 4390/4401, Batch Loss: 0.2374, Total Loss: 1394.2412\n",
      "Epoch 4/10, Batch 4400/4401, Batch Loss: 0.3756, Total Loss: 1397.4668\n",
      "Epoch 4/10, Batch 4401/4401, Batch Loss: 0.0388, Total Loss: 1397.5056\n",
      "Epoch 4/10 completed. Total Loss: 1397.5056\n",
      "\n",
      "Epoch 5/10 running...\n",
      "cuda:0\n",
      "Epoch 5/10, Batch 10/4401, Batch Loss: 1.0738, Total Loss: 3.0276\n",
      "Epoch 5/10, Batch 20/4401, Batch Loss: 0.5579, Total Loss: 5.8402\n",
      "Epoch 5/10, Batch 30/4401, Batch Loss: 0.1584, Total Loss: 8.2013\n",
      "Epoch 5/10, Batch 40/4401, Batch Loss: 0.2933, Total Loss: 10.8200\n",
      "Epoch 5/10, Batch 50/4401, Batch Loss: 0.2193, Total Loss: 13.7209\n",
      "Epoch 5/10, Batch 60/4401, Batch Loss: 0.3106, Total Loss: 15.9054\n",
      "Epoch 5/10, Batch 70/4401, Batch Loss: 0.0608, Total Loss: 18.9584\n",
      "Epoch 5/10, Batch 80/4401, Batch Loss: 0.3494, Total Loss: 21.5504\n",
      "Epoch 5/10, Batch 90/4401, Batch Loss: 0.0791, Total Loss: 23.8851\n",
      "Epoch 5/10, Batch 100/4401, Batch Loss: 0.0034, Total Loss: 25.2961\n",
      "Epoch 5/10, Batch 110/4401, Batch Loss: 0.8310, Total Loss: 28.0464\n",
      "Epoch 5/10, Batch 120/4401, Batch Loss: 0.3410, Total Loss: 30.9240\n",
      "Epoch 5/10, Batch 130/4401, Batch Loss: 0.0361, Total Loss: 32.7247\n",
      "Epoch 5/10, Batch 140/4401, Batch Loss: 0.6930, Total Loss: 35.7495\n",
      "Epoch 5/10, Batch 150/4401, Batch Loss: 0.1474, Total Loss: 37.8845\n",
      "Epoch 5/10, Batch 160/4401, Batch Loss: 0.3326, Total Loss: 40.2510\n",
      "Epoch 5/10, Batch 170/4401, Batch Loss: 0.0414, Total Loss: 43.1833\n",
      "Epoch 5/10, Batch 180/4401, Batch Loss: 0.2076, Total Loss: 45.9566\n",
      "Epoch 5/10, Batch 190/4401, Batch Loss: 0.2953, Total Loss: 48.9905\n",
      "Epoch 5/10, Batch 200/4401, Batch Loss: 0.0050, Total Loss: 50.2840\n",
      "Epoch 5/10, Batch 210/4401, Batch Loss: 0.2425, Total Loss: 52.9795\n",
      "Epoch 5/10, Batch 220/4401, Batch Loss: 0.2708, Total Loss: 55.9588\n",
      "Epoch 5/10, Batch 230/4401, Batch Loss: 0.1227, Total Loss: 57.4834\n",
      "Epoch 5/10, Batch 240/4401, Batch Loss: 0.4357, Total Loss: 60.6080\n",
      "Epoch 5/10, Batch 250/4401, Batch Loss: 0.0945, Total Loss: 63.4739\n",
      "Epoch 5/10, Batch 260/4401, Batch Loss: 0.2900, Total Loss: 65.7747\n",
      "Epoch 5/10, Batch 270/4401, Batch Loss: 0.3738, Total Loss: 69.7460\n",
      "Epoch 5/10, Batch 280/4401, Batch Loss: 0.1958, Total Loss: 71.9288\n",
      "Epoch 5/10, Batch 290/4401, Batch Loss: 0.6456, Total Loss: 74.8027\n",
      "Epoch 5/10, Batch 300/4401, Batch Loss: 0.4927, Total Loss: 78.5426\n",
      "Epoch 5/10, Batch 310/4401, Batch Loss: 0.1981, Total Loss: 80.6358\n",
      "Epoch 5/10, Batch 320/4401, Batch Loss: 0.2846, Total Loss: 83.0664\n",
      "Epoch 5/10, Batch 330/4401, Batch Loss: 0.0546, Total Loss: 85.6261\n",
      "Epoch 5/10, Batch 340/4401, Batch Loss: 0.0946, Total Loss: 88.4170\n",
      "Epoch 5/10, Batch 350/4401, Batch Loss: 0.1516, Total Loss: 90.5166\n",
      "Epoch 5/10, Batch 360/4401, Batch Loss: 0.1526, Total Loss: 92.8788\n",
      "Epoch 5/10, Batch 370/4401, Batch Loss: 0.3492, Total Loss: 96.4421\n",
      "Epoch 5/10, Batch 380/4401, Batch Loss: 0.0311, Total Loss: 98.3614\n",
      "Epoch 5/10, Batch 390/4401, Batch Loss: 0.5350, Total Loss: 101.6167\n",
      "Epoch 5/10, Batch 400/4401, Batch Loss: 0.2409, Total Loss: 104.1196\n",
      "Epoch 5/10, Batch 410/4401, Batch Loss: 0.3803, Total Loss: 106.6403\n",
      "Epoch 5/10, Batch 420/4401, Batch Loss: 0.4703, Total Loss: 110.8409\n",
      "Epoch 5/10, Batch 430/4401, Batch Loss: 0.3468, Total Loss: 114.0597\n",
      "Epoch 5/10, Batch 440/4401, Batch Loss: 0.5932, Total Loss: 118.4066\n",
      "Epoch 5/10, Batch 450/4401, Batch Loss: 0.0825, Total Loss: 120.6810\n",
      "Epoch 5/10, Batch 460/4401, Batch Loss: 0.2623, Total Loss: 124.4084\n",
      "Epoch 5/10, Batch 470/4401, Batch Loss: 0.1416, Total Loss: 127.4094\n",
      "Epoch 5/10, Batch 480/4401, Batch Loss: 0.3315, Total Loss: 130.5319\n",
      "Epoch 5/10, Batch 490/4401, Batch Loss: 0.3001, Total Loss: 132.4017\n",
      "Epoch 5/10, Batch 500/4401, Batch Loss: 0.2991, Total Loss: 135.9068\n",
      "Epoch 5/10, Batch 510/4401, Batch Loss: 0.0676, Total Loss: 139.5522\n",
      "Epoch 5/10, Batch 520/4401, Batch Loss: 0.1431, Total Loss: 142.9657\n",
      "Epoch 5/10, Batch 530/4401, Batch Loss: 0.6243, Total Loss: 145.5792\n",
      "Epoch 5/10, Batch 540/4401, Batch Loss: 0.0696, Total Loss: 148.1239\n",
      "Epoch 5/10, Batch 550/4401, Batch Loss: 0.2163, Total Loss: 150.4826\n",
      "Epoch 5/10, Batch 560/4401, Batch Loss: 0.6122, Total Loss: 153.2830\n",
      "Epoch 5/10, Batch 570/4401, Batch Loss: 0.2781, Total Loss: 155.6185\n",
      "Epoch 5/10, Batch 580/4401, Batch Loss: 0.3772, Total Loss: 158.6685\n",
      "Epoch 5/10, Batch 590/4401, Batch Loss: 0.4626, Total Loss: 161.1202\n",
      "Epoch 5/10, Batch 600/4401, Batch Loss: 0.1809, Total Loss: 163.7896\n",
      "Epoch 5/10, Batch 610/4401, Batch Loss: 0.0019, Total Loss: 166.1268\n",
      "Epoch 5/10, Batch 620/4401, Batch Loss: 0.1619, Total Loss: 168.2327\n",
      "Epoch 5/10, Batch 630/4401, Batch Loss: 0.0906, Total Loss: 172.2876\n",
      "Epoch 5/10, Batch 640/4401, Batch Loss: 0.4918, Total Loss: 175.1731\n",
      "Epoch 5/10, Batch 650/4401, Batch Loss: 0.1646, Total Loss: 177.4621\n",
      "Epoch 5/10, Batch 660/4401, Batch Loss: 0.4253, Total Loss: 179.9453\n",
      "Epoch 5/10, Batch 670/4401, Batch Loss: 0.2603, Total Loss: 183.5410\n",
      "Epoch 5/10, Batch 680/4401, Batch Loss: 0.2827, Total Loss: 186.1725\n",
      "Epoch 5/10, Batch 690/4401, Batch Loss: 0.3251, Total Loss: 188.6048\n",
      "Epoch 5/10, Batch 700/4401, Batch Loss: 0.5301, Total Loss: 192.2404\n",
      "Epoch 5/10, Batch 710/4401, Batch Loss: 0.2941, Total Loss: 195.9685\n",
      "Epoch 5/10, Batch 720/4401, Batch Loss: 0.1932, Total Loss: 198.7127\n",
      "Epoch 5/10, Batch 730/4401, Batch Loss: 0.1908, Total Loss: 201.2124\n",
      "Epoch 5/10, Batch 740/4401, Batch Loss: 0.3976, Total Loss: 203.8917\n",
      "Epoch 5/10, Batch 750/4401, Batch Loss: 0.2162, Total Loss: 206.2932\n",
      "Epoch 5/10, Batch 760/4401, Batch Loss: 0.2556, Total Loss: 209.7988\n",
      "Epoch 5/10, Batch 770/4401, Batch Loss: 0.0351, Total Loss: 212.7629\n",
      "Epoch 5/10, Batch 780/4401, Batch Loss: 0.1256, Total Loss: 215.9340\n",
      "Epoch 5/10, Batch 790/4401, Batch Loss: 0.2742, Total Loss: 218.6073\n",
      "Epoch 5/10, Batch 800/4401, Batch Loss: 0.0644, Total Loss: 220.9124\n",
      "Epoch 5/10, Batch 810/4401, Batch Loss: 0.1218, Total Loss: 223.8347\n",
      "Epoch 5/10, Batch 820/4401, Batch Loss: 0.1880, Total Loss: 227.1347\n",
      "Epoch 5/10, Batch 830/4401, Batch Loss: 0.3728, Total Loss: 230.8206\n",
      "Epoch 5/10, Batch 840/4401, Batch Loss: 0.3364, Total Loss: 233.6973\n",
      "Epoch 5/10, Batch 850/4401, Batch Loss: 0.2764, Total Loss: 236.3251\n",
      "Epoch 5/10, Batch 860/4401, Batch Loss: 0.0230, Total Loss: 238.8364\n",
      "Epoch 5/10, Batch 870/4401, Batch Loss: 0.5447, Total Loss: 243.2717\n",
      "Epoch 5/10, Batch 880/4401, Batch Loss: 0.4132, Total Loss: 246.5213\n",
      "Epoch 5/10, Batch 890/4401, Batch Loss: 0.4028, Total Loss: 249.9806\n",
      "Epoch 5/10, Batch 900/4401, Batch Loss: 0.3907, Total Loss: 253.5002\n",
      "Epoch 5/10, Batch 910/4401, Batch Loss: 0.0557, Total Loss: 255.9870\n",
      "Epoch 5/10, Batch 920/4401, Batch Loss: 0.1303, Total Loss: 258.8905\n",
      "Epoch 5/10, Batch 930/4401, Batch Loss: 0.0756, Total Loss: 260.6282\n",
      "Epoch 5/10, Batch 940/4401, Batch Loss: 0.0572, Total Loss: 263.6266\n",
      "Epoch 5/10, Batch 950/4401, Batch Loss: 0.2234, Total Loss: 267.5061\n",
      "Epoch 5/10, Batch 960/4401, Batch Loss: 0.2100, Total Loss: 270.0737\n",
      "Epoch 5/10, Batch 970/4401, Batch Loss: 0.3938, Total Loss: 273.4432\n",
      "Epoch 5/10, Batch 980/4401, Batch Loss: 0.1713, Total Loss: 275.4956\n",
      "Epoch 5/10, Batch 990/4401, Batch Loss: 0.7000, Total Loss: 278.2636\n",
      "Epoch 5/10, Batch 1000/4401, Batch Loss: 0.1567, Total Loss: 280.9145\n",
      "Epoch 5/10, Batch 1010/4401, Batch Loss: 0.1847, Total Loss: 284.4046\n",
      "Epoch 5/10, Batch 1020/4401, Batch Loss: 0.2379, Total Loss: 287.6890\n",
      "Epoch 5/10, Batch 1030/4401, Batch Loss: 0.2562, Total Loss: 290.6071\n",
      "Epoch 5/10, Batch 1040/4401, Batch Loss: 0.2176, Total Loss: 293.6233\n",
      "Epoch 5/10, Batch 1050/4401, Batch Loss: 0.6349, Total Loss: 297.7271\n",
      "Epoch 5/10, Batch 1060/4401, Batch Loss: 0.2448, Total Loss: 300.4573\n",
      "Epoch 5/10, Batch 1070/4401, Batch Loss: 0.4936, Total Loss: 303.3303\n",
      "Epoch 5/10, Batch 1080/4401, Batch Loss: 0.5430, Total Loss: 306.2014\n",
      "Epoch 5/10, Batch 1090/4401, Batch Loss: 0.1582, Total Loss: 309.5589\n",
      "Epoch 5/10, Batch 1100/4401, Batch Loss: 0.2289, Total Loss: 311.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1110/4401, Batch Loss: 0.2217, Total Loss: 314.3171\n",
      "Epoch 5/10, Batch 1120/4401, Batch Loss: 0.1973, Total Loss: 316.8235\n",
      "Epoch 5/10, Batch 1130/4401, Batch Loss: 0.7213, Total Loss: 319.9699\n",
      "Epoch 5/10, Batch 1140/4401, Batch Loss: 0.2134, Total Loss: 322.9184\n",
      "Epoch 5/10, Batch 1150/4401, Batch Loss: 0.4449, Total Loss: 326.4912\n",
      "Epoch 5/10, Batch 1160/4401, Batch Loss: 0.8280, Total Loss: 330.3315\n",
      "Epoch 5/10, Batch 1170/4401, Batch Loss: 0.2291, Total Loss: 333.1833\n",
      "Epoch 5/10, Batch 1180/4401, Batch Loss: 0.1379, Total Loss: 335.4855\n",
      "Epoch 5/10, Batch 1190/4401, Batch Loss: 0.4987, Total Loss: 338.4042\n",
      "Epoch 5/10, Batch 1200/4401, Batch Loss: 0.2829, Total Loss: 340.9686\n",
      "Epoch 5/10, Batch 1210/4401, Batch Loss: 0.1875, Total Loss: 344.5306\n",
      "Epoch 5/10, Batch 1220/4401, Batch Loss: 0.3080, Total Loss: 347.8765\n",
      "Epoch 5/10, Batch 1230/4401, Batch Loss: 0.2576, Total Loss: 350.1771\n",
      "Epoch 5/10, Batch 1240/4401, Batch Loss: 0.5067, Total Loss: 353.3867\n",
      "Epoch 5/10, Batch 1250/4401, Batch Loss: 0.1155, Total Loss: 355.7562\n",
      "Epoch 5/10, Batch 1260/4401, Batch Loss: 0.3605, Total Loss: 359.5515\n",
      "Epoch 5/10, Batch 1270/4401, Batch Loss: 0.1364, Total Loss: 361.8829\n",
      "Epoch 5/10, Batch 1280/4401, Batch Loss: 1.1848, Total Loss: 364.9500\n",
      "Epoch 5/10, Batch 1290/4401, Batch Loss: 0.1392, Total Loss: 367.7967\n",
      "Epoch 5/10, Batch 1300/4401, Batch Loss: 0.0558, Total Loss: 371.0754\n",
      "Epoch 5/10, Batch 1310/4401, Batch Loss: 0.2659, Total Loss: 374.6660\n",
      "Epoch 5/10, Batch 1320/4401, Batch Loss: 0.0040, Total Loss: 377.6120\n",
      "Epoch 5/10, Batch 1330/4401, Batch Loss: 0.1744, Total Loss: 380.5276\n",
      "Epoch 5/10, Batch 1340/4401, Batch Loss: 0.2822, Total Loss: 383.8103\n",
      "Epoch 5/10, Batch 1350/4401, Batch Loss: 0.1234, Total Loss: 385.9328\n",
      "Epoch 5/10, Batch 1360/4401, Batch Loss: 0.4917, Total Loss: 388.5235\n",
      "Epoch 5/10, Batch 1370/4401, Batch Loss: 0.0091, Total Loss: 391.1687\n",
      "Epoch 5/10, Batch 1380/4401, Batch Loss: 0.2066, Total Loss: 393.5894\n",
      "Epoch 5/10, Batch 1390/4401, Batch Loss: 0.2347, Total Loss: 395.7679\n",
      "Epoch 5/10, Batch 1400/4401, Batch Loss: 0.3110, Total Loss: 398.0965\n",
      "Epoch 5/10, Batch 1410/4401, Batch Loss: 0.3920, Total Loss: 401.1732\n",
      "Epoch 5/10, Batch 1420/4401, Batch Loss: 0.1761, Total Loss: 403.2683\n",
      "Epoch 5/10, Batch 1430/4401, Batch Loss: 0.1784, Total Loss: 405.4211\n",
      "Epoch 5/10, Batch 1440/4401, Batch Loss: 0.3142, Total Loss: 408.9778\n",
      "Epoch 5/10, Batch 1450/4401, Batch Loss: 0.1680, Total Loss: 411.0028\n",
      "Epoch 5/10, Batch 1460/4401, Batch Loss: 0.2442, Total Loss: 413.7805\n",
      "Epoch 5/10, Batch 1470/4401, Batch Loss: 0.1905, Total Loss: 415.6191\n",
      "Epoch 5/10, Batch 1480/4401, Batch Loss: 0.0999, Total Loss: 417.9080\n",
      "Epoch 5/10, Batch 1490/4401, Batch Loss: 0.3915, Total Loss: 419.7007\n",
      "Epoch 5/10, Batch 1500/4401, Batch Loss: 0.2624, Total Loss: 422.6831\n",
      "Epoch 5/10, Batch 1510/4401, Batch Loss: 0.1027, Total Loss: 425.0762\n",
      "Epoch 5/10, Batch 1520/4401, Batch Loss: 0.3241, Total Loss: 427.3167\n",
      "Epoch 5/10, Batch 1530/4401, Batch Loss: 0.1606, Total Loss: 430.4405\n",
      "Epoch 5/10, Batch 1540/4401, Batch Loss: 0.1407, Total Loss: 433.0593\n",
      "Epoch 5/10, Batch 1550/4401, Batch Loss: 0.2980, Total Loss: 436.0006\n",
      "Epoch 5/10, Batch 1560/4401, Batch Loss: 0.1684, Total Loss: 440.0334\n",
      "Epoch 5/10, Batch 1570/4401, Batch Loss: 0.1286, Total Loss: 442.6731\n",
      "Epoch 5/10, Batch 1580/4401, Batch Loss: 0.4208, Total Loss: 445.6101\n",
      "Epoch 5/10, Batch 1590/4401, Batch Loss: 0.1318, Total Loss: 448.2735\n",
      "Epoch 5/10, Batch 1600/4401, Batch Loss: 0.1402, Total Loss: 450.7225\n",
      "Epoch 5/10, Batch 1610/4401, Batch Loss: 0.3771, Total Loss: 453.2921\n",
      "Epoch 5/10, Batch 1620/4401, Batch Loss: 0.4877, Total Loss: 455.6462\n",
      "Epoch 5/10, Batch 1630/4401, Batch Loss: 0.1914, Total Loss: 458.2871\n",
      "Epoch 5/10, Batch 1640/4401, Batch Loss: 0.3625, Total Loss: 460.7183\n",
      "Epoch 5/10, Batch 1650/4401, Batch Loss: 0.2080, Total Loss: 463.9227\n",
      "Epoch 5/10, Batch 1660/4401, Batch Loss: 0.3538, Total Loss: 467.1667\n",
      "Epoch 5/10, Batch 1670/4401, Batch Loss: 0.4155, Total Loss: 470.2067\n",
      "Epoch 5/10, Batch 1680/4401, Batch Loss: 0.2484, Total Loss: 474.0155\n",
      "Epoch 5/10, Batch 1690/4401, Batch Loss: 0.3950, Total Loss: 477.2705\n",
      "Epoch 5/10, Batch 1700/4401, Batch Loss: 0.3705, Total Loss: 479.1209\n",
      "Epoch 5/10, Batch 1710/4401, Batch Loss: 0.1448, Total Loss: 481.7826\n",
      "Epoch 5/10, Batch 1720/4401, Batch Loss: 0.1106, Total Loss: 484.3265\n",
      "Epoch 5/10, Batch 1730/4401, Batch Loss: 0.2273, Total Loss: 487.2383\n",
      "Epoch 5/10, Batch 1740/4401, Batch Loss: 0.2968, Total Loss: 489.2936\n",
      "Epoch 5/10, Batch 1750/4401, Batch Loss: 0.1717, Total Loss: 491.9560\n",
      "Epoch 5/10, Batch 1760/4401, Batch Loss: 0.0056, Total Loss: 494.6362\n",
      "Epoch 5/10, Batch 1770/4401, Batch Loss: 0.4532, Total Loss: 496.7936\n",
      "Epoch 5/10, Batch 1780/4401, Batch Loss: 0.3253, Total Loss: 499.3647\n",
      "Epoch 5/10, Batch 1790/4401, Batch Loss: 0.5570, Total Loss: 503.1014\n",
      "Epoch 5/10, Batch 1800/4401, Batch Loss: 0.2332, Total Loss: 506.4111\n",
      "Epoch 5/10, Batch 1810/4401, Batch Loss: 0.3613, Total Loss: 508.4640\n",
      "Epoch 5/10, Batch 1820/4401, Batch Loss: 0.2504, Total Loss: 511.8336\n",
      "Epoch 5/10, Batch 1830/4401, Batch Loss: 0.4436, Total Loss: 514.2084\n",
      "Epoch 5/10, Batch 1840/4401, Batch Loss: 0.8256, Total Loss: 517.6032\n",
      "Epoch 5/10, Batch 1850/4401, Batch Loss: 0.2191, Total Loss: 520.6528\n",
      "Epoch 5/10, Batch 1860/4401, Batch Loss: 0.0529, Total Loss: 522.8016\n",
      "Epoch 5/10, Batch 1870/4401, Batch Loss: 0.3701, Total Loss: 525.8385\n",
      "Epoch 5/10, Batch 1880/4401, Batch Loss: 0.0034, Total Loss: 527.8775\n",
      "Epoch 5/10, Batch 1890/4401, Batch Loss: 0.5256, Total Loss: 530.6764\n",
      "Epoch 5/10, Batch 1900/4401, Batch Loss: 0.3011, Total Loss: 533.8006\n",
      "Epoch 5/10, Batch 1910/4401, Batch Loss: 0.4319, Total Loss: 537.9711\n",
      "Epoch 5/10, Batch 1920/4401, Batch Loss: 0.9831, Total Loss: 540.8728\n",
      "Epoch 5/10, Batch 1930/4401, Batch Loss: 0.2908, Total Loss: 543.9065\n",
      "Epoch 5/10, Batch 1940/4401, Batch Loss: 0.3597, Total Loss: 546.4015\n",
      "Epoch 5/10, Batch 1950/4401, Batch Loss: 0.5884, Total Loss: 549.6431\n",
      "Epoch 5/10, Batch 1960/4401, Batch Loss: 0.7794, Total Loss: 552.8877\n",
      "Epoch 5/10, Batch 1970/4401, Batch Loss: 0.9551, Total Loss: 556.3608\n",
      "Epoch 5/10, Batch 1980/4401, Batch Loss: 0.3269, Total Loss: 558.6082\n",
      "Epoch 5/10, Batch 1990/4401, Batch Loss: 0.2516, Total Loss: 560.7235\n",
      "Epoch 5/10, Batch 2000/4401, Batch Loss: 0.2932, Total Loss: 563.7211\n",
      "Epoch 5/10, Batch 2010/4401, Batch Loss: 0.2623, Total Loss: 568.7322\n",
      "Epoch 5/10, Batch 2020/4401, Batch Loss: 0.1750, Total Loss: 571.9193\n",
      "Epoch 5/10, Batch 2030/4401, Batch Loss: 0.1920, Total Loss: 574.9443\n",
      "Epoch 5/10, Batch 2040/4401, Batch Loss: 0.2781, Total Loss: 577.2799\n",
      "Epoch 5/10, Batch 2050/4401, Batch Loss: 0.3415, Total Loss: 579.6422\n",
      "Epoch 5/10, Batch 2060/4401, Batch Loss: 0.5136, Total Loss: 582.5814\n",
      "Epoch 5/10, Batch 2070/4401, Batch Loss: 0.0784, Total Loss: 585.8353\n",
      "Epoch 5/10, Batch 2080/4401, Batch Loss: 0.3688, Total Loss: 587.7281\n",
      "Epoch 5/10, Batch 2090/4401, Batch Loss: 0.1746, Total Loss: 589.5157\n",
      "Epoch 5/10, Batch 2100/4401, Batch Loss: 0.4715, Total Loss: 592.2343\n",
      "Epoch 5/10, Batch 2110/4401, Batch Loss: 0.3314, Total Loss: 595.3725\n",
      "Epoch 5/10, Batch 2120/4401, Batch Loss: 0.1952, Total Loss: 597.9922\n",
      "Epoch 5/10, Batch 2130/4401, Batch Loss: 1.8373, Total Loss: 601.9074\n",
      "Epoch 5/10, Batch 2140/4401, Batch Loss: 0.0472, Total Loss: 603.9202\n",
      "Epoch 5/10, Batch 2150/4401, Batch Loss: 0.3844, Total Loss: 607.2444\n",
      "Epoch 5/10, Batch 2160/4401, Batch Loss: 0.3119, Total Loss: 609.9866\n",
      "Epoch 5/10, Batch 2170/4401, Batch Loss: 0.0878, Total Loss: 611.9095\n",
      "Epoch 5/10, Batch 2180/4401, Batch Loss: 0.3304, Total Loss: 615.2753\n",
      "Epoch 5/10, Batch 2190/4401, Batch Loss: 0.2302, Total Loss: 617.8657\n",
      "Epoch 5/10, Batch 2200/4401, Batch Loss: 0.2491, Total Loss: 619.6403\n",
      "Epoch 5/10, Batch 2210/4401, Batch Loss: 0.1241, Total Loss: 622.1021\n",
      "Epoch 5/10, Batch 2220/4401, Batch Loss: 0.2141, Total Loss: 625.4502\n",
      "Epoch 5/10, Batch 2230/4401, Batch Loss: 0.1244, Total Loss: 628.7968\n",
      "Epoch 5/10, Batch 2240/4401, Batch Loss: 0.3298, Total Loss: 632.3146\n",
      "Epoch 5/10, Batch 2250/4401, Batch Loss: 0.2475, Total Loss: 635.0497\n",
      "Epoch 5/10, Batch 2260/4401, Batch Loss: 0.3776, Total Loss: 637.4734\n",
      "Epoch 5/10, Batch 2270/4401, Batch Loss: 0.4413, Total Loss: 641.0600\n",
      "Epoch 5/10, Batch 2280/4401, Batch Loss: 0.2230, Total Loss: 644.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 2290/4401, Batch Loss: 0.4389, Total Loss: 646.6435\n",
      "Epoch 5/10, Batch 2300/4401, Batch Loss: 0.1474, Total Loss: 649.8402\n",
      "Epoch 5/10, Batch 2310/4401, Batch Loss: 0.3018, Total Loss: 652.9569\n",
      "Epoch 5/10, Batch 2320/4401, Batch Loss: 0.0944, Total Loss: 655.5437\n",
      "Epoch 5/10, Batch 2330/4401, Batch Loss: 0.1674, Total Loss: 658.3809\n",
      "Epoch 5/10, Batch 2340/4401, Batch Loss: 0.0743, Total Loss: 660.5332\n",
      "Epoch 5/10, Batch 2350/4401, Batch Loss: 0.1306, Total Loss: 663.1168\n",
      "Epoch 5/10, Batch 2360/4401, Batch Loss: 0.3888, Total Loss: 665.9671\n",
      "Epoch 5/10, Batch 2370/4401, Batch Loss: 0.4023, Total Loss: 668.9033\n",
      "Epoch 5/10, Batch 2380/4401, Batch Loss: 0.1125, Total Loss: 671.4004\n",
      "Epoch 5/10, Batch 2390/4401, Batch Loss: 0.2266, Total Loss: 673.8478\n",
      "Epoch 5/10, Batch 2400/4401, Batch Loss: 0.2104, Total Loss: 676.7902\n",
      "Epoch 5/10, Batch 2410/4401, Batch Loss: 0.2752, Total Loss: 681.6649\n",
      "Epoch 5/10, Batch 2420/4401, Batch Loss: 0.1841, Total Loss: 684.8052\n",
      "Epoch 5/10, Batch 2430/4401, Batch Loss: 0.3237, Total Loss: 688.4429\n",
      "Epoch 5/10, Batch 2440/4401, Batch Loss: 0.1722, Total Loss: 690.6497\n",
      "Epoch 5/10, Batch 2450/4401, Batch Loss: 0.1986, Total Loss: 694.0107\n",
      "Epoch 5/10, Batch 2460/4401, Batch Loss: 0.4718, Total Loss: 697.4030\n",
      "Epoch 5/10, Batch 2470/4401, Batch Loss: 0.0636, Total Loss: 699.7326\n",
      "Epoch 5/10, Batch 2480/4401, Batch Loss: 0.3177, Total Loss: 702.1996\n",
      "Epoch 5/10, Batch 2490/4401, Batch Loss: 0.2966, Total Loss: 704.9403\n",
      "Epoch 5/10, Batch 2500/4401, Batch Loss: 0.0651, Total Loss: 707.5057\n",
      "Epoch 5/10, Batch 2510/4401, Batch Loss: 0.1733, Total Loss: 710.5865\n",
      "Epoch 5/10, Batch 2520/4401, Batch Loss: 0.2203, Total Loss: 714.0470\n",
      "Epoch 5/10, Batch 2530/4401, Batch Loss: 0.3282, Total Loss: 716.7315\n",
      "Epoch 5/10, Batch 2540/4401, Batch Loss: 0.1611, Total Loss: 719.8412\n",
      "Epoch 5/10, Batch 2550/4401, Batch Loss: 0.2562, Total Loss: 723.3371\n",
      "Epoch 5/10, Batch 2560/4401, Batch Loss: 1.0242, Total Loss: 726.5679\n",
      "Epoch 5/10, Batch 2570/4401, Batch Loss: 0.1559, Total Loss: 728.9133\n",
      "Epoch 5/10, Batch 2580/4401, Batch Loss: 0.1701, Total Loss: 731.4872\n",
      "Epoch 5/10, Batch 2590/4401, Batch Loss: 0.2337, Total Loss: 734.3221\n",
      "Epoch 5/10, Batch 2600/4401, Batch Loss: 0.1918, Total Loss: 737.1414\n",
      "Epoch 5/10, Batch 2610/4401, Batch Loss: 0.0864, Total Loss: 739.5077\n",
      "Epoch 5/10, Batch 2620/4401, Batch Loss: 0.3116, Total Loss: 741.2218\n",
      "Epoch 5/10, Batch 2630/4401, Batch Loss: 0.4086, Total Loss: 745.8542\n",
      "Epoch 5/10, Batch 2640/4401, Batch Loss: 0.2935, Total Loss: 749.4863\n",
      "Epoch 5/10, Batch 2650/4401, Batch Loss: 0.0471, Total Loss: 753.3888\n",
      "Epoch 5/10, Batch 2660/4401, Batch Loss: 0.5416, Total Loss: 756.2792\n",
      "Epoch 5/10, Batch 2670/4401, Batch Loss: 0.0681, Total Loss: 758.4649\n",
      "Epoch 5/10, Batch 2680/4401, Batch Loss: 0.7534, Total Loss: 762.1993\n",
      "Epoch 5/10, Batch 2690/4401, Batch Loss: 0.6857, Total Loss: 766.0820\n",
      "Epoch 5/10, Batch 2700/4401, Batch Loss: 0.2962, Total Loss: 768.2636\n",
      "Epoch 5/10, Batch 2710/4401, Batch Loss: 0.7295, Total Loss: 772.9830\n",
      "Epoch 5/10, Batch 2720/4401, Batch Loss: 0.1736, Total Loss: 776.1770\n",
      "Epoch 5/10, Batch 2730/4401, Batch Loss: 0.9151, Total Loss: 779.6668\n",
      "Epoch 5/10, Batch 2740/4401, Batch Loss: 0.3765, Total Loss: 782.6670\n",
      "Epoch 5/10, Batch 2750/4401, Batch Loss: 0.1289, Total Loss: 784.8652\n",
      "Epoch 5/10, Batch 2760/4401, Batch Loss: 0.1423, Total Loss: 789.6840\n",
      "Epoch 5/10, Batch 2770/4401, Batch Loss: 0.0106, Total Loss: 792.4511\n",
      "Epoch 5/10, Batch 2780/4401, Batch Loss: 0.2219, Total Loss: 794.5933\n",
      "Epoch 5/10, Batch 2790/4401, Batch Loss: 0.1134, Total Loss: 797.1880\n",
      "Epoch 5/10, Batch 2800/4401, Batch Loss: 0.0434, Total Loss: 799.9425\n",
      "Epoch 5/10, Batch 2810/4401, Batch Loss: 0.3298, Total Loss: 803.1370\n",
      "Epoch 5/10, Batch 2820/4401, Batch Loss: 0.1513, Total Loss: 805.7796\n",
      "Epoch 5/10, Batch 2830/4401, Batch Loss: 0.1015, Total Loss: 808.7689\n",
      "Epoch 5/10, Batch 2840/4401, Batch Loss: 0.1169, Total Loss: 810.9506\n",
      "Epoch 5/10, Batch 2850/4401, Batch Loss: 0.2613, Total Loss: 813.0952\n",
      "Epoch 5/10, Batch 2860/4401, Batch Loss: 0.7014, Total Loss: 816.0129\n",
      "Epoch 5/10, Batch 2870/4401, Batch Loss: 0.3427, Total Loss: 818.7770\n",
      "Epoch 5/10, Batch 2880/4401, Batch Loss: 0.2087, Total Loss: 821.5858\n",
      "Epoch 5/10, Batch 2890/4401, Batch Loss: 0.2150, Total Loss: 823.7013\n",
      "Epoch 5/10, Batch 2900/4401, Batch Loss: 0.4196, Total Loss: 826.1927\n",
      "Epoch 5/10, Batch 2910/4401, Batch Loss: 0.2010, Total Loss: 828.4703\n",
      "Epoch 5/10, Batch 2920/4401, Batch Loss: 0.3706, Total Loss: 830.9842\n",
      "Epoch 5/10, Batch 2930/4401, Batch Loss: 0.0607, Total Loss: 833.0592\n",
      "Epoch 5/10, Batch 2940/4401, Batch Loss: 0.2358, Total Loss: 836.7730\n",
      "Epoch 5/10, Batch 2950/4401, Batch Loss: 0.2184, Total Loss: 839.1246\n",
      "Epoch 5/10, Batch 2960/4401, Batch Loss: 0.2878, Total Loss: 842.3395\n",
      "Epoch 5/10, Batch 2970/4401, Batch Loss: 0.5389, Total Loss: 846.4517\n",
      "Epoch 5/10, Batch 2980/4401, Batch Loss: 0.1095, Total Loss: 849.4591\n",
      "Epoch 5/10, Batch 2990/4401, Batch Loss: 0.1436, Total Loss: 852.8566\n",
      "Epoch 5/10, Batch 3000/4401, Batch Loss: 0.3023, Total Loss: 855.8634\n",
      "Epoch 5/10, Batch 3010/4401, Batch Loss: 0.2419, Total Loss: 858.0009\n",
      "Epoch 5/10, Batch 3020/4401, Batch Loss: 0.0112, Total Loss: 860.4460\n",
      "Epoch 5/10, Batch 3030/4401, Batch Loss: 0.1396, Total Loss: 862.7266\n",
      "Epoch 5/10, Batch 3040/4401, Batch Loss: 0.4292, Total Loss: 865.9405\n",
      "Epoch 5/10, Batch 3050/4401, Batch Loss: 0.1246, Total Loss: 868.7171\n",
      "Epoch 5/10, Batch 3060/4401, Batch Loss: 0.0534, Total Loss: 871.1874\n",
      "Epoch 5/10, Batch 3070/4401, Batch Loss: 0.2147, Total Loss: 874.3058\n",
      "Epoch 5/10, Batch 3080/4401, Batch Loss: 0.2034, Total Loss: 880.4293\n",
      "Epoch 5/10, Batch 3090/4401, Batch Loss: 0.3334, Total Loss: 883.2620\n",
      "Epoch 5/10, Batch 3100/4401, Batch Loss: 0.1748, Total Loss: 885.0573\n",
      "Epoch 5/10, Batch 3110/4401, Batch Loss: 0.3457, Total Loss: 887.8858\n",
      "Epoch 5/10, Batch 3120/4401, Batch Loss: 0.4276, Total Loss: 889.9819\n",
      "Epoch 5/10, Batch 3130/4401, Batch Loss: 0.1493, Total Loss: 893.2284\n",
      "Epoch 5/10, Batch 3140/4401, Batch Loss: 0.3556, Total Loss: 896.9630\n",
      "Epoch 5/10, Batch 3150/4401, Batch Loss: 0.1233, Total Loss: 900.7158\n",
      "Epoch 5/10, Batch 3160/4401, Batch Loss: 0.1142, Total Loss: 902.8359\n",
      "Epoch 5/10, Batch 3170/4401, Batch Loss: 0.4075, Total Loss: 905.9872\n",
      "Epoch 5/10, Batch 3180/4401, Batch Loss: 0.3791, Total Loss: 908.9935\n",
      "Epoch 5/10, Batch 3190/4401, Batch Loss: 0.2236, Total Loss: 911.5268\n",
      "Epoch 5/10, Batch 3200/4401, Batch Loss: 0.4757, Total Loss: 915.0359\n",
      "Epoch 5/10, Batch 3210/4401, Batch Loss: 0.2875, Total Loss: 917.0311\n",
      "Epoch 5/10, Batch 3220/4401, Batch Loss: 0.6281, Total Loss: 920.1798\n",
      "Epoch 5/10, Batch 3230/4401, Batch Loss: 0.3657, Total Loss: 922.9131\n",
      "Epoch 5/10, Batch 3240/4401, Batch Loss: 0.1708, Total Loss: 925.7904\n",
      "Epoch 5/10, Batch 3250/4401, Batch Loss: 0.0042, Total Loss: 928.3648\n",
      "Epoch 5/10, Batch 3260/4401, Batch Loss: 0.5910, Total Loss: 931.7960\n",
      "Epoch 5/10, Batch 3270/4401, Batch Loss: 0.2380, Total Loss: 934.0081\n",
      "Epoch 5/10, Batch 3280/4401, Batch Loss: 0.1687, Total Loss: 936.5212\n",
      "Epoch 5/10, Batch 3290/4401, Batch Loss: 0.2945, Total Loss: 940.2764\n",
      "Epoch 5/10, Batch 3300/4401, Batch Loss: 0.4183, Total Loss: 942.9576\n",
      "Epoch 5/10, Batch 3310/4401, Batch Loss: 0.1797, Total Loss: 945.4432\n",
      "Epoch 5/10, Batch 3320/4401, Batch Loss: 0.1238, Total Loss: 947.7147\n",
      "Epoch 5/10, Batch 3330/4401, Batch Loss: 0.4474, Total Loss: 950.9480\n",
      "Epoch 5/10, Batch 3340/4401, Batch Loss: 0.1951, Total Loss: 953.9200\n",
      "Epoch 5/10, Batch 3350/4401, Batch Loss: 0.8658, Total Loss: 958.0705\n",
      "Epoch 5/10, Batch 3360/4401, Batch Loss: 0.1503, Total Loss: 960.6928\n",
      "Epoch 5/10, Batch 3370/4401, Batch Loss: 0.3745, Total Loss: 963.6866\n",
      "Epoch 5/10, Batch 3380/4401, Batch Loss: 0.3646, Total Loss: 965.8086\n",
      "Epoch 5/10, Batch 3390/4401, Batch Loss: 0.2017, Total Loss: 968.7846\n",
      "Epoch 5/10, Batch 3400/4401, Batch Loss: 0.1494, Total Loss: 971.5188\n",
      "Epoch 5/10, Batch 3410/4401, Batch Loss: 0.3439, Total Loss: 973.8768\n",
      "Epoch 5/10, Batch 3420/4401, Batch Loss: 0.1285, Total Loss: 976.2430\n",
      "Epoch 5/10, Batch 3430/4401, Batch Loss: 0.0665, Total Loss: 979.0892\n",
      "Epoch 5/10, Batch 3440/4401, Batch Loss: 0.1152, Total Loss: 981.0862\n",
      "Epoch 5/10, Batch 3450/4401, Batch Loss: 0.3138, Total Loss: 983.4444\n",
      "Epoch 5/10, Batch 3460/4401, Batch Loss: 0.3261, Total Loss: 986.5804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 3470/4401, Batch Loss: 0.5005, Total Loss: 988.9822\n",
      "Epoch 5/10, Batch 3480/4401, Batch Loss: 0.2424, Total Loss: 990.9313\n",
      "Epoch 5/10, Batch 3490/4401, Batch Loss: 0.0370, Total Loss: 992.1281\n",
      "Epoch 5/10, Batch 3500/4401, Batch Loss: 0.0841, Total Loss: 994.7686\n",
      "Epoch 5/10, Batch 3510/4401, Batch Loss: 0.2421, Total Loss: 998.1504\n",
      "Epoch 5/10, Batch 3520/4401, Batch Loss: 0.1651, Total Loss: 1000.7697\n",
      "Epoch 5/10, Batch 3530/4401, Batch Loss: 0.2457, Total Loss: 1003.8493\n",
      "Epoch 5/10, Batch 3540/4401, Batch Loss: 0.3642, Total Loss: 1008.6510\n",
      "Epoch 5/10, Batch 3550/4401, Batch Loss: 0.1037, Total Loss: 1012.0325\n",
      "Epoch 5/10, Batch 3560/4401, Batch Loss: 0.3011, Total Loss: 1015.7826\n",
      "Epoch 5/10, Batch 3570/4401, Batch Loss: 0.2836, Total Loss: 1018.2894\n",
      "Epoch 5/10, Batch 3580/4401, Batch Loss: 0.4153, Total Loss: 1020.9529\n",
      "Epoch 5/10, Batch 3590/4401, Batch Loss: 0.4781, Total Loss: 1026.1431\n",
      "Epoch 5/10, Batch 3600/4401, Batch Loss: 0.4345, Total Loss: 1028.8981\n",
      "Epoch 5/10, Batch 3610/4401, Batch Loss: 0.4202, Total Loss: 1031.8449\n",
      "Epoch 5/10, Batch 3620/4401, Batch Loss: 0.3122, Total Loss: 1033.8068\n",
      "Epoch 5/10, Batch 3630/4401, Batch Loss: 0.2445, Total Loss: 1037.2437\n",
      "Epoch 5/10, Batch 3640/4401, Batch Loss: 0.2611, Total Loss: 1041.2812\n",
      "Epoch 5/10, Batch 3650/4401, Batch Loss: 0.2498, Total Loss: 1043.2597\n",
      "Epoch 5/10, Batch 3660/4401, Batch Loss: 0.3562, Total Loss: 1045.9613\n",
      "Epoch 5/10, Batch 3670/4401, Batch Loss: 0.2809, Total Loss: 1048.3186\n",
      "Epoch 5/10, Batch 3680/4401, Batch Loss: 0.1082, Total Loss: 1051.1545\n",
      "Epoch 5/10, Batch 3690/4401, Batch Loss: 0.3810, Total Loss: 1054.2506\n",
      "Epoch 5/10, Batch 3700/4401, Batch Loss: 0.2686, Total Loss: 1057.0454\n",
      "Epoch 5/10, Batch 3710/4401, Batch Loss: 0.8889, Total Loss: 1059.7280\n",
      "Epoch 5/10, Batch 3720/4401, Batch Loss: 0.1180, Total Loss: 1062.0193\n",
      "Epoch 5/10, Batch 3730/4401, Batch Loss: 1.0738, Total Loss: 1067.1444\n",
      "Epoch 5/10, Batch 3740/4401, Batch Loss: 0.1648, Total Loss: 1069.3660\n",
      "Epoch 5/10, Batch 3750/4401, Batch Loss: 0.2651, Total Loss: 1072.9269\n",
      "Epoch 5/10, Batch 3760/4401, Batch Loss: 0.3030, Total Loss: 1075.3210\n",
      "Epoch 5/10, Batch 3770/4401, Batch Loss: 0.1545, Total Loss: 1077.6318\n",
      "Epoch 5/10, Batch 3780/4401, Batch Loss: 0.3283, Total Loss: 1081.4392\n",
      "Epoch 5/10, Batch 3790/4401, Batch Loss: 0.2989, Total Loss: 1083.8128\n",
      "Epoch 5/10, Batch 3800/4401, Batch Loss: 0.0505, Total Loss: 1086.7778\n",
      "Epoch 5/10, Batch 3810/4401, Batch Loss: 0.0096, Total Loss: 1089.4688\n",
      "Epoch 5/10, Batch 3820/4401, Batch Loss: 0.6062, Total Loss: 1093.3062\n",
      "Epoch 5/10, Batch 3830/4401, Batch Loss: 0.3771, Total Loss: 1095.7658\n",
      "Epoch 5/10, Batch 3840/4401, Batch Loss: 0.4021, Total Loss: 1098.2061\n",
      "Epoch 5/10, Batch 3850/4401, Batch Loss: 0.3387, Total Loss: 1102.0344\n",
      "Epoch 5/10, Batch 3860/4401, Batch Loss: 0.1297, Total Loss: 1104.3692\n",
      "Epoch 5/10, Batch 3870/4401, Batch Loss: 0.3060, Total Loss: 1108.2225\n",
      "Epoch 5/10, Batch 3880/4401, Batch Loss: 0.0841, Total Loss: 1111.5417\n",
      "Epoch 5/10, Batch 3890/4401, Batch Loss: 0.3770, Total Loss: 1114.4738\n",
      "Epoch 5/10, Batch 3900/4401, Batch Loss: 0.0378, Total Loss: 1116.6683\n",
      "Epoch 5/10, Batch 3910/4401, Batch Loss: 0.2444, Total Loss: 1118.9309\n",
      "Epoch 5/10, Batch 3920/4401, Batch Loss: 0.0979, Total Loss: 1120.9883\n",
      "Epoch 5/10, Batch 3930/4401, Batch Loss: 0.1376, Total Loss: 1123.4278\n",
      "Epoch 5/10, Batch 3940/4401, Batch Loss: 0.1554, Total Loss: 1126.7766\n",
      "Epoch 5/10, Batch 3950/4401, Batch Loss: 0.2369, Total Loss: 1128.5772\n",
      "Epoch 5/10, Batch 3960/4401, Batch Loss: 0.5956, Total Loss: 1132.0698\n",
      "Epoch 5/10, Batch 3970/4401, Batch Loss: 0.2678, Total Loss: 1135.3526\n",
      "Epoch 5/10, Batch 3980/4401, Batch Loss: 0.2044, Total Loss: 1139.4018\n",
      "Epoch 5/10, Batch 3990/4401, Batch Loss: 0.0796, Total Loss: 1142.3524\n",
      "Epoch 5/10, Batch 4000/4401, Batch Loss: 0.3225, Total Loss: 1144.8053\n",
      "Epoch 5/10, Batch 4010/4401, Batch Loss: 0.1455, Total Loss: 1148.1408\n",
      "Epoch 5/10, Batch 4020/4401, Batch Loss: 0.2295, Total Loss: 1151.0253\n",
      "Epoch 5/10, Batch 4030/4401, Batch Loss: 1.3474, Total Loss: 1154.6637\n",
      "Epoch 5/10, Batch 4040/4401, Batch Loss: 0.1842, Total Loss: 1156.9623\n",
      "Epoch 5/10, Batch 4050/4401, Batch Loss: 0.2441, Total Loss: 1160.0483\n",
      "Epoch 5/10, Batch 4060/4401, Batch Loss: 0.2077, Total Loss: 1162.2372\n",
      "Epoch 5/10, Batch 4070/4401, Batch Loss: 0.1293, Total Loss: 1165.0214\n",
      "Epoch 5/10, Batch 4080/4401, Batch Loss: 0.1155, Total Loss: 1168.4134\n",
      "Epoch 5/10, Batch 4090/4401, Batch Loss: 0.6220, Total Loss: 1173.1548\n",
      "Epoch 5/10, Batch 4100/4401, Batch Loss: 0.2199, Total Loss: 1176.7171\n",
      "Epoch 5/10, Batch 4110/4401, Batch Loss: 0.0539, Total Loss: 1178.7729\n",
      "Epoch 5/10, Batch 4120/4401, Batch Loss: 0.1596, Total Loss: 1181.8781\n",
      "Epoch 5/10, Batch 4130/4401, Batch Loss: 0.1665, Total Loss: 1185.4901\n",
      "Epoch 5/10, Batch 4140/4401, Batch Loss: 0.1439, Total Loss: 1187.7214\n",
      "Epoch 5/10, Batch 4150/4401, Batch Loss: 0.0470, Total Loss: 1190.0738\n",
      "Epoch 5/10, Batch 4160/4401, Batch Loss: 0.1404, Total Loss: 1192.5018\n",
      "Epoch 5/10, Batch 4170/4401, Batch Loss: 0.4617, Total Loss: 1196.3711\n",
      "Epoch 5/10, Batch 4180/4401, Batch Loss: 0.5207, Total Loss: 1200.6290\n",
      "Epoch 5/10, Batch 4190/4401, Batch Loss: 0.1367, Total Loss: 1202.9667\n",
      "Epoch 5/10, Batch 4200/4401, Batch Loss: 0.2764, Total Loss: 1206.2860\n",
      "Epoch 5/10, Batch 4210/4401, Batch Loss: 0.1092, Total Loss: 1208.8047\n",
      "Epoch 5/10, Batch 4220/4401, Batch Loss: 0.1089, Total Loss: 1211.6605\n",
      "Epoch 5/10, Batch 4230/4401, Batch Loss: 0.1822, Total Loss: 1215.4435\n",
      "Epoch 5/10, Batch 4240/4401, Batch Loss: 0.3313, Total Loss: 1218.2932\n",
      "Epoch 5/10, Batch 4250/4401, Batch Loss: 0.1941, Total Loss: 1220.4144\n",
      "Epoch 5/10, Batch 4260/4401, Batch Loss: 0.2782, Total Loss: 1223.0071\n",
      "Epoch 5/10, Batch 4270/4401, Batch Loss: 0.3421, Total Loss: 1226.6127\n",
      "Epoch 5/10, Batch 4280/4401, Batch Loss: 0.3852, Total Loss: 1229.6197\n",
      "Epoch 5/10, Batch 4290/4401, Batch Loss: 0.8212, Total Loss: 1233.5422\n",
      "Epoch 5/10, Batch 4300/4401, Batch Loss: 0.2339, Total Loss: 1236.8348\n",
      "Epoch 5/10, Batch 4310/4401, Batch Loss: 0.0848, Total Loss: 1238.4647\n",
      "Epoch 5/10, Batch 4320/4401, Batch Loss: 0.3055, Total Loss: 1241.0483\n",
      "Epoch 5/10, Batch 4330/4401, Batch Loss: 0.3323, Total Loss: 1244.6040\n",
      "Epoch 5/10, Batch 4340/4401, Batch Loss: 0.5465, Total Loss: 1247.5076\n",
      "Epoch 5/10, Batch 4350/4401, Batch Loss: 0.2010, Total Loss: 1251.1567\n",
      "Epoch 5/10, Batch 4360/4401, Batch Loss: 0.2049, Total Loss: 1253.6650\n",
      "Epoch 5/10, Batch 4370/4401, Batch Loss: 0.2470, Total Loss: 1257.5578\n",
      "Epoch 5/10, Batch 4380/4401, Batch Loss: 0.2385, Total Loss: 1259.9191\n",
      "Epoch 5/10, Batch 4390/4401, Batch Loss: 0.0456, Total Loss: 1262.7684\n",
      "Epoch 5/10, Batch 4400/4401, Batch Loss: 0.1252, Total Loss: 1265.3352\n",
      "Epoch 5/10, Batch 4401/4401, Batch Loss: 0.6660, Total Loss: 1266.0012\n",
      "Epoch 5/10 completed. Total Loss: 1266.0012\n",
      "\n",
      "Epoch 6/10 running...\n",
      "cuda:0\n",
      "Epoch 6/10, Batch 10/4401, Batch Loss: 0.3821, Total Loss: 3.4795\n",
      "Epoch 6/10, Batch 20/4401, Batch Loss: 0.4230, Total Loss: 6.6059\n",
      "Epoch 6/10, Batch 30/4401, Batch Loss: 0.1933, Total Loss: 8.6191\n",
      "Epoch 6/10, Batch 40/4401, Batch Loss: 0.5861, Total Loss: 11.0030\n",
      "Epoch 6/10, Batch 50/4401, Batch Loss: 0.0310, Total Loss: 12.9649\n",
      "Epoch 6/10, Batch 60/4401, Batch Loss: 0.1558, Total Loss: 14.8051\n",
      "Epoch 6/10, Batch 70/4401, Batch Loss: 0.1266, Total Loss: 17.4470\n",
      "Epoch 6/10, Batch 80/4401, Batch Loss: 0.1592, Total Loss: 20.2041\n",
      "Epoch 6/10, Batch 90/4401, Batch Loss: 0.3828, Total Loss: 22.7369\n",
      "Epoch 6/10, Batch 100/4401, Batch Loss: 0.0575, Total Loss: 25.7877\n",
      "Epoch 6/10, Batch 110/4401, Batch Loss: 0.2751, Total Loss: 28.0504\n",
      "Epoch 6/10, Batch 120/4401, Batch Loss: 0.0166, Total Loss: 30.5499\n",
      "Epoch 6/10, Batch 130/4401, Batch Loss: 0.3363, Total Loss: 32.9885\n",
      "Epoch 6/10, Batch 140/4401, Batch Loss: 0.1726, Total Loss: 35.5494\n",
      "Epoch 6/10, Batch 150/4401, Batch Loss: 0.0974, Total Loss: 37.3117\n",
      "Epoch 6/10, Batch 160/4401, Batch Loss: 0.7052, Total Loss: 40.5976\n",
      "Epoch 6/10, Batch 170/4401, Batch Loss: 0.2682, Total Loss: 43.2244\n",
      "Epoch 6/10, Batch 180/4401, Batch Loss: 0.9572, Total Loss: 47.0167\n",
      "Epoch 6/10, Batch 190/4401, Batch Loss: 0.2058, Total Loss: 49.6198\n",
      "Epoch 6/10, Batch 200/4401, Batch Loss: 0.5183, Total Loss: 51.1727\n",
      "Epoch 6/10, Batch 210/4401, Batch Loss: 0.2564, Total Loss: 53.7958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 220/4401, Batch Loss: 0.4164, Total Loss: 56.2344\n",
      "Epoch 6/10, Batch 230/4401, Batch Loss: 0.2151, Total Loss: 58.9111\n",
      "Epoch 6/10, Batch 240/4401, Batch Loss: 0.6149, Total Loss: 61.7028\n",
      "Epoch 6/10, Batch 250/4401, Batch Loss: 0.0478, Total Loss: 63.5923\n",
      "Epoch 6/10, Batch 260/4401, Batch Loss: 0.2147, Total Loss: 65.5343\n",
      "Epoch 6/10, Batch 270/4401, Batch Loss: 0.5606, Total Loss: 68.5507\n",
      "Epoch 6/10, Batch 280/4401, Batch Loss: 0.1632, Total Loss: 71.2690\n",
      "Epoch 6/10, Batch 290/4401, Batch Loss: 0.4616, Total Loss: 73.6085\n",
      "Epoch 6/10, Batch 300/4401, Batch Loss: 0.0606, Total Loss: 76.6254\n",
      "Epoch 6/10, Batch 310/4401, Batch Loss: 0.3269, Total Loss: 79.4859\n",
      "Epoch 6/10, Batch 320/4401, Batch Loss: 0.2676, Total Loss: 81.9763\n",
      "Epoch 6/10, Batch 330/4401, Batch Loss: 0.5148, Total Loss: 85.0811\n",
      "Epoch 6/10, Batch 340/4401, Batch Loss: 0.3765, Total Loss: 88.4974\n",
      "Epoch 6/10, Batch 350/4401, Batch Loss: 0.3140, Total Loss: 90.8663\n",
      "Epoch 6/10, Batch 360/4401, Batch Loss: 0.2037, Total Loss: 94.4906\n",
      "Epoch 6/10, Batch 370/4401, Batch Loss: 0.2185, Total Loss: 97.4320\n",
      "Epoch 6/10, Batch 380/4401, Batch Loss: 0.1911, Total Loss: 99.6412\n",
      "Epoch 6/10, Batch 390/4401, Batch Loss: 0.2258, Total Loss: 101.5207\n",
      "Epoch 6/10, Batch 400/4401, Batch Loss: 0.2210, Total Loss: 103.5138\n",
      "Epoch 6/10, Batch 410/4401, Batch Loss: 0.6226, Total Loss: 106.6831\n",
      "Epoch 6/10, Batch 420/4401, Batch Loss: 0.2742, Total Loss: 110.1143\n",
      "Epoch 6/10, Batch 430/4401, Batch Loss: 0.2205, Total Loss: 112.3938\n",
      "Epoch 6/10, Batch 440/4401, Batch Loss: 0.1558, Total Loss: 115.5072\n",
      "Epoch 6/10, Batch 450/4401, Batch Loss: 0.0463, Total Loss: 117.8251\n",
      "Epoch 6/10, Batch 460/4401, Batch Loss: 0.3215, Total Loss: 119.9884\n",
      "Epoch 6/10, Batch 470/4401, Batch Loss: 0.0782, Total Loss: 121.6056\n",
      "Epoch 6/10, Batch 480/4401, Batch Loss: 0.2285, Total Loss: 123.6212\n",
      "Epoch 6/10, Batch 490/4401, Batch Loss: 0.4363, Total Loss: 127.4007\n",
      "Epoch 6/10, Batch 500/4401, Batch Loss: 0.3023, Total Loss: 130.4093\n",
      "Epoch 6/10, Batch 510/4401, Batch Loss: 0.1760, Total Loss: 133.0163\n",
      "Epoch 6/10, Batch 520/4401, Batch Loss: 0.1963, Total Loss: 136.6168\n",
      "Epoch 6/10, Batch 530/4401, Batch Loss: 0.4022, Total Loss: 139.3835\n",
      "Epoch 6/10, Batch 540/4401, Batch Loss: 0.2224, Total Loss: 142.0514\n",
      "Epoch 6/10, Batch 550/4401, Batch Loss: 0.2911, Total Loss: 144.1243\n",
      "Epoch 6/10, Batch 560/4401, Batch Loss: 0.3758, Total Loss: 146.7109\n",
      "Epoch 6/10, Batch 570/4401, Batch Loss: 0.2411, Total Loss: 148.8903\n",
      "Epoch 6/10, Batch 580/4401, Batch Loss: 0.1778, Total Loss: 150.8408\n",
      "Epoch 6/10, Batch 590/4401, Batch Loss: 0.7814, Total Loss: 154.2930\n",
      "Epoch 6/10, Batch 600/4401, Batch Loss: 0.1758, Total Loss: 157.4674\n",
      "Epoch 6/10, Batch 610/4401, Batch Loss: 0.2650, Total Loss: 160.1220\n",
      "Epoch 6/10, Batch 620/4401, Batch Loss: 0.3708, Total Loss: 163.0973\n",
      "Epoch 6/10, Batch 630/4401, Batch Loss: 0.4442, Total Loss: 167.4133\n",
      "Epoch 6/10, Batch 640/4401, Batch Loss: 0.2007, Total Loss: 168.8302\n",
      "Epoch 6/10, Batch 650/4401, Batch Loss: 0.1225, Total Loss: 171.9759\n",
      "Epoch 6/10, Batch 660/4401, Batch Loss: 0.3088, Total Loss: 174.3436\n",
      "Epoch 6/10, Batch 670/4401, Batch Loss: 0.3597, Total Loss: 176.5199\n",
      "Epoch 6/10, Batch 680/4401, Batch Loss: 0.0365, Total Loss: 178.1951\n",
      "Epoch 6/10, Batch 690/4401, Batch Loss: 0.4993, Total Loss: 181.5018\n",
      "Epoch 6/10, Batch 700/4401, Batch Loss: 0.2448, Total Loss: 185.1970\n",
      "Epoch 6/10, Batch 710/4401, Batch Loss: 0.6293, Total Loss: 188.1304\n",
      "Epoch 6/10, Batch 720/4401, Batch Loss: 0.3919, Total Loss: 189.8997\n",
      "Epoch 6/10, Batch 730/4401, Batch Loss: 1.2470, Total Loss: 193.9043\n",
      "Epoch 6/10, Batch 740/4401, Batch Loss: 0.1830, Total Loss: 197.1813\n",
      "Epoch 6/10, Batch 750/4401, Batch Loss: 0.7249, Total Loss: 200.2665\n",
      "Epoch 6/10, Batch 760/4401, Batch Loss: 0.1854, Total Loss: 202.5760\n",
      "Epoch 6/10, Batch 770/4401, Batch Loss: 0.0845, Total Loss: 204.5140\n",
      "Epoch 6/10, Batch 780/4401, Batch Loss: 0.4785, Total Loss: 206.9194\n",
      "Epoch 6/10, Batch 790/4401, Batch Loss: 0.3263, Total Loss: 210.2764\n",
      "Epoch 6/10, Batch 800/4401, Batch Loss: 0.3646, Total Loss: 213.2893\n",
      "Epoch 6/10, Batch 810/4401, Batch Loss: 0.3024, Total Loss: 215.4785\n",
      "Epoch 6/10, Batch 820/4401, Batch Loss: 0.4738, Total Loss: 217.2894\n",
      "Epoch 6/10, Batch 830/4401, Batch Loss: 0.1576, Total Loss: 219.8313\n",
      "Epoch 6/10, Batch 840/4401, Batch Loss: 0.1978, Total Loss: 222.5802\n",
      "Epoch 6/10, Batch 850/4401, Batch Loss: 0.7820, Total Loss: 225.5516\n",
      "Epoch 6/10, Batch 860/4401, Batch Loss: 0.2281, Total Loss: 227.7761\n",
      "Epoch 6/10, Batch 870/4401, Batch Loss: 0.0727, Total Loss: 230.7714\n",
      "Epoch 6/10, Batch 880/4401, Batch Loss: 0.1543, Total Loss: 232.4794\n",
      "Epoch 6/10, Batch 890/4401, Batch Loss: 0.1302, Total Loss: 234.4407\n",
      "Epoch 6/10, Batch 900/4401, Batch Loss: 0.4996, Total Loss: 237.7761\n",
      "Epoch 6/10, Batch 910/4401, Batch Loss: 0.6725, Total Loss: 241.7162\n",
      "Epoch 6/10, Batch 920/4401, Batch Loss: 0.0800, Total Loss: 243.3519\n",
      "Epoch 6/10, Batch 930/4401, Batch Loss: 0.1282, Total Loss: 245.8126\n",
      "Epoch 6/10, Batch 940/4401, Batch Loss: 0.1818, Total Loss: 248.5288\n",
      "Epoch 6/10, Batch 950/4401, Batch Loss: 0.2295, Total Loss: 251.5963\n",
      "Epoch 6/10, Batch 960/4401, Batch Loss: 0.2326, Total Loss: 253.6383\n",
      "Epoch 6/10, Batch 970/4401, Batch Loss: 0.1718, Total Loss: 255.5061\n",
      "Epoch 6/10, Batch 980/4401, Batch Loss: 0.3868, Total Loss: 257.7842\n",
      "Epoch 6/10, Batch 990/4401, Batch Loss: 0.2479, Total Loss: 259.7962\n",
      "Epoch 6/10, Batch 1000/4401, Batch Loss: 0.5692, Total Loss: 263.1576\n",
      "Epoch 6/10, Batch 1010/4401, Batch Loss: 0.3739, Total Loss: 266.1236\n",
      "Epoch 6/10, Batch 1020/4401, Batch Loss: 0.2512, Total Loss: 268.7719\n",
      "Epoch 6/10, Batch 1030/4401, Batch Loss: 0.0654, Total Loss: 270.9106\n",
      "Epoch 6/10, Batch 1040/4401, Batch Loss: 0.0665, Total Loss: 272.7593\n",
      "Epoch 6/10, Batch 1050/4401, Batch Loss: 0.4912, Total Loss: 274.7094\n",
      "Epoch 6/10, Batch 1060/4401, Batch Loss: 0.1204, Total Loss: 277.5798\n",
      "Epoch 6/10, Batch 1070/4401, Batch Loss: 0.0041, Total Loss: 279.4193\n",
      "Epoch 6/10, Batch 1080/4401, Batch Loss: 0.2076, Total Loss: 282.8211\n",
      "Epoch 6/10, Batch 1090/4401, Batch Loss: 0.2521, Total Loss: 284.9258\n",
      "Epoch 6/10, Batch 1100/4401, Batch Loss: 0.4620, Total Loss: 288.4184\n",
      "Epoch 6/10, Batch 1110/4401, Batch Loss: 0.3668, Total Loss: 290.7602\n",
      "Epoch 6/10, Batch 1120/4401, Batch Loss: 0.4627, Total Loss: 294.1546\n",
      "Epoch 6/10, Batch 1130/4401, Batch Loss: 0.1311, Total Loss: 297.9713\n",
      "Epoch 6/10, Batch 1140/4401, Batch Loss: 0.1222, Total Loss: 300.2247\n",
      "Epoch 6/10, Batch 1150/4401, Batch Loss: 0.3083, Total Loss: 302.7170\n",
      "Epoch 6/10, Batch 1160/4401, Batch Loss: 0.1621, Total Loss: 305.7217\n",
      "Epoch 6/10, Batch 1170/4401, Batch Loss: 0.1836, Total Loss: 308.7295\n",
      "Epoch 6/10, Batch 1180/4401, Batch Loss: 0.3645, Total Loss: 311.4356\n",
      "Epoch 6/10, Batch 1190/4401, Batch Loss: 0.5155, Total Loss: 315.2375\n",
      "Epoch 6/10, Batch 1200/4401, Batch Loss: 0.1142, Total Loss: 318.0433\n",
      "Epoch 6/10, Batch 1210/4401, Batch Loss: 0.7391, Total Loss: 321.6880\n",
      "Epoch 6/10, Batch 1220/4401, Batch Loss: 0.2378, Total Loss: 324.7386\n",
      "Epoch 6/10, Batch 1230/4401, Batch Loss: 0.2873, Total Loss: 327.0735\n",
      "Epoch 6/10, Batch 1240/4401, Batch Loss: 0.0527, Total Loss: 330.4782\n",
      "Epoch 6/10, Batch 1250/4401, Batch Loss: 0.4526, Total Loss: 333.9891\n",
      "Epoch 6/10, Batch 1260/4401, Batch Loss: 0.1536, Total Loss: 335.7332\n",
      "Epoch 6/10, Batch 1270/4401, Batch Loss: 0.2405, Total Loss: 338.3425\n",
      "Epoch 6/10, Batch 1280/4401, Batch Loss: 0.2603, Total Loss: 341.6571\n",
      "Epoch 6/10, Batch 1290/4401, Batch Loss: 0.2289, Total Loss: 344.1099\n",
      "Epoch 6/10, Batch 1300/4401, Batch Loss: 0.1497, Total Loss: 346.5871\n",
      "Epoch 6/10, Batch 1310/4401, Batch Loss: 0.5668, Total Loss: 350.3327\n",
      "Epoch 6/10, Batch 1320/4401, Batch Loss: 0.4942, Total Loss: 353.5474\n",
      "Epoch 6/10, Batch 1330/4401, Batch Loss: 0.1076, Total Loss: 356.3864\n",
      "Epoch 6/10, Batch 1340/4401, Batch Loss: 0.0236, Total Loss: 359.5598\n",
      "Epoch 6/10, Batch 1350/4401, Batch Loss: 0.4350, Total Loss: 362.2672\n",
      "Epoch 6/10, Batch 1360/4401, Batch Loss: 0.1913, Total Loss: 364.7770\n",
      "Epoch 6/10, Batch 1370/4401, Batch Loss: 0.2872, Total Loss: 367.7831\n",
      "Epoch 6/10, Batch 1380/4401, Batch Loss: 0.2152, Total Loss: 371.6470\n",
      "Epoch 6/10, Batch 1390/4401, Batch Loss: 0.0552, Total Loss: 373.2312\n",
      "Epoch 6/10, Batch 1400/4401, Batch Loss: 0.2415, Total Loss: 375.4703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1410/4401, Batch Loss: 0.2299, Total Loss: 378.5401\n",
      "Epoch 6/10, Batch 1420/4401, Batch Loss: 0.2413, Total Loss: 381.4926\n",
      "Epoch 6/10, Batch 1430/4401, Batch Loss: 0.2888, Total Loss: 384.5725\n",
      "Epoch 6/10, Batch 1440/4401, Batch Loss: 0.0552, Total Loss: 387.6443\n",
      "Epoch 6/10, Batch 1450/4401, Batch Loss: 0.0042, Total Loss: 389.2293\n",
      "Epoch 6/10, Batch 1460/4401, Batch Loss: 0.1206, Total Loss: 391.7068\n",
      "Epoch 6/10, Batch 1470/4401, Batch Loss: 0.1393, Total Loss: 394.9688\n",
      "Epoch 6/10, Batch 1480/4401, Batch Loss: 0.3989, Total Loss: 397.1298\n",
      "Epoch 6/10, Batch 1490/4401, Batch Loss: 0.1374, Total Loss: 399.3550\n",
      "Epoch 6/10, Batch 1500/4401, Batch Loss: 0.5246, Total Loss: 402.4122\n",
      "Epoch 6/10, Batch 1510/4401, Batch Loss: 0.1784, Total Loss: 404.8558\n",
      "Epoch 6/10, Batch 1520/4401, Batch Loss: 0.4667, Total Loss: 407.8511\n",
      "Epoch 6/10, Batch 1530/4401, Batch Loss: 0.3407, Total Loss: 410.5175\n",
      "Epoch 6/10, Batch 1540/4401, Batch Loss: 0.3552, Total Loss: 414.3690\n",
      "Epoch 6/10, Batch 1550/4401, Batch Loss: 0.3849, Total Loss: 417.4175\n",
      "Epoch 6/10, Batch 1560/4401, Batch Loss: 0.2129, Total Loss: 420.6414\n",
      "Epoch 6/10, Batch 1570/4401, Batch Loss: 0.2104, Total Loss: 422.8764\n",
      "Epoch 6/10, Batch 1580/4401, Batch Loss: 0.1859, Total Loss: 425.6932\n",
      "Epoch 6/10, Batch 1590/4401, Batch Loss: 0.1630, Total Loss: 428.2934\n",
      "Epoch 6/10, Batch 1600/4401, Batch Loss: 0.2104, Total Loss: 430.4307\n",
      "Epoch 6/10, Batch 1610/4401, Batch Loss: 0.5693, Total Loss: 433.3512\n",
      "Epoch 6/10, Batch 1620/4401, Batch Loss: 0.1764, Total Loss: 436.1543\n",
      "Epoch 6/10, Batch 1630/4401, Batch Loss: 0.2118, Total Loss: 438.0446\n",
      "Epoch 6/10, Batch 1640/4401, Batch Loss: 0.3889, Total Loss: 441.0551\n",
      "Epoch 6/10, Batch 1650/4401, Batch Loss: 0.0892, Total Loss: 443.7869\n",
      "Epoch 6/10, Batch 1660/4401, Batch Loss: 0.2383, Total Loss: 445.8482\n",
      "Epoch 6/10, Batch 1670/4401, Batch Loss: 0.3054, Total Loss: 448.6966\n",
      "Epoch 6/10, Batch 1680/4401, Batch Loss: 0.2151, Total Loss: 450.7503\n",
      "Epoch 6/10, Batch 1690/4401, Batch Loss: 0.6715, Total Loss: 457.0623\n",
      "Epoch 6/10, Batch 1700/4401, Batch Loss: 0.5059, Total Loss: 459.7217\n",
      "Epoch 6/10, Batch 1710/4401, Batch Loss: 0.2564, Total Loss: 461.6101\n",
      "Epoch 6/10, Batch 1720/4401, Batch Loss: 0.1321, Total Loss: 464.1292\n",
      "Epoch 6/10, Batch 1730/4401, Batch Loss: 0.3736, Total Loss: 466.9038\n",
      "Epoch 6/10, Batch 1740/4401, Batch Loss: 0.0870, Total Loss: 469.2951\n",
      "Epoch 6/10, Batch 1750/4401, Batch Loss: 0.2266, Total Loss: 472.2205\n",
      "Epoch 6/10, Batch 1760/4401, Batch Loss: 0.3179, Total Loss: 475.3577\n",
      "Epoch 6/10, Batch 1770/4401, Batch Loss: 0.2796, Total Loss: 478.2606\n",
      "Epoch 6/10, Batch 1780/4401, Batch Loss: 0.1646, Total Loss: 480.3402\n",
      "Epoch 6/10, Batch 1790/4401, Batch Loss: 0.3199, Total Loss: 483.0510\n",
      "Epoch 6/10, Batch 1800/4401, Batch Loss: 0.3603, Total Loss: 485.3070\n",
      "Epoch 6/10, Batch 1810/4401, Batch Loss: 0.0524, Total Loss: 487.0213\n",
      "Epoch 6/10, Batch 1820/4401, Batch Loss: 0.1044, Total Loss: 489.1211\n",
      "Epoch 6/10, Batch 1830/4401, Batch Loss: 0.3389, Total Loss: 490.7008\n",
      "Epoch 6/10, Batch 1840/4401, Batch Loss: 0.5456, Total Loss: 493.8465\n",
      "Epoch 6/10, Batch 1850/4401, Batch Loss: 0.4436, Total Loss: 496.7324\n",
      "Epoch 6/10, Batch 1860/4401, Batch Loss: 0.1131, Total Loss: 498.8163\n",
      "Epoch 6/10, Batch 1870/4401, Batch Loss: 0.4856, Total Loss: 501.9839\n",
      "Epoch 6/10, Batch 1880/4401, Batch Loss: 0.1262, Total Loss: 504.5748\n",
      "Epoch 6/10, Batch 1890/4401, Batch Loss: 0.1809, Total Loss: 507.3237\n",
      "Epoch 6/10, Batch 1900/4401, Batch Loss: 0.3425, Total Loss: 510.8712\n",
      "Epoch 6/10, Batch 1910/4401, Batch Loss: 0.0260, Total Loss: 512.7470\n",
      "Epoch 6/10, Batch 1920/4401, Batch Loss: 0.0701, Total Loss: 514.8071\n",
      "Epoch 6/10, Batch 1930/4401, Batch Loss: 0.5580, Total Loss: 517.6458\n",
      "Epoch 6/10, Batch 1940/4401, Batch Loss: 0.0870, Total Loss: 519.9131\n",
      "Epoch 6/10, Batch 1950/4401, Batch Loss: 0.1546, Total Loss: 522.2214\n",
      "Epoch 6/10, Batch 1960/4401, Batch Loss: 0.2162, Total Loss: 523.9354\n",
      "Epoch 6/10, Batch 1970/4401, Batch Loss: 0.6149, Total Loss: 526.8843\n",
      "Epoch 6/10, Batch 1980/4401, Batch Loss: 0.2244, Total Loss: 529.7478\n",
      "Epoch 6/10, Batch 1990/4401, Batch Loss: 0.1973, Total Loss: 533.2297\n",
      "Epoch 6/10, Batch 2000/4401, Batch Loss: 0.6552, Total Loss: 536.2926\n",
      "Epoch 6/10, Batch 2010/4401, Batch Loss: 0.2629, Total Loss: 538.7096\n",
      "Epoch 6/10, Batch 2020/4401, Batch Loss: 1.2625, Total Loss: 541.8171\n",
      "Epoch 6/10, Batch 2030/4401, Batch Loss: 0.0524, Total Loss: 544.6822\n",
      "Epoch 6/10, Batch 2040/4401, Batch Loss: 0.3903, Total Loss: 546.8913\n",
      "Epoch 6/10, Batch 2050/4401, Batch Loss: 0.3020, Total Loss: 549.8617\n",
      "Epoch 6/10, Batch 2060/4401, Batch Loss: 0.1118, Total Loss: 551.7799\n",
      "Epoch 6/10, Batch 2070/4401, Batch Loss: 0.2002, Total Loss: 554.1620\n",
      "Epoch 6/10, Batch 2080/4401, Batch Loss: 0.3250, Total Loss: 557.5661\n",
      "Epoch 6/10, Batch 2090/4401, Batch Loss: 0.2405, Total Loss: 561.2151\n",
      "Epoch 6/10, Batch 2100/4401, Batch Loss: 0.0934, Total Loss: 564.0621\n",
      "Epoch 6/10, Batch 2110/4401, Batch Loss: 0.2543, Total Loss: 566.4723\n",
      "Epoch 6/10, Batch 2120/4401, Batch Loss: 0.3583, Total Loss: 568.3618\n",
      "Epoch 6/10, Batch 2130/4401, Batch Loss: 0.1090, Total Loss: 570.6951\n",
      "Epoch 6/10, Batch 2140/4401, Batch Loss: 0.2480, Total Loss: 573.9298\n",
      "Epoch 6/10, Batch 2150/4401, Batch Loss: 0.2531, Total Loss: 576.3745\n",
      "Epoch 6/10, Batch 2160/4401, Batch Loss: 0.1909, Total Loss: 578.9375\n",
      "Epoch 6/10, Batch 2170/4401, Batch Loss: 0.3440, Total Loss: 581.7805\n",
      "Epoch 6/10, Batch 2180/4401, Batch Loss: 0.2013, Total Loss: 584.3281\n",
      "Epoch 6/10, Batch 2190/4401, Batch Loss: 0.3208, Total Loss: 588.4042\n",
      "Epoch 6/10, Batch 2200/4401, Batch Loss: 0.0617, Total Loss: 590.3075\n",
      "Epoch 6/10, Batch 2210/4401, Batch Loss: 0.0776, Total Loss: 593.1806\n",
      "Epoch 6/10, Batch 2220/4401, Batch Loss: 0.2191, Total Loss: 596.0570\n",
      "Epoch 6/10, Batch 2230/4401, Batch Loss: 0.2889, Total Loss: 598.6039\n",
      "Epoch 6/10, Batch 2240/4401, Batch Loss: 0.2387, Total Loss: 601.1872\n",
      "Epoch 6/10, Batch 2250/4401, Batch Loss: 0.3088, Total Loss: 604.1157\n",
      "Epoch 6/10, Batch 2260/4401, Batch Loss: 0.1143, Total Loss: 606.3992\n",
      "Epoch 6/10, Batch 2270/4401, Batch Loss: 0.1900, Total Loss: 608.4568\n",
      "Epoch 6/10, Batch 2280/4401, Batch Loss: 0.1059, Total Loss: 610.6927\n",
      "Epoch 6/10, Batch 2290/4401, Batch Loss: 0.3171, Total Loss: 613.2684\n",
      "Epoch 6/10, Batch 2300/4401, Batch Loss: 0.0039, Total Loss: 615.9583\n",
      "Epoch 6/10, Batch 2310/4401, Batch Loss: 0.1229, Total Loss: 619.1669\n",
      "Epoch 6/10, Batch 2320/4401, Batch Loss: 0.5559, Total Loss: 621.7099\n",
      "Epoch 6/10, Batch 2330/4401, Batch Loss: 0.2348, Total Loss: 624.2211\n",
      "Epoch 6/10, Batch 2340/4401, Batch Loss: 0.1897, Total Loss: 627.8729\n",
      "Epoch 6/10, Batch 2350/4401, Batch Loss: 0.1817, Total Loss: 629.9924\n",
      "Epoch 6/10, Batch 2360/4401, Batch Loss: 0.3785, Total Loss: 632.6628\n",
      "Epoch 6/10, Batch 2370/4401, Batch Loss: 0.3534, Total Loss: 635.0237\n",
      "Epoch 6/10, Batch 2380/4401, Batch Loss: 0.0028, Total Loss: 637.1980\n",
      "Epoch 6/10, Batch 2390/4401, Batch Loss: 0.2600, Total Loss: 641.5754\n",
      "Epoch 6/10, Batch 2400/4401, Batch Loss: 0.0954, Total Loss: 643.6119\n",
      "Epoch 6/10, Batch 2410/4401, Batch Loss: 0.1616, Total Loss: 645.1213\n",
      "Epoch 6/10, Batch 2420/4401, Batch Loss: 0.7133, Total Loss: 649.2045\n",
      "Epoch 6/10, Batch 2430/4401, Batch Loss: 0.2702, Total Loss: 652.7067\n",
      "Epoch 6/10, Batch 2440/4401, Batch Loss: 1.0223, Total Loss: 655.8618\n",
      "Epoch 6/10, Batch 2450/4401, Batch Loss: 0.0712, Total Loss: 659.2721\n",
      "Epoch 6/10, Batch 2460/4401, Batch Loss: 0.2796, Total Loss: 661.3160\n",
      "Epoch 6/10, Batch 2470/4401, Batch Loss: 0.3776, Total Loss: 664.1663\n",
      "Epoch 6/10, Batch 2480/4401, Batch Loss: 0.3124, Total Loss: 666.9531\n",
      "Epoch 6/10, Batch 2490/4401, Batch Loss: 0.1795, Total Loss: 669.4352\n",
      "Epoch 6/10, Batch 2500/4401, Batch Loss: 0.2053, Total Loss: 671.8243\n",
      "Epoch 6/10, Batch 2510/4401, Batch Loss: 0.4927, Total Loss: 674.7010\n",
      "Epoch 6/10, Batch 2520/4401, Batch Loss: 0.0988, Total Loss: 676.7804\n",
      "Epoch 6/10, Batch 2530/4401, Batch Loss: 0.0453, Total Loss: 679.5564\n",
      "Epoch 6/10, Batch 2540/4401, Batch Loss: 0.2231, Total Loss: 681.7124\n",
      "Epoch 6/10, Batch 2550/4401, Batch Loss: 0.1228, Total Loss: 684.5457\n",
      "Epoch 6/10, Batch 2560/4401, Batch Loss: 0.3984, Total Loss: 687.1639\n",
      "Epoch 6/10, Batch 2570/4401, Batch Loss: 0.4804, Total Loss: 690.7894\n",
      "Epoch 6/10, Batch 2580/4401, Batch Loss: 0.0542, Total Loss: 692.7086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 2590/4401, Batch Loss: 0.2072, Total Loss: 695.1893\n",
      "Epoch 6/10, Batch 2600/4401, Batch Loss: 0.2070, Total Loss: 697.4678\n",
      "Epoch 6/10, Batch 2610/4401, Batch Loss: 0.1027, Total Loss: 699.4114\n",
      "Epoch 6/10, Batch 2620/4401, Batch Loss: 0.2691, Total Loss: 701.1889\n",
      "Epoch 6/10, Batch 2630/4401, Batch Loss: 0.0509, Total Loss: 704.1320\n",
      "Epoch 6/10, Batch 2640/4401, Batch Loss: 0.6216, Total Loss: 706.1051\n",
      "Epoch 6/10, Batch 2650/4401, Batch Loss: 0.2423, Total Loss: 707.6568\n",
      "Epoch 6/10, Batch 2660/4401, Batch Loss: 0.8807, Total Loss: 711.1811\n",
      "Epoch 6/10, Batch 2670/4401, Batch Loss: 0.1420, Total Loss: 714.0881\n",
      "Epoch 6/10, Batch 2680/4401, Batch Loss: 0.3113, Total Loss: 717.8791\n",
      "Epoch 6/10, Batch 2690/4401, Batch Loss: 0.2588, Total Loss: 721.1065\n",
      "Epoch 6/10, Batch 2700/4401, Batch Loss: 0.3651, Total Loss: 723.8093\n",
      "Epoch 6/10, Batch 2710/4401, Batch Loss: 0.2132, Total Loss: 726.2832\n",
      "Epoch 6/10, Batch 2720/4401, Batch Loss: 0.3113, Total Loss: 729.7013\n",
      "Epoch 6/10, Batch 2730/4401, Batch Loss: 0.4040, Total Loss: 732.6352\n",
      "Epoch 6/10, Batch 2740/4401, Batch Loss: 0.2126, Total Loss: 734.6273\n",
      "Epoch 6/10, Batch 2750/4401, Batch Loss: 0.3949, Total Loss: 736.9444\n",
      "Epoch 6/10, Batch 2760/4401, Batch Loss: 0.3716, Total Loss: 738.9849\n",
      "Epoch 6/10, Batch 2770/4401, Batch Loss: 0.0641, Total Loss: 742.0294\n",
      "Epoch 6/10, Batch 2780/4401, Batch Loss: 0.0566, Total Loss: 744.9093\n",
      "Epoch 6/10, Batch 2790/4401, Batch Loss: 0.1501, Total Loss: 747.9274\n",
      "Epoch 6/10, Batch 2800/4401, Batch Loss: 0.2114, Total Loss: 749.9910\n",
      "Epoch 6/10, Batch 2810/4401, Batch Loss: 0.6137, Total Loss: 751.9913\n",
      "Epoch 6/10, Batch 2820/4401, Batch Loss: 0.2772, Total Loss: 754.2353\n",
      "Epoch 6/10, Batch 2830/4401, Batch Loss: 0.2142, Total Loss: 756.0661\n",
      "Epoch 6/10, Batch 2840/4401, Batch Loss: 0.8945, Total Loss: 760.2979\n",
      "Epoch 6/10, Batch 2850/4401, Batch Loss: 0.0748, Total Loss: 762.7933\n",
      "Epoch 6/10, Batch 2860/4401, Batch Loss: 0.1807, Total Loss: 765.5099\n",
      "Epoch 6/10, Batch 2870/4401, Batch Loss: 0.3032, Total Loss: 768.1937\n",
      "Epoch 6/10, Batch 2880/4401, Batch Loss: 0.2023, Total Loss: 771.3577\n",
      "Epoch 6/10, Batch 2890/4401, Batch Loss: 0.1965, Total Loss: 773.7165\n",
      "Epoch 6/10, Batch 2900/4401, Batch Loss: 0.2940, Total Loss: 776.1378\n",
      "Epoch 6/10, Batch 2910/4401, Batch Loss: 0.2683, Total Loss: 779.1743\n",
      "Epoch 6/10, Batch 2920/4401, Batch Loss: 0.2449, Total Loss: 782.2933\n",
      "Epoch 6/10, Batch 2930/4401, Batch Loss: 0.2311, Total Loss: 784.3260\n",
      "Epoch 6/10, Batch 2940/4401, Batch Loss: 0.2032, Total Loss: 786.9098\n",
      "Epoch 6/10, Batch 2950/4401, Batch Loss: 0.1446, Total Loss: 788.8511\n",
      "Epoch 6/10, Batch 2960/4401, Batch Loss: 0.1692, Total Loss: 791.8052\n",
      "Epoch 6/10, Batch 2970/4401, Batch Loss: 0.3577, Total Loss: 795.1111\n",
      "Epoch 6/10, Batch 2980/4401, Batch Loss: 0.2860, Total Loss: 797.9225\n",
      "Epoch 6/10, Batch 2990/4401, Batch Loss: 0.3736, Total Loss: 800.5481\n",
      "Epoch 6/10, Batch 3000/4401, Batch Loss: 0.1844, Total Loss: 804.2508\n",
      "Epoch 6/10, Batch 3010/4401, Batch Loss: 0.2237, Total Loss: 807.0512\n",
      "Epoch 6/10, Batch 3020/4401, Batch Loss: 0.1575, Total Loss: 809.5694\n",
      "Epoch 6/10, Batch 3030/4401, Batch Loss: 0.4528, Total Loss: 811.7913\n",
      "Epoch 6/10, Batch 3040/4401, Batch Loss: 0.2573, Total Loss: 813.7822\n",
      "Epoch 6/10, Batch 3050/4401, Batch Loss: 0.3983, Total Loss: 815.7790\n",
      "Epoch 6/10, Batch 3060/4401, Batch Loss: 0.3412, Total Loss: 818.9601\n",
      "Epoch 6/10, Batch 3070/4401, Batch Loss: 0.3497, Total Loss: 821.0215\n",
      "Epoch 6/10, Batch 3080/4401, Batch Loss: 0.3528, Total Loss: 823.9409\n",
      "Epoch 6/10, Batch 3090/4401, Batch Loss: 0.0774, Total Loss: 826.3783\n",
      "Epoch 6/10, Batch 3100/4401, Batch Loss: 0.2340, Total Loss: 828.3639\n",
      "Epoch 6/10, Batch 3110/4401, Batch Loss: 0.5503, Total Loss: 831.6491\n",
      "Epoch 6/10, Batch 3120/4401, Batch Loss: 0.4552, Total Loss: 834.0916\n",
      "Epoch 6/10, Batch 3130/4401, Batch Loss: 0.1822, Total Loss: 837.4096\n",
      "Epoch 6/10, Batch 3140/4401, Batch Loss: 0.1987, Total Loss: 840.0151\n",
      "Epoch 6/10, Batch 3150/4401, Batch Loss: 0.5834, Total Loss: 844.8791\n",
      "Epoch 6/10, Batch 3160/4401, Batch Loss: 0.0974, Total Loss: 847.2369\n",
      "Epoch 6/10, Batch 3170/4401, Batch Loss: 0.1752, Total Loss: 849.8305\n",
      "Epoch 6/10, Batch 3180/4401, Batch Loss: 0.2940, Total Loss: 853.1486\n",
      "Epoch 6/10, Batch 3190/4401, Batch Loss: 0.0827, Total Loss: 854.9710\n",
      "Epoch 6/10, Batch 3200/4401, Batch Loss: 0.1885, Total Loss: 857.9829\n",
      "Epoch 6/10, Batch 3210/4401, Batch Loss: 0.3038, Total Loss: 860.5279\n",
      "Epoch 6/10, Batch 3220/4401, Batch Loss: 0.0506, Total Loss: 862.7079\n",
      "Epoch 6/10, Batch 3230/4401, Batch Loss: 0.0511, Total Loss: 864.9518\n",
      "Epoch 6/10, Batch 3240/4401, Batch Loss: 1.2346, Total Loss: 868.1816\n",
      "Epoch 6/10, Batch 3250/4401, Batch Loss: 0.1675, Total Loss: 870.0923\n",
      "Epoch 6/10, Batch 3260/4401, Batch Loss: 0.0446, Total Loss: 873.6559\n",
      "Epoch 6/10, Batch 3270/4401, Batch Loss: 0.1499, Total Loss: 876.9074\n",
      "Epoch 6/10, Batch 3280/4401, Batch Loss: 0.0098, Total Loss: 879.3206\n",
      "Epoch 6/10, Batch 3290/4401, Batch Loss: 0.3472, Total Loss: 882.3225\n",
      "Epoch 6/10, Batch 3300/4401, Batch Loss: 0.3329, Total Loss: 885.1953\n",
      "Epoch 6/10, Batch 3310/4401, Batch Loss: 0.1869, Total Loss: 887.4918\n",
      "Epoch 6/10, Batch 3320/4401, Batch Loss: 0.1841, Total Loss: 890.4930\n",
      "Epoch 6/10, Batch 3330/4401, Batch Loss: 0.2944, Total Loss: 893.7782\n",
      "Epoch 6/10, Batch 3340/4401, Batch Loss: 0.5785, Total Loss: 896.2883\n",
      "Epoch 6/10, Batch 3350/4401, Batch Loss: 0.1269, Total Loss: 900.0165\n",
      "Epoch 6/10, Batch 3360/4401, Batch Loss: 0.4884, Total Loss: 903.5497\n",
      "Epoch 6/10, Batch 3370/4401, Batch Loss: 0.3041, Total Loss: 906.2767\n",
      "Epoch 6/10, Batch 3380/4401, Batch Loss: 0.5580, Total Loss: 909.2014\n",
      "Epoch 6/10, Batch 3390/4401, Batch Loss: 0.1757, Total Loss: 911.2246\n",
      "Epoch 6/10, Batch 3400/4401, Batch Loss: 0.1285, Total Loss: 913.5231\n",
      "Epoch 6/10, Batch 3410/4401, Batch Loss: 0.4535, Total Loss: 916.3227\n",
      "Epoch 6/10, Batch 3420/4401, Batch Loss: 0.1120, Total Loss: 918.5505\n",
      "Epoch 6/10, Batch 3430/4401, Batch Loss: 0.2144, Total Loss: 921.5382\n",
      "Epoch 6/10, Batch 3440/4401, Batch Loss: 0.2189, Total Loss: 924.4407\n",
      "Epoch 6/10, Batch 3450/4401, Batch Loss: 0.2091, Total Loss: 926.8449\n",
      "Epoch 6/10, Batch 3460/4401, Batch Loss: 0.0052, Total Loss: 929.3370\n",
      "Epoch 6/10, Batch 3470/4401, Batch Loss: 0.3393, Total Loss: 931.4864\n",
      "Epoch 6/10, Batch 3480/4401, Batch Loss: 0.2780, Total Loss: 933.7324\n",
      "Epoch 6/10, Batch 3490/4401, Batch Loss: 0.2956, Total Loss: 935.7005\n",
      "Epoch 6/10, Batch 3500/4401, Batch Loss: 0.2674, Total Loss: 937.5275\n",
      "Epoch 6/10, Batch 3510/4401, Batch Loss: 0.1349, Total Loss: 939.5235\n",
      "Epoch 6/10, Batch 3520/4401, Batch Loss: 0.3184, Total Loss: 945.1694\n",
      "Epoch 6/10, Batch 3530/4401, Batch Loss: 0.6932, Total Loss: 948.6227\n",
      "Epoch 6/10, Batch 3540/4401, Batch Loss: 0.2860, Total Loss: 952.0209\n",
      "Epoch 6/10, Batch 3550/4401, Batch Loss: 0.2317, Total Loss: 953.9683\n",
      "Epoch 6/10, Batch 3560/4401, Batch Loss: 0.2325, Total Loss: 955.5462\n",
      "Epoch 6/10, Batch 3570/4401, Batch Loss: 0.0043, Total Loss: 958.4269\n",
      "Epoch 6/10, Batch 3580/4401, Batch Loss: 0.1829, Total Loss: 960.7495\n",
      "Epoch 6/10, Batch 3590/4401, Batch Loss: 0.1708, Total Loss: 962.6221\n",
      "Epoch 6/10, Batch 3600/4401, Batch Loss: 0.3377, Total Loss: 965.4731\n",
      "Epoch 6/10, Batch 3610/4401, Batch Loss: 0.2587, Total Loss: 968.2832\n",
      "Epoch 6/10, Batch 3620/4401, Batch Loss: 0.2914, Total Loss: 970.9506\n",
      "Epoch 6/10, Batch 3630/4401, Batch Loss: 0.0022, Total Loss: 973.0636\n",
      "Epoch 6/10, Batch 3640/4401, Batch Loss: 0.3146, Total Loss: 975.3895\n",
      "Epoch 6/10, Batch 3650/4401, Batch Loss: 0.1350, Total Loss: 977.9209\n",
      "Epoch 6/10, Batch 3660/4401, Batch Loss: 0.3377, Total Loss: 980.5713\n",
      "Epoch 6/10, Batch 3670/4401, Batch Loss: 0.4323, Total Loss: 983.2175\n",
      "Epoch 6/10, Batch 3680/4401, Batch Loss: 0.0862, Total Loss: 985.7546\n",
      "Epoch 6/10, Batch 3690/4401, Batch Loss: 0.4100, Total Loss: 988.6946\n",
      "Epoch 6/10, Batch 3700/4401, Batch Loss: 0.3652, Total Loss: 991.3193\n",
      "Epoch 6/10, Batch 3710/4401, Batch Loss: 0.0532, Total Loss: 993.7353\n",
      "Epoch 6/10, Batch 3720/4401, Batch Loss: 0.0888, Total Loss: 995.4244\n",
      "Epoch 6/10, Batch 3730/4401, Batch Loss: 0.3196, Total Loss: 998.7198\n",
      "Epoch 6/10, Batch 3740/4401, Batch Loss: 0.0605, Total Loss: 1000.7872\n",
      "Epoch 6/10, Batch 3750/4401, Batch Loss: 0.7752, Total Loss: 1003.2151\n",
      "Epoch 6/10, Batch 3760/4401, Batch Loss: 0.2856, Total Loss: 1006.2816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 3770/4401, Batch Loss: 0.2125, Total Loss: 1008.3924\n",
      "Epoch 6/10, Batch 3780/4401, Batch Loss: 0.0595, Total Loss: 1010.5460\n",
      "Epoch 6/10, Batch 3790/4401, Batch Loss: 0.1312, Total Loss: 1012.7686\n",
      "Epoch 6/10, Batch 3800/4401, Batch Loss: 0.0976, Total Loss: 1014.3332\n",
      "Epoch 6/10, Batch 3810/4401, Batch Loss: 0.0740, Total Loss: 1016.3509\n",
      "Epoch 6/10, Batch 3820/4401, Batch Loss: 0.4309, Total Loss: 1019.8372\n",
      "Epoch 6/10, Batch 3830/4401, Batch Loss: 0.1838, Total Loss: 1022.6121\n",
      "Epoch 6/10, Batch 3840/4401, Batch Loss: 0.3652, Total Loss: 1025.4206\n",
      "Epoch 6/10, Batch 3850/4401, Batch Loss: 0.2877, Total Loss: 1028.7346\n",
      "Epoch 6/10, Batch 3860/4401, Batch Loss: 0.9022, Total Loss: 1032.4478\n",
      "Epoch 6/10, Batch 3870/4401, Batch Loss: 0.1809, Total Loss: 1035.5137\n",
      "Epoch 6/10, Batch 3880/4401, Batch Loss: 0.1328, Total Loss: 1038.6012\n",
      "Epoch 6/10, Batch 3890/4401, Batch Loss: 0.1983, Total Loss: 1040.9598\n",
      "Epoch 6/10, Batch 3900/4401, Batch Loss: 0.3154, Total Loss: 1044.0034\n",
      "Epoch 6/10, Batch 3910/4401, Batch Loss: 0.4423, Total Loss: 1046.8755\n",
      "Epoch 6/10, Batch 3920/4401, Batch Loss: 0.3224, Total Loss: 1050.0037\n",
      "Epoch 6/10, Batch 3930/4401, Batch Loss: 0.2560, Total Loss: 1051.9600\n",
      "Epoch 6/10, Batch 3940/4401, Batch Loss: 0.0956, Total Loss: 1053.4863\n",
      "Epoch 6/10, Batch 3950/4401, Batch Loss: 0.1190, Total Loss: 1056.0761\n",
      "Epoch 6/10, Batch 3960/4401, Batch Loss: 0.1757, Total Loss: 1058.8892\n",
      "Epoch 6/10, Batch 3970/4401, Batch Loss: 0.2699, Total Loss: 1061.3724\n",
      "Epoch 6/10, Batch 3980/4401, Batch Loss: 0.2673, Total Loss: 1063.4067\n",
      "Epoch 6/10, Batch 3990/4401, Batch Loss: 0.0011, Total Loss: 1065.6039\n",
      "Epoch 6/10, Batch 4000/4401, Batch Loss: 0.4399, Total Loss: 1067.2156\n",
      "Epoch 6/10, Batch 4010/4401, Batch Loss: 0.2831, Total Loss: 1071.0359\n",
      "Epoch 6/10, Batch 4020/4401, Batch Loss: 0.1939, Total Loss: 1074.5980\n",
      "Epoch 6/10, Batch 4030/4401, Batch Loss: 0.3573, Total Loss: 1077.3238\n",
      "Epoch 6/10, Batch 4040/4401, Batch Loss: 0.5683, Total Loss: 1080.2869\n",
      "Epoch 6/10, Batch 4050/4401, Batch Loss: 0.2857, Total Loss: 1082.2879\n",
      "Epoch 6/10, Batch 4060/4401, Batch Loss: 0.1145, Total Loss: 1084.2046\n",
      "Epoch 6/10, Batch 4070/4401, Batch Loss: 0.1776, Total Loss: 1086.3328\n",
      "Epoch 6/10, Batch 4080/4401, Batch Loss: 0.6646, Total Loss: 1089.7277\n",
      "Epoch 6/10, Batch 4090/4401, Batch Loss: 0.3717, Total Loss: 1092.2769\n",
      "Epoch 6/10, Batch 4100/4401, Batch Loss: 0.0595, Total Loss: 1096.0625\n",
      "Epoch 6/10, Batch 4110/4401, Batch Loss: 0.1101, Total Loss: 1098.5212\n",
      "Epoch 6/10, Batch 4120/4401, Batch Loss: 0.2096, Total Loss: 1101.1788\n",
      "Epoch 6/10, Batch 4130/4401, Batch Loss: 0.0589, Total Loss: 1103.6234\n",
      "Epoch 6/10, Batch 4140/4401, Batch Loss: 0.2733, Total Loss: 1106.5260\n",
      "Epoch 6/10, Batch 4150/4401, Batch Loss: 0.3624, Total Loss: 1109.4396\n",
      "Epoch 6/10, Batch 4160/4401, Batch Loss: 0.0876, Total Loss: 1112.5359\n",
      "Epoch 6/10, Batch 4170/4401, Batch Loss: 0.1205, Total Loss: 1115.3240\n",
      "Epoch 6/10, Batch 4180/4401, Batch Loss: 0.3468, Total Loss: 1117.7383\n",
      "Epoch 6/10, Batch 4190/4401, Batch Loss: 0.2976, Total Loss: 1119.7983\n",
      "Epoch 6/10, Batch 4200/4401, Batch Loss: 0.2587, Total Loss: 1122.7258\n",
      "Epoch 6/10, Batch 4210/4401, Batch Loss: 0.0788, Total Loss: 1125.2974\n",
      "Epoch 6/10, Batch 4220/4401, Batch Loss: 0.2491, Total Loss: 1128.6075\n",
      "Epoch 6/10, Batch 4230/4401, Batch Loss: 0.2453, Total Loss: 1131.2190\n",
      "Epoch 6/10, Batch 4240/4401, Batch Loss: 0.2286, Total Loss: 1133.8381\n",
      "Epoch 6/10, Batch 4250/4401, Batch Loss: 0.2896, Total Loss: 1135.9905\n",
      "Epoch 6/10, Batch 4260/4401, Batch Loss: 0.1155, Total Loss: 1139.3650\n",
      "Epoch 6/10, Batch 4270/4401, Batch Loss: 0.0954, Total Loss: 1140.7914\n",
      "Epoch 6/10, Batch 4280/4401, Batch Loss: 0.1734, Total Loss: 1142.8887\n",
      "Epoch 6/10, Batch 4290/4401, Batch Loss: 0.2424, Total Loss: 1146.2823\n",
      "Epoch 6/10, Batch 4300/4401, Batch Loss: 0.4556, Total Loss: 1148.4466\n",
      "Epoch 6/10, Batch 4310/4401, Batch Loss: 0.5228, Total Loss: 1151.8734\n",
      "Epoch 6/10, Batch 4320/4401, Batch Loss: 0.1608, Total Loss: 1155.2479\n",
      "Epoch 6/10, Batch 4330/4401, Batch Loss: 0.2190, Total Loss: 1157.7989\n",
      "Epoch 6/10, Batch 4340/4401, Batch Loss: 0.1228, Total Loss: 1160.1903\n",
      "Epoch 6/10, Batch 4350/4401, Batch Loss: 0.1710, Total Loss: 1162.9133\n",
      "Epoch 6/10, Batch 4360/4401, Batch Loss: 0.2470, Total Loss: 1165.6765\n",
      "Epoch 6/10, Batch 4370/4401, Batch Loss: 0.1324, Total Loss: 1169.0749\n",
      "Epoch 6/10, Batch 4380/4401, Batch Loss: 0.0595, Total Loss: 1170.9875\n",
      "Epoch 6/10, Batch 4390/4401, Batch Loss: 0.2226, Total Loss: 1173.6066\n",
      "Epoch 6/10, Batch 4400/4401, Batch Loss: 0.2337, Total Loss: 1176.3479\n",
      "Epoch 6/10, Batch 4401/4401, Batch Loss: 0.0544, Total Loss: 1176.4022\n",
      "Epoch 6/10 completed. Total Loss: 1176.4022\n",
      "\n",
      "Epoch 7/10 running...\n",
      "cuda:0\n",
      "Epoch 7/10, Batch 10/4401, Batch Loss: 0.0614, Total Loss: 2.3696\n",
      "Epoch 7/10, Batch 20/4401, Batch Loss: 0.3622, Total Loss: 4.6730\n",
      "Epoch 7/10, Batch 30/4401, Batch Loss: 0.4876, Total Loss: 8.3607\n",
      "Epoch 7/10, Batch 40/4401, Batch Loss: 0.2003, Total Loss: 10.8292\n",
      "Epoch 7/10, Batch 50/4401, Batch Loss: 0.0987, Total Loss: 13.6795\n",
      "Epoch 7/10, Batch 60/4401, Batch Loss: 0.2629, Total Loss: 15.7262\n",
      "Epoch 7/10, Batch 70/4401, Batch Loss: 0.1272, Total Loss: 18.2214\n",
      "Epoch 7/10, Batch 80/4401, Batch Loss: 0.2043, Total Loss: 20.4561\n",
      "Epoch 7/10, Batch 90/4401, Batch Loss: 0.0060, Total Loss: 22.0430\n",
      "Epoch 7/10, Batch 100/4401, Batch Loss: 0.1810, Total Loss: 25.1303\n",
      "Epoch 7/10, Batch 110/4401, Batch Loss: 0.3946, Total Loss: 27.8251\n",
      "Epoch 7/10, Batch 120/4401, Batch Loss: 0.1549, Total Loss: 29.8937\n",
      "Epoch 7/10, Batch 130/4401, Batch Loss: 1.0355, Total Loss: 33.5736\n",
      "Epoch 7/10, Batch 140/4401, Batch Loss: 0.3896, Total Loss: 36.7051\n",
      "Epoch 7/10, Batch 150/4401, Batch Loss: 0.0810, Total Loss: 39.1018\n",
      "Epoch 7/10, Batch 160/4401, Batch Loss: 0.5732, Total Loss: 41.4697\n",
      "Epoch 7/10, Batch 170/4401, Batch Loss: 0.1962, Total Loss: 44.5248\n",
      "Epoch 7/10, Batch 180/4401, Batch Loss: 1.3350, Total Loss: 47.9891\n",
      "Epoch 7/10, Batch 190/4401, Batch Loss: 0.2160, Total Loss: 50.3547\n",
      "Epoch 7/10, Batch 200/4401, Batch Loss: 0.4034, Total Loss: 52.7954\n",
      "Epoch 7/10, Batch 210/4401, Batch Loss: 0.1211, Total Loss: 54.6546\n",
      "Epoch 7/10, Batch 220/4401, Batch Loss: 0.1387, Total Loss: 57.6024\n",
      "Epoch 7/10, Batch 230/4401, Batch Loss: 0.2094, Total Loss: 59.6600\n",
      "Epoch 7/10, Batch 240/4401, Batch Loss: 0.2296, Total Loss: 62.3650\n",
      "Epoch 7/10, Batch 250/4401, Batch Loss: 0.5763, Total Loss: 65.6147\n",
      "Epoch 7/10, Batch 260/4401, Batch Loss: 0.2407, Total Loss: 68.4489\n",
      "Epoch 7/10, Batch 270/4401, Batch Loss: 0.1160, Total Loss: 70.3580\n",
      "Epoch 7/10, Batch 280/4401, Batch Loss: 0.3354, Total Loss: 73.7629\n",
      "Epoch 7/10, Batch 290/4401, Batch Loss: 0.0647, Total Loss: 76.0589\n",
      "Epoch 7/10, Batch 300/4401, Batch Loss: 0.2835, Total Loss: 78.8822\n",
      "Epoch 7/10, Batch 310/4401, Batch Loss: 0.5010, Total Loss: 82.1132\n",
      "Epoch 7/10, Batch 320/4401, Batch Loss: 0.1489, Total Loss: 84.1355\n",
      "Epoch 7/10, Batch 330/4401, Batch Loss: 0.1499, Total Loss: 87.0501\n",
      "Epoch 7/10, Batch 340/4401, Batch Loss: 0.4031, Total Loss: 90.3051\n",
      "Epoch 7/10, Batch 350/4401, Batch Loss: 0.2905, Total Loss: 93.5940\n",
      "Epoch 7/10, Batch 360/4401, Batch Loss: 0.4523, Total Loss: 95.7140\n",
      "Epoch 7/10, Batch 370/4401, Batch Loss: 0.5226, Total Loss: 98.5021\n",
      "Epoch 7/10, Batch 380/4401, Batch Loss: 0.2511, Total Loss: 100.4877\n",
      "Epoch 7/10, Batch 390/4401, Batch Loss: 0.4430, Total Loss: 103.9039\n",
      "Epoch 7/10, Batch 400/4401, Batch Loss: 0.2109, Total Loss: 106.3998\n",
      "Epoch 7/10, Batch 410/4401, Batch Loss: 0.1433, Total Loss: 108.4567\n",
      "Epoch 7/10, Batch 420/4401, Batch Loss: 0.0464, Total Loss: 110.2744\n",
      "Epoch 7/10, Batch 430/4401, Batch Loss: 0.6029, Total Loss: 112.7857\n",
      "Epoch 7/10, Batch 440/4401, Batch Loss: 0.3820, Total Loss: 114.6043\n",
      "Epoch 7/10, Batch 450/4401, Batch Loss: 0.3563, Total Loss: 116.6213\n",
      "Epoch 7/10, Batch 460/4401, Batch Loss: 0.2525, Total Loss: 118.8801\n",
      "Epoch 7/10, Batch 470/4401, Batch Loss: 0.3796, Total Loss: 121.9194\n",
      "Epoch 7/10, Batch 480/4401, Batch Loss: 0.2129, Total Loss: 124.0255\n",
      "Epoch 7/10, Batch 490/4401, Batch Loss: 0.3394, Total Loss: 127.1460\n",
      "Epoch 7/10, Batch 500/4401, Batch Loss: 0.0839, Total Loss: 130.0375\n",
      "Epoch 7/10, Batch 510/4401, Batch Loss: 0.4940, Total Loss: 133.1401\n",
      "Epoch 7/10, Batch 520/4401, Batch Loss: 0.2681, Total Loss: 135.5178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 530/4401, Batch Loss: 0.3942, Total Loss: 138.6642\n",
      "Epoch 7/10, Batch 540/4401, Batch Loss: 0.0143, Total Loss: 141.9221\n",
      "Epoch 7/10, Batch 550/4401, Batch Loss: 0.0705, Total Loss: 143.2508\n",
      "Epoch 7/10, Batch 560/4401, Batch Loss: 0.1634, Total Loss: 145.9866\n",
      "Epoch 7/10, Batch 570/4401, Batch Loss: 0.0915, Total Loss: 148.6929\n",
      "Epoch 7/10, Batch 580/4401, Batch Loss: 0.1261, Total Loss: 151.0981\n",
      "Epoch 7/10, Batch 590/4401, Batch Loss: 0.0685, Total Loss: 152.9764\n",
      "Epoch 7/10, Batch 600/4401, Batch Loss: 0.3010, Total Loss: 155.1506\n",
      "Epoch 7/10, Batch 610/4401, Batch Loss: 0.1721, Total Loss: 157.3041\n",
      "Epoch 7/10, Batch 620/4401, Batch Loss: 0.0816, Total Loss: 161.0205\n",
      "Epoch 7/10, Batch 630/4401, Batch Loss: 0.4455, Total Loss: 163.4223\n",
      "Epoch 7/10, Batch 640/4401, Batch Loss: 0.4827, Total Loss: 166.0481\n",
      "Epoch 7/10, Batch 650/4401, Batch Loss: 0.3072, Total Loss: 168.8331\n",
      "Epoch 7/10, Batch 660/4401, Batch Loss: 0.4968, Total Loss: 171.3795\n",
      "Epoch 7/10, Batch 670/4401, Batch Loss: 0.4746, Total Loss: 174.4417\n",
      "Epoch 7/10, Batch 680/4401, Batch Loss: 0.1771, Total Loss: 177.5585\n",
      "Epoch 7/10, Batch 690/4401, Batch Loss: 0.0577, Total Loss: 179.1174\n",
      "Epoch 7/10, Batch 700/4401, Batch Loss: 0.1498, Total Loss: 181.2469\n",
      "Epoch 7/10, Batch 710/4401, Batch Loss: 0.0764, Total Loss: 184.2365\n",
      "Epoch 7/10, Batch 720/4401, Batch Loss: 0.2997, Total Loss: 187.3084\n",
      "Epoch 7/10, Batch 730/4401, Batch Loss: 0.2200, Total Loss: 189.5025\n",
      "Epoch 7/10, Batch 740/4401, Batch Loss: 0.2487, Total Loss: 192.8800\n",
      "Epoch 7/10, Batch 750/4401, Batch Loss: 0.0968, Total Loss: 195.2471\n",
      "Epoch 7/10, Batch 760/4401, Batch Loss: 0.1426, Total Loss: 197.3194\n",
      "Epoch 7/10, Batch 770/4401, Batch Loss: 0.3905, Total Loss: 200.0592\n",
      "Epoch 7/10, Batch 780/4401, Batch Loss: 0.2737, Total Loss: 202.7620\n",
      "Epoch 7/10, Batch 790/4401, Batch Loss: 0.1500, Total Loss: 206.1705\n",
      "Epoch 7/10, Batch 800/4401, Batch Loss: 0.2615, Total Loss: 209.0650\n",
      "Epoch 7/10, Batch 810/4401, Batch Loss: 0.3277, Total Loss: 212.5424\n",
      "Epoch 7/10, Batch 820/4401, Batch Loss: 0.1892, Total Loss: 214.6620\n",
      "Epoch 7/10, Batch 830/4401, Batch Loss: 0.1789, Total Loss: 216.9005\n",
      "Epoch 7/10, Batch 840/4401, Batch Loss: 0.3337, Total Loss: 219.0121\n",
      "Epoch 7/10, Batch 850/4401, Batch Loss: 0.0953, Total Loss: 222.2780\n",
      "Epoch 7/10, Batch 860/4401, Batch Loss: 0.2807, Total Loss: 225.4837\n",
      "Epoch 7/10, Batch 870/4401, Batch Loss: 0.0537, Total Loss: 227.6415\n",
      "Epoch 7/10, Batch 880/4401, Batch Loss: 0.1896, Total Loss: 230.8591\n",
      "Epoch 7/10, Batch 890/4401, Batch Loss: 0.1110, Total Loss: 233.2890\n",
      "Epoch 7/10, Batch 900/4401, Batch Loss: 0.3344, Total Loss: 235.8548\n",
      "Epoch 7/10, Batch 910/4401, Batch Loss: 0.1259, Total Loss: 238.1593\n",
      "Epoch 7/10, Batch 920/4401, Batch Loss: 0.2550, Total Loss: 239.7641\n",
      "Epoch 7/10, Batch 930/4401, Batch Loss: 0.2123, Total Loss: 242.0582\n",
      "Epoch 7/10, Batch 940/4401, Batch Loss: 0.4847, Total Loss: 245.3142\n",
      "Epoch 7/10, Batch 950/4401, Batch Loss: 0.0652, Total Loss: 247.6049\n",
      "Epoch 7/10, Batch 960/4401, Batch Loss: 0.0617, Total Loss: 249.4296\n",
      "Epoch 7/10, Batch 970/4401, Batch Loss: 0.1146, Total Loss: 252.3863\n",
      "Epoch 7/10, Batch 980/4401, Batch Loss: 0.1194, Total Loss: 254.3917\n",
      "Epoch 7/10, Batch 990/4401, Batch Loss: 0.3304, Total Loss: 256.3626\n",
      "Epoch 7/10, Batch 1000/4401, Batch Loss: 0.1593, Total Loss: 258.2836\n",
      "Epoch 7/10, Batch 1010/4401, Batch Loss: 0.3925, Total Loss: 262.1105\n",
      "Epoch 7/10, Batch 1020/4401, Batch Loss: 0.1625, Total Loss: 264.8176\n",
      "Epoch 7/10, Batch 1030/4401, Batch Loss: 0.4228, Total Loss: 267.5444\n",
      "Epoch 7/10, Batch 1040/4401, Batch Loss: 0.1702, Total Loss: 269.5313\n",
      "Epoch 7/10, Batch 1050/4401, Batch Loss: 0.1330, Total Loss: 271.8068\n",
      "Epoch 7/10, Batch 1060/4401, Batch Loss: 0.1748, Total Loss: 273.9472\n",
      "Epoch 7/10, Batch 1070/4401, Batch Loss: 0.8295, Total Loss: 277.0466\n",
      "Epoch 7/10, Batch 1080/4401, Batch Loss: 0.3918, Total Loss: 279.8111\n",
      "Epoch 7/10, Batch 1090/4401, Batch Loss: 0.7240, Total Loss: 283.4028\n",
      "Epoch 7/10, Batch 1100/4401, Batch Loss: 0.0016, Total Loss: 285.7505\n",
      "Epoch 7/10, Batch 1110/4401, Batch Loss: 0.1497, Total Loss: 288.6883\n",
      "Epoch 7/10, Batch 1120/4401, Batch Loss: 0.2504, Total Loss: 291.0398\n",
      "Epoch 7/10, Batch 1130/4401, Batch Loss: 0.3833, Total Loss: 293.7740\n",
      "Epoch 7/10, Batch 1140/4401, Batch Loss: 0.2193, Total Loss: 296.1503\n",
      "Epoch 7/10, Batch 1150/4401, Batch Loss: 0.2926, Total Loss: 299.0419\n",
      "Epoch 7/10, Batch 1160/4401, Batch Loss: 0.1652, Total Loss: 301.8905\n",
      "Epoch 7/10, Batch 1170/4401, Batch Loss: 0.2671, Total Loss: 303.7787\n",
      "Epoch 7/10, Batch 1180/4401, Batch Loss: 0.0425, Total Loss: 306.4919\n",
      "Epoch 7/10, Batch 1190/4401, Batch Loss: 0.1503, Total Loss: 310.0153\n",
      "Epoch 7/10, Batch 1200/4401, Batch Loss: 0.1319, Total Loss: 313.1759\n",
      "Epoch 7/10, Batch 1210/4401, Batch Loss: 0.2408, Total Loss: 315.5140\n",
      "Epoch 7/10, Batch 1220/4401, Batch Loss: 0.4558, Total Loss: 318.2844\n",
      "Epoch 7/10, Batch 1230/4401, Batch Loss: 0.0823, Total Loss: 320.5172\n",
      "Epoch 7/10, Batch 1240/4401, Batch Loss: 0.2864, Total Loss: 322.6261\n",
      "Epoch 7/10, Batch 1250/4401, Batch Loss: 0.2598, Total Loss: 326.4710\n",
      "Epoch 7/10, Batch 1260/4401, Batch Loss: 0.4807, Total Loss: 329.0345\n",
      "Epoch 7/10, Batch 1270/4401, Batch Loss: 0.2339, Total Loss: 331.0053\n",
      "Epoch 7/10, Batch 1280/4401, Batch Loss: 0.0034, Total Loss: 333.2951\n",
      "Epoch 7/10, Batch 1290/4401, Batch Loss: 0.1087, Total Loss: 335.2573\n",
      "Epoch 7/10, Batch 1300/4401, Batch Loss: 0.1536, Total Loss: 337.6119\n",
      "Epoch 7/10, Batch 1310/4401, Batch Loss: 0.2195, Total Loss: 339.5232\n",
      "Epoch 7/10, Batch 1320/4401, Batch Loss: 0.1286, Total Loss: 341.9046\n",
      "Epoch 7/10, Batch 1330/4401, Batch Loss: 0.1408, Total Loss: 343.3854\n",
      "Epoch 7/10, Batch 1340/4401, Batch Loss: 0.0927, Total Loss: 345.5160\n",
      "Epoch 7/10, Batch 1350/4401, Batch Loss: 0.1767, Total Loss: 347.8352\n",
      "Epoch 7/10, Batch 1360/4401, Batch Loss: 0.2605, Total Loss: 350.7483\n",
      "Epoch 7/10, Batch 1370/4401, Batch Loss: 0.3466, Total Loss: 353.1424\n",
      "Epoch 7/10, Batch 1380/4401, Batch Loss: 0.4560, Total Loss: 355.7449\n",
      "Epoch 7/10, Batch 1390/4401, Batch Loss: 0.1566, Total Loss: 358.0106\n",
      "Epoch 7/10, Batch 1400/4401, Batch Loss: 0.3057, Total Loss: 361.1349\n",
      "Epoch 7/10, Batch 1410/4401, Batch Loss: 0.2106, Total Loss: 362.7870\n",
      "Epoch 7/10, Batch 1420/4401, Batch Loss: 0.4532, Total Loss: 365.5791\n",
      "Epoch 7/10, Batch 1430/4401, Batch Loss: 0.1397, Total Loss: 368.7771\n",
      "Epoch 7/10, Batch 1440/4401, Batch Loss: 0.1173, Total Loss: 370.4786\n",
      "Epoch 7/10, Batch 1450/4401, Batch Loss: 0.0312, Total Loss: 372.7920\n",
      "Epoch 7/10, Batch 1460/4401, Batch Loss: 0.2295, Total Loss: 375.0686\n",
      "Epoch 7/10, Batch 1470/4401, Batch Loss: 0.2367, Total Loss: 377.0393\n",
      "Epoch 7/10, Batch 1480/4401, Batch Loss: 0.0886, Total Loss: 378.5728\n",
      "Epoch 7/10, Batch 1490/4401, Batch Loss: 0.3835, Total Loss: 381.7793\n",
      "Epoch 7/10, Batch 1500/4401, Batch Loss: 0.2809, Total Loss: 384.5134\n",
      "Epoch 7/10, Batch 1510/4401, Batch Loss: 0.1459, Total Loss: 386.7339\n",
      "Epoch 7/10, Batch 1520/4401, Batch Loss: 0.2790, Total Loss: 389.1678\n",
      "Epoch 7/10, Batch 1530/4401, Batch Loss: 0.5398, Total Loss: 393.3065\n",
      "Epoch 7/10, Batch 1540/4401, Batch Loss: 0.3631, Total Loss: 396.2726\n",
      "Epoch 7/10, Batch 1550/4401, Batch Loss: 0.2852, Total Loss: 399.7584\n",
      "Epoch 7/10, Batch 1560/4401, Batch Loss: 0.3341, Total Loss: 402.6404\n",
      "Epoch 7/10, Batch 1570/4401, Batch Loss: 0.2323, Total Loss: 405.5837\n",
      "Epoch 7/10, Batch 1580/4401, Batch Loss: 0.2488, Total Loss: 407.9043\n",
      "Epoch 7/10, Batch 1590/4401, Batch Loss: 0.1710, Total Loss: 409.4077\n",
      "Epoch 7/10, Batch 1600/4401, Batch Loss: 0.2892, Total Loss: 411.8759\n",
      "Epoch 7/10, Batch 1610/4401, Batch Loss: 0.1893, Total Loss: 414.5417\n",
      "Epoch 7/10, Batch 1620/4401, Batch Loss: 0.3559, Total Loss: 417.7930\n",
      "Epoch 7/10, Batch 1630/4401, Batch Loss: 0.1625, Total Loss: 419.7307\n",
      "Epoch 7/10, Batch 1640/4401, Batch Loss: 0.2569, Total Loss: 422.3723\n",
      "Epoch 7/10, Batch 1650/4401, Batch Loss: 0.4262, Total Loss: 424.7828\n",
      "Epoch 7/10, Batch 1660/4401, Batch Loss: 0.3712, Total Loss: 427.0673\n",
      "Epoch 7/10, Batch 1670/4401, Batch Loss: 0.2529, Total Loss: 428.8512\n",
      "Epoch 7/10, Batch 1680/4401, Batch Loss: 0.2597, Total Loss: 430.5290\n",
      "Epoch 7/10, Batch 1690/4401, Batch Loss: 0.2229, Total Loss: 432.6912\n",
      "Epoch 7/10, Batch 1700/4401, Batch Loss: 0.0674, Total Loss: 435.2591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1710/4401, Batch Loss: 0.0009, Total Loss: 437.5390\n",
      "Epoch 7/10, Batch 1720/4401, Batch Loss: 0.2496, Total Loss: 439.9783\n",
      "Epoch 7/10, Batch 1730/4401, Batch Loss: 0.4659, Total Loss: 442.0459\n",
      "Epoch 7/10, Batch 1740/4401, Batch Loss: 0.5121, Total Loss: 444.4439\n",
      "Epoch 7/10, Batch 1750/4401, Batch Loss: 0.0701, Total Loss: 447.7976\n",
      "Epoch 7/10, Batch 1760/4401, Batch Loss: 0.4028, Total Loss: 452.0671\n",
      "Epoch 7/10, Batch 1770/4401, Batch Loss: 0.2245, Total Loss: 453.7438\n",
      "Epoch 7/10, Batch 1780/4401, Batch Loss: 1.1819, Total Loss: 456.8402\n",
      "Epoch 7/10, Batch 1790/4401, Batch Loss: 0.5138, Total Loss: 459.0793\n",
      "Epoch 7/10, Batch 1800/4401, Batch Loss: 0.5009, Total Loss: 460.9294\n",
      "Epoch 7/10, Batch 1810/4401, Batch Loss: 0.2696, Total Loss: 464.1985\n",
      "Epoch 7/10, Batch 1820/4401, Batch Loss: 0.3956, Total Loss: 465.9652\n",
      "Epoch 7/10, Batch 1830/4401, Batch Loss: 0.1519, Total Loss: 468.1847\n",
      "Epoch 7/10, Batch 1840/4401, Batch Loss: 0.1129, Total Loss: 470.4766\n",
      "Epoch 7/10, Batch 1850/4401, Batch Loss: 0.1256, Total Loss: 472.6120\n",
      "Epoch 7/10, Batch 1860/4401, Batch Loss: 0.1753, Total Loss: 474.4998\n",
      "Epoch 7/10, Batch 1870/4401, Batch Loss: 0.0010, Total Loss: 475.7778\n",
      "Epoch 7/10, Batch 1880/4401, Batch Loss: 0.1571, Total Loss: 477.2673\n",
      "Epoch 7/10, Batch 1890/4401, Batch Loss: 0.2199, Total Loss: 479.8402\n",
      "Epoch 7/10, Batch 1900/4401, Batch Loss: 0.6489, Total Loss: 482.4264\n",
      "Epoch 7/10, Batch 1910/4401, Batch Loss: 0.4002, Total Loss: 485.3655\n",
      "Epoch 7/10, Batch 1920/4401, Batch Loss: 0.7347, Total Loss: 487.6929\n",
      "Epoch 7/10, Batch 1930/4401, Batch Loss: 0.2281, Total Loss: 491.1483\n",
      "Epoch 7/10, Batch 1940/4401, Batch Loss: 0.0968, Total Loss: 493.8742\n",
      "Epoch 7/10, Batch 1950/4401, Batch Loss: 0.6127, Total Loss: 496.8723\n",
      "Epoch 7/10, Batch 1960/4401, Batch Loss: 0.3167, Total Loss: 499.6472\n",
      "Epoch 7/10, Batch 1970/4401, Batch Loss: 0.3110, Total Loss: 503.1610\n",
      "Epoch 7/10, Batch 1980/4401, Batch Loss: 0.2507, Total Loss: 505.5216\n",
      "Epoch 7/10, Batch 1990/4401, Batch Loss: 0.3140, Total Loss: 508.1718\n",
      "Epoch 7/10, Batch 2000/4401, Batch Loss: 0.1228, Total Loss: 511.8199\n",
      "Epoch 7/10, Batch 2010/4401, Batch Loss: 0.2484, Total Loss: 513.9575\n",
      "Epoch 7/10, Batch 2020/4401, Batch Loss: 0.1747, Total Loss: 516.6850\n",
      "Epoch 7/10, Batch 2030/4401, Batch Loss: 0.0027, Total Loss: 519.2088\n",
      "Epoch 7/10, Batch 2040/4401, Batch Loss: 1.0336, Total Loss: 522.0514\n",
      "Epoch 7/10, Batch 2050/4401, Batch Loss: 0.1254, Total Loss: 524.7934\n",
      "Epoch 7/10, Batch 2060/4401, Batch Loss: 0.0723, Total Loss: 525.9991\n",
      "Epoch 7/10, Batch 2070/4401, Batch Loss: 0.3146, Total Loss: 528.1848\n",
      "Epoch 7/10, Batch 2080/4401, Batch Loss: 0.1322, Total Loss: 530.1119\n",
      "Epoch 7/10, Batch 2090/4401, Batch Loss: 0.3239, Total Loss: 532.5320\n",
      "Epoch 7/10, Batch 2100/4401, Batch Loss: 0.2125, Total Loss: 534.3620\n",
      "Epoch 7/10, Batch 2110/4401, Batch Loss: 0.2050, Total Loss: 537.9617\n",
      "Epoch 7/10, Batch 2120/4401, Batch Loss: 0.1273, Total Loss: 541.0047\n",
      "Epoch 7/10, Batch 2130/4401, Batch Loss: 0.1390, Total Loss: 542.0867\n",
      "Epoch 7/10, Batch 2140/4401, Batch Loss: 0.3001, Total Loss: 545.3745\n",
      "Epoch 7/10, Batch 2150/4401, Batch Loss: 0.1593, Total Loss: 548.5967\n",
      "Epoch 7/10, Batch 2160/4401, Batch Loss: 0.1124, Total Loss: 551.2283\n",
      "Epoch 7/10, Batch 2170/4401, Batch Loss: 0.1158, Total Loss: 554.3378\n",
      "Epoch 7/10, Batch 2180/4401, Batch Loss: 0.1460, Total Loss: 556.7573\n",
      "Epoch 7/10, Batch 2190/4401, Batch Loss: 0.0552, Total Loss: 557.9298\n",
      "Epoch 7/10, Batch 2200/4401, Batch Loss: 0.1561, Total Loss: 560.9675\n",
      "Epoch 7/10, Batch 2210/4401, Batch Loss: 0.2362, Total Loss: 564.3898\n",
      "Epoch 7/10, Batch 2220/4401, Batch Loss: 0.1731, Total Loss: 567.0405\n",
      "Epoch 7/10, Batch 2230/4401, Batch Loss: 0.2744, Total Loss: 569.2632\n",
      "Epoch 7/10, Batch 2240/4401, Batch Loss: 0.2838, Total Loss: 572.0581\n",
      "Epoch 7/10, Batch 2250/4401, Batch Loss: 0.1856, Total Loss: 575.4444\n",
      "Epoch 7/10, Batch 2260/4401, Batch Loss: 0.1208, Total Loss: 577.7285\n",
      "Epoch 7/10, Batch 2270/4401, Batch Loss: 0.2631, Total Loss: 579.9815\n",
      "Epoch 7/10, Batch 2280/4401, Batch Loss: 0.2529, Total Loss: 582.5599\n",
      "Epoch 7/10, Batch 2290/4401, Batch Loss: 0.3983, Total Loss: 586.1354\n",
      "Epoch 7/10, Batch 2300/4401, Batch Loss: 0.0491, Total Loss: 589.0582\n",
      "Epoch 7/10, Batch 2310/4401, Batch Loss: 0.3357, Total Loss: 590.9726\n",
      "Epoch 7/10, Batch 2320/4401, Batch Loss: 0.3587, Total Loss: 593.7229\n",
      "Epoch 7/10, Batch 2330/4401, Batch Loss: 0.2396, Total Loss: 595.9313\n",
      "Epoch 7/10, Batch 2340/4401, Batch Loss: 0.0010, Total Loss: 597.2494\n",
      "Epoch 7/10, Batch 2350/4401, Batch Loss: 0.3455, Total Loss: 599.6270\n",
      "Epoch 7/10, Batch 2360/4401, Batch Loss: 0.2757, Total Loss: 601.8755\n",
      "Epoch 7/10, Batch 2370/4401, Batch Loss: 0.3803, Total Loss: 604.7110\n",
      "Epoch 7/10, Batch 2380/4401, Batch Loss: 0.3143, Total Loss: 606.4277\n",
      "Epoch 7/10, Batch 2390/4401, Batch Loss: 0.1889, Total Loss: 608.7310\n",
      "Epoch 7/10, Batch 2400/4401, Batch Loss: 0.3582, Total Loss: 611.1031\n",
      "Epoch 7/10, Batch 2410/4401, Batch Loss: 0.1609, Total Loss: 613.7914\n",
      "Epoch 7/10, Batch 2420/4401, Batch Loss: 0.0546, Total Loss: 615.4052\n",
      "Epoch 7/10, Batch 2430/4401, Batch Loss: 0.3858, Total Loss: 617.7461\n",
      "Epoch 7/10, Batch 2440/4401, Batch Loss: 0.2743, Total Loss: 620.7454\n",
      "Epoch 7/10, Batch 2450/4401, Batch Loss: 0.4471, Total Loss: 623.6988\n",
      "Epoch 7/10, Batch 2460/4401, Batch Loss: 0.4145, Total Loss: 625.8466\n",
      "Epoch 7/10, Batch 2470/4401, Batch Loss: 0.1751, Total Loss: 627.6036\n",
      "Epoch 7/10, Batch 2480/4401, Batch Loss: 0.0056, Total Loss: 630.2933\n",
      "Epoch 7/10, Batch 2490/4401, Batch Loss: 0.0544, Total Loss: 633.2717\n",
      "Epoch 7/10, Batch 2500/4401, Batch Loss: 0.0763, Total Loss: 634.9466\n",
      "Epoch 7/10, Batch 2510/4401, Batch Loss: 0.2822, Total Loss: 637.6866\n",
      "Epoch 7/10, Batch 2520/4401, Batch Loss: 0.0024, Total Loss: 640.8729\n",
      "Epoch 7/10, Batch 2530/4401, Batch Loss: 0.2488, Total Loss: 644.1926\n",
      "Epoch 7/10, Batch 2540/4401, Batch Loss: 0.1787, Total Loss: 646.9104\n",
      "Epoch 7/10, Batch 2550/4401, Batch Loss: 0.1142, Total Loss: 648.5757\n",
      "Epoch 7/10, Batch 2560/4401, Batch Loss: 0.1625, Total Loss: 650.8872\n",
      "Epoch 7/10, Batch 2570/4401, Batch Loss: 0.4352, Total Loss: 653.3923\n",
      "Epoch 7/10, Batch 2580/4401, Batch Loss: 0.1104, Total Loss: 655.9965\n",
      "Epoch 7/10, Batch 2590/4401, Batch Loss: 0.1455, Total Loss: 658.4234\n",
      "Epoch 7/10, Batch 2600/4401, Batch Loss: 0.2011, Total Loss: 659.8388\n",
      "Epoch 7/10, Batch 2610/4401, Batch Loss: 0.2901, Total Loss: 661.7482\n",
      "Epoch 7/10, Batch 2620/4401, Batch Loss: 0.1706, Total Loss: 663.6765\n",
      "Epoch 7/10, Batch 2630/4401, Batch Loss: 0.2851, Total Loss: 665.1314\n",
      "Epoch 7/10, Batch 2640/4401, Batch Loss: 0.4345, Total Loss: 667.5175\n",
      "Epoch 7/10, Batch 2650/4401, Batch Loss: 0.3221, Total Loss: 670.0594\n",
      "Epoch 7/10, Batch 2660/4401, Batch Loss: 0.3366, Total Loss: 673.0339\n",
      "Epoch 7/10, Batch 2670/4401, Batch Loss: 0.3080, Total Loss: 675.8879\n",
      "Epoch 7/10, Batch 2680/4401, Batch Loss: 0.4430, Total Loss: 679.5873\n",
      "Epoch 7/10, Batch 2690/4401, Batch Loss: 0.3313, Total Loss: 682.7015\n",
      "Epoch 7/10, Batch 2700/4401, Batch Loss: 0.2434, Total Loss: 686.3291\n",
      "Epoch 7/10, Batch 2710/4401, Batch Loss: 0.2493, Total Loss: 689.0575\n",
      "Epoch 7/10, Batch 2720/4401, Batch Loss: 0.3925, Total Loss: 691.9985\n",
      "Epoch 7/10, Batch 2730/4401, Batch Loss: 0.3196, Total Loss: 694.3891\n",
      "Epoch 7/10, Batch 2740/4401, Batch Loss: 0.2478, Total Loss: 696.5333\n",
      "Epoch 7/10, Batch 2750/4401, Batch Loss: 0.5678, Total Loss: 699.2818\n",
      "Epoch 7/10, Batch 2760/4401, Batch Loss: 0.2358, Total Loss: 701.4703\n",
      "Epoch 7/10, Batch 2770/4401, Batch Loss: 0.5384, Total Loss: 703.3954\n",
      "Epoch 7/10, Batch 2780/4401, Batch Loss: 0.1066, Total Loss: 706.4220\n",
      "Epoch 7/10, Batch 2790/4401, Batch Loss: 0.1915, Total Loss: 709.4518\n",
      "Epoch 7/10, Batch 2800/4401, Batch Loss: 0.0639, Total Loss: 711.8026\n",
      "Epoch 7/10, Batch 2810/4401, Batch Loss: 0.2280, Total Loss: 714.5950\n",
      "Epoch 7/10, Batch 2820/4401, Batch Loss: 0.0026, Total Loss: 717.4557\n",
      "Epoch 7/10, Batch 2830/4401, Batch Loss: 0.4090, Total Loss: 719.6553\n",
      "Epoch 7/10, Batch 2840/4401, Batch Loss: 0.3640, Total Loss: 722.1786\n",
      "Epoch 7/10, Batch 2850/4401, Batch Loss: 0.2967, Total Loss: 724.3874\n",
      "Epoch 7/10, Batch 2860/4401, Batch Loss: 0.2702, Total Loss: 727.1184\n",
      "Epoch 7/10, Batch 2870/4401, Batch Loss: 0.3267, Total Loss: 729.7808\n",
      "Epoch 7/10, Batch 2880/4401, Batch Loss: 0.2613, Total Loss: 733.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 2890/4401, Batch Loss: 0.3817, Total Loss: 735.3101\n",
      "Epoch 7/10, Batch 2900/4401, Batch Loss: 0.0587, Total Loss: 737.4306\n",
      "Epoch 7/10, Batch 2910/4401, Batch Loss: 0.1627, Total Loss: 740.1375\n",
      "Epoch 7/10, Batch 2920/4401, Batch Loss: 0.2710, Total Loss: 743.1640\n",
      "Epoch 7/10, Batch 2930/4401, Batch Loss: 0.1721, Total Loss: 746.7064\n",
      "Epoch 7/10, Batch 2940/4401, Batch Loss: 0.3516, Total Loss: 750.6909\n",
      "Epoch 7/10, Batch 2950/4401, Batch Loss: 0.2245, Total Loss: 752.8125\n",
      "Epoch 7/10, Batch 2960/4401, Batch Loss: 0.4173, Total Loss: 755.2902\n",
      "Epoch 7/10, Batch 2970/4401, Batch Loss: 1.2395, Total Loss: 758.7065\n",
      "Epoch 7/10, Batch 2980/4401, Batch Loss: 0.0516, Total Loss: 760.8766\n",
      "Epoch 7/10, Batch 2990/4401, Batch Loss: 0.4748, Total Loss: 762.8669\n",
      "Epoch 7/10, Batch 3000/4401, Batch Loss: 0.9643, Total Loss: 765.7577\n",
      "Epoch 7/10, Batch 3010/4401, Batch Loss: 0.3895, Total Loss: 769.9334\n",
      "Epoch 7/10, Batch 3020/4401, Batch Loss: 0.4553, Total Loss: 772.0729\n",
      "Epoch 7/10, Batch 3030/4401, Batch Loss: 0.3206, Total Loss: 774.3401\n",
      "Epoch 7/10, Batch 3040/4401, Batch Loss: 0.6605, Total Loss: 776.7245\n",
      "Epoch 7/10, Batch 3050/4401, Batch Loss: 0.0765, Total Loss: 779.1693\n",
      "Epoch 7/10, Batch 3060/4401, Batch Loss: 0.5443, Total Loss: 782.0032\n",
      "Epoch 7/10, Batch 3070/4401, Batch Loss: 0.5840, Total Loss: 784.8340\n",
      "Epoch 7/10, Batch 3080/4401, Batch Loss: 0.5461, Total Loss: 787.6321\n",
      "Epoch 7/10, Batch 3090/4401, Batch Loss: 0.3499, Total Loss: 790.5414\n",
      "Epoch 7/10, Batch 3100/4401, Batch Loss: 0.5209, Total Loss: 793.0216\n",
      "Epoch 7/10, Batch 3110/4401, Batch Loss: 0.1587, Total Loss: 795.8691\n",
      "Epoch 7/10, Batch 3120/4401, Batch Loss: 0.1428, Total Loss: 799.0143\n",
      "Epoch 7/10, Batch 3130/4401, Batch Loss: 0.1473, Total Loss: 800.8131\n",
      "Epoch 7/10, Batch 3140/4401, Batch Loss: 0.2524, Total Loss: 803.6376\n",
      "Epoch 7/10, Batch 3150/4401, Batch Loss: 0.0404, Total Loss: 805.7771\n",
      "Epoch 7/10, Batch 3160/4401, Batch Loss: 0.3268, Total Loss: 808.0026\n",
      "Epoch 7/10, Batch 3170/4401, Batch Loss: 0.3389, Total Loss: 810.3852\n",
      "Epoch 7/10, Batch 3180/4401, Batch Loss: 0.0911, Total Loss: 812.7892\n",
      "Epoch 7/10, Batch 3190/4401, Batch Loss: 0.0468, Total Loss: 815.8838\n",
      "Epoch 7/10, Batch 3200/4401, Batch Loss: 0.0942, Total Loss: 818.7399\n",
      "Epoch 7/10, Batch 3210/4401, Batch Loss: 0.3906, Total Loss: 820.5968\n",
      "Epoch 7/10, Batch 3220/4401, Batch Loss: 0.6721, Total Loss: 823.3923\n",
      "Epoch 7/10, Batch 3230/4401, Batch Loss: 0.1078, Total Loss: 825.3749\n",
      "Epoch 7/10, Batch 3240/4401, Batch Loss: 0.2018, Total Loss: 827.9067\n",
      "Epoch 7/10, Batch 3250/4401, Batch Loss: 0.0872, Total Loss: 830.1301\n",
      "Epoch 7/10, Batch 3260/4401, Batch Loss: 0.1028, Total Loss: 831.3372\n",
      "Epoch 7/10, Batch 3270/4401, Batch Loss: 0.3119, Total Loss: 833.9426\n",
      "Epoch 7/10, Batch 3280/4401, Batch Loss: 0.2925, Total Loss: 835.7654\n",
      "Epoch 7/10, Batch 3290/4401, Batch Loss: 0.3405, Total Loss: 839.3099\n",
      "Epoch 7/10, Batch 3300/4401, Batch Loss: 0.3051, Total Loss: 841.4659\n",
      "Epoch 7/10, Batch 3310/4401, Batch Loss: 0.1168, Total Loss: 843.1505\n",
      "Epoch 7/10, Batch 3320/4401, Batch Loss: 0.0088, Total Loss: 845.3560\n",
      "Epoch 7/10, Batch 3330/4401, Batch Loss: 0.6179, Total Loss: 847.9465\n",
      "Epoch 7/10, Batch 3340/4401, Batch Loss: 0.1601, Total Loss: 850.0974\n",
      "Epoch 7/10, Batch 3350/4401, Batch Loss: 0.1055, Total Loss: 853.1869\n",
      "Epoch 7/10, Batch 3360/4401, Batch Loss: 0.4718, Total Loss: 855.7671\n",
      "Epoch 7/10, Batch 3370/4401, Batch Loss: 0.1804, Total Loss: 857.9156\n",
      "Epoch 7/10, Batch 3380/4401, Batch Loss: 0.3282, Total Loss: 859.7535\n",
      "Epoch 7/10, Batch 3390/4401, Batch Loss: 0.1407, Total Loss: 861.8018\n",
      "Epoch 7/10, Batch 3400/4401, Batch Loss: 0.3369, Total Loss: 864.0619\n",
      "Epoch 7/10, Batch 3410/4401, Batch Loss: 0.2029, Total Loss: 866.2595\n",
      "Epoch 7/10, Batch 3420/4401, Batch Loss: 0.3425, Total Loss: 870.4418\n",
      "Epoch 7/10, Batch 3430/4401, Batch Loss: 0.0991, Total Loss: 872.2761\n",
      "Epoch 7/10, Batch 3440/4401, Batch Loss: 0.2614, Total Loss: 875.9466\n",
      "Epoch 7/10, Batch 3450/4401, Batch Loss: 0.2261, Total Loss: 878.2463\n",
      "Epoch 7/10, Batch 3460/4401, Batch Loss: 0.0091, Total Loss: 882.1572\n",
      "Epoch 7/10, Batch 3470/4401, Batch Loss: 0.1195, Total Loss: 884.8569\n",
      "Epoch 7/10, Batch 3480/4401, Batch Loss: 0.6776, Total Loss: 887.4242\n",
      "Epoch 7/10, Batch 3490/4401, Batch Loss: 0.0543, Total Loss: 889.5584\n",
      "Epoch 7/10, Batch 3500/4401, Batch Loss: 0.0882, Total Loss: 892.0414\n",
      "Epoch 7/10, Batch 3510/4401, Batch Loss: 0.7038, Total Loss: 894.8125\n",
      "Epoch 7/10, Batch 3520/4401, Batch Loss: 0.1746, Total Loss: 897.0064\n",
      "Epoch 7/10, Batch 3530/4401, Batch Loss: 0.6356, Total Loss: 899.3729\n",
      "Epoch 7/10, Batch 3540/4401, Batch Loss: 0.1325, Total Loss: 902.0320\n",
      "Epoch 7/10, Batch 3550/4401, Batch Loss: 0.2084, Total Loss: 904.5207\n",
      "Epoch 7/10, Batch 3560/4401, Batch Loss: 0.4306, Total Loss: 907.3628\n",
      "Epoch 7/10, Batch 3570/4401, Batch Loss: 0.2640, Total Loss: 910.2334\n",
      "Epoch 7/10, Batch 3580/4401, Batch Loss: 0.3289, Total Loss: 913.0817\n",
      "Epoch 7/10, Batch 3590/4401, Batch Loss: 0.1095, Total Loss: 915.5805\n",
      "Epoch 7/10, Batch 3600/4401, Batch Loss: 0.1853, Total Loss: 917.7545\n",
      "Epoch 7/10, Batch 3610/4401, Batch Loss: 0.0054, Total Loss: 920.0026\n",
      "Epoch 7/10, Batch 3620/4401, Batch Loss: 0.0079, Total Loss: 921.8868\n",
      "Epoch 7/10, Batch 3630/4401, Batch Loss: 0.0428, Total Loss: 924.3269\n",
      "Epoch 7/10, Batch 3640/4401, Batch Loss: 0.6485, Total Loss: 927.5783\n",
      "Epoch 7/10, Batch 3650/4401, Batch Loss: 0.1418, Total Loss: 931.1418\n",
      "Epoch 7/10, Batch 3660/4401, Batch Loss: 0.5256, Total Loss: 933.7088\n",
      "Epoch 7/10, Batch 3670/4401, Batch Loss: 0.0679, Total Loss: 936.0764\n",
      "Epoch 7/10, Batch 3680/4401, Batch Loss: 0.5485, Total Loss: 938.4239\n",
      "Epoch 7/10, Batch 3690/4401, Batch Loss: 0.1276, Total Loss: 940.5017\n",
      "Epoch 7/10, Batch 3700/4401, Batch Loss: 0.2385, Total Loss: 942.6630\n",
      "Epoch 7/10, Batch 3710/4401, Batch Loss: 0.1305, Total Loss: 944.2466\n",
      "Epoch 7/10, Batch 3720/4401, Batch Loss: 0.0274, Total Loss: 946.7207\n",
      "Epoch 7/10, Batch 3730/4401, Batch Loss: 0.3950, Total Loss: 950.0835\n",
      "Epoch 7/10, Batch 3740/4401, Batch Loss: 0.1198, Total Loss: 952.2434\n",
      "Epoch 7/10, Batch 3750/4401, Batch Loss: 0.2008, Total Loss: 955.3670\n",
      "Epoch 7/10, Batch 3760/4401, Batch Loss: 0.1041, Total Loss: 956.4271\n",
      "Epoch 7/10, Batch 3770/4401, Batch Loss: 0.5797, Total Loss: 959.7443\n",
      "Epoch 7/10, Batch 3780/4401, Batch Loss: 0.2461, Total Loss: 961.9928\n",
      "Epoch 7/10, Batch 3790/4401, Batch Loss: 0.4143, Total Loss: 965.1098\n",
      "Epoch 7/10, Batch 3800/4401, Batch Loss: 0.4259, Total Loss: 967.3707\n",
      "Epoch 7/10, Batch 3810/4401, Batch Loss: 0.5712, Total Loss: 969.5217\n",
      "Epoch 7/10, Batch 3820/4401, Batch Loss: 0.1395, Total Loss: 972.2472\n",
      "Epoch 7/10, Batch 3830/4401, Batch Loss: 0.0819, Total Loss: 974.0219\n",
      "Epoch 7/10, Batch 3840/4401, Batch Loss: 0.1934, Total Loss: 976.3819\n",
      "Epoch 7/10, Batch 3850/4401, Batch Loss: 0.4374, Total Loss: 979.1643\n",
      "Epoch 7/10, Batch 3860/4401, Batch Loss: 0.4445, Total Loss: 982.4631\n",
      "Epoch 7/10, Batch 3870/4401, Batch Loss: 0.0472, Total Loss: 984.2861\n",
      "Epoch 7/10, Batch 3880/4401, Batch Loss: 0.3374, Total Loss: 988.3554\n",
      "Epoch 7/10, Batch 3890/4401, Batch Loss: 0.3471, Total Loss: 990.8828\n",
      "Epoch 7/10, Batch 3900/4401, Batch Loss: 0.3616, Total Loss: 994.0898\n",
      "Epoch 7/10, Batch 3910/4401, Batch Loss: 0.4264, Total Loss: 997.2496\n",
      "Epoch 7/10, Batch 3920/4401, Batch Loss: 0.4014, Total Loss: 1000.5809\n",
      "Epoch 7/10, Batch 3930/4401, Batch Loss: 0.6981, Total Loss: 1003.3641\n",
      "Epoch 7/10, Batch 3940/4401, Batch Loss: 0.1586, Total Loss: 1005.3427\n",
      "Epoch 7/10, Batch 3950/4401, Batch Loss: 0.3037, Total Loss: 1008.2789\n",
      "Epoch 7/10, Batch 3960/4401, Batch Loss: 0.2088, Total Loss: 1010.7967\n",
      "Epoch 7/10, Batch 3970/4401, Batch Loss: 0.4262, Total Loss: 1012.9086\n",
      "Epoch 7/10, Batch 3980/4401, Batch Loss: 0.1075, Total Loss: 1015.4911\n",
      "Epoch 7/10, Batch 3990/4401, Batch Loss: 0.1144, Total Loss: 1018.8868\n",
      "Epoch 7/10, Batch 4000/4401, Batch Loss: 0.4007, Total Loss: 1021.0105\n",
      "Epoch 7/10, Batch 4010/4401, Batch Loss: 0.1833, Total Loss: 1023.5981\n",
      "Epoch 7/10, Batch 4020/4401, Batch Loss: 0.0481, Total Loss: 1025.8941\n",
      "Epoch 7/10, Batch 4030/4401, Batch Loss: 0.0749, Total Loss: 1028.7979\n",
      "Epoch 7/10, Batch 4040/4401, Batch Loss: 0.2760, Total Loss: 1031.6676\n",
      "Epoch 7/10, Batch 4050/4401, Batch Loss: 0.3466, Total Loss: 1033.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 4060/4401, Batch Loss: 0.2029, Total Loss: 1036.7828\n",
      "Epoch 7/10, Batch 4070/4401, Batch Loss: 0.2692, Total Loss: 1039.3954\n",
      "Epoch 7/10, Batch 4080/4401, Batch Loss: 0.3857, Total Loss: 1042.0940\n",
      "Epoch 7/10, Batch 4090/4401, Batch Loss: 0.0630, Total Loss: 1044.7715\n",
      "Epoch 7/10, Batch 4100/4401, Batch Loss: 0.2259, Total Loss: 1046.9959\n",
      "Epoch 7/10, Batch 4110/4401, Batch Loss: 0.2223, Total Loss: 1050.0188\n",
      "Epoch 7/10, Batch 4120/4401, Batch Loss: 0.2179, Total Loss: 1052.7701\n",
      "Epoch 7/10, Batch 4130/4401, Batch Loss: 0.2665, Total Loss: 1055.8797\n",
      "Epoch 7/10, Batch 4140/4401, Batch Loss: 0.3346, Total Loss: 1058.6660\n",
      "Epoch 7/10, Batch 4150/4401, Batch Loss: 0.4670, Total Loss: 1061.0264\n",
      "Epoch 7/10, Batch 4160/4401, Batch Loss: 0.2351, Total Loss: 1063.7198\n",
      "Epoch 7/10, Batch 4170/4401, Batch Loss: 0.0997, Total Loss: 1065.9222\n",
      "Epoch 7/10, Batch 4180/4401, Batch Loss: 0.2386, Total Loss: 1068.7672\n",
      "Epoch 7/10, Batch 4190/4401, Batch Loss: 0.1135, Total Loss: 1071.2154\n",
      "Epoch 7/10, Batch 4200/4401, Batch Loss: 0.2877, Total Loss: 1073.9776\n",
      "Epoch 7/10, Batch 4210/4401, Batch Loss: 0.2205, Total Loss: 1075.8539\n",
      "Epoch 7/10, Batch 4220/4401, Batch Loss: 0.0489, Total Loss: 1078.7609\n",
      "Epoch 7/10, Batch 4230/4401, Batch Loss: 0.1416, Total Loss: 1081.5311\n",
      "Epoch 7/10, Batch 4240/4401, Batch Loss: 0.2526, Total Loss: 1083.8004\n",
      "Epoch 7/10, Batch 4250/4401, Batch Loss: 0.1395, Total Loss: 1086.3039\n",
      "Epoch 7/10, Batch 4260/4401, Batch Loss: 0.2348, Total Loss: 1088.3561\n",
      "Epoch 7/10, Batch 4270/4401, Batch Loss: 0.0840, Total Loss: 1090.4976\n",
      "Epoch 7/10, Batch 4280/4401, Batch Loss: 0.3246, Total Loss: 1093.0427\n",
      "Epoch 7/10, Batch 4290/4401, Batch Loss: 0.4896, Total Loss: 1095.5117\n",
      "Epoch 7/10, Batch 4300/4401, Batch Loss: 0.1845, Total Loss: 1097.9632\n",
      "Epoch 7/10, Batch 4310/4401, Batch Loss: 1.0066, Total Loss: 1101.1435\n",
      "Epoch 7/10, Batch 4320/4401, Batch Loss: 0.3896, Total Loss: 1102.9944\n",
      "Epoch 7/10, Batch 4330/4401, Batch Loss: 0.6172, Total Loss: 1105.2696\n",
      "Epoch 7/10, Batch 4340/4401, Batch Loss: 0.3653, Total Loss: 1107.3572\n",
      "Epoch 7/10, Batch 4350/4401, Batch Loss: 0.0813, Total Loss: 1110.4141\n",
      "Epoch 7/10, Batch 4360/4401, Batch Loss: 0.2138, Total Loss: 1112.7185\n",
      "Epoch 7/10, Batch 4370/4401, Batch Loss: 0.3842, Total Loss: 1115.8333\n",
      "Epoch 7/10, Batch 4380/4401, Batch Loss: 0.3272, Total Loss: 1117.8827\n",
      "Epoch 7/10, Batch 4390/4401, Batch Loss: 0.0547, Total Loss: 1119.9806\n",
      "Epoch 7/10, Batch 4400/4401, Batch Loss: 0.5443, Total Loss: 1123.0441\n",
      "Epoch 7/10, Batch 4401/4401, Batch Loss: 0.0928, Total Loss: 1123.1369\n",
      "Epoch 7/10 completed. Total Loss: 1123.1369\n",
      "\n",
      "Epoch 8/10 running...\n",
      "cuda:0\n",
      "Epoch 8/10, Batch 10/4401, Batch Loss: 0.2444, Total Loss: 2.6363\n",
      "Epoch 8/10, Batch 20/4401, Batch Loss: 0.5737, Total Loss: 5.0324\n",
      "Epoch 8/10, Batch 30/4401, Batch Loss: 0.0014, Total Loss: 6.4492\n",
      "Epoch 8/10, Batch 40/4401, Batch Loss: 0.3122, Total Loss: 8.1752\n",
      "Epoch 8/10, Batch 50/4401, Batch Loss: 0.2149, Total Loss: 11.4377\n",
      "Epoch 8/10, Batch 60/4401, Batch Loss: 0.1563, Total Loss: 14.2349\n",
      "Epoch 8/10, Batch 70/4401, Batch Loss: 0.1327, Total Loss: 16.0843\n",
      "Epoch 8/10, Batch 80/4401, Batch Loss: 0.3170, Total Loss: 19.0977\n",
      "Epoch 8/10, Batch 90/4401, Batch Loss: 0.3101, Total Loss: 21.6166\n",
      "Epoch 8/10, Batch 100/4401, Batch Loss: 0.2622, Total Loss: 23.4011\n",
      "Epoch 8/10, Batch 110/4401, Batch Loss: 0.4215, Total Loss: 26.4109\n",
      "Epoch 8/10, Batch 120/4401, Batch Loss: 0.1902, Total Loss: 28.5572\n",
      "Epoch 8/10, Batch 130/4401, Batch Loss: 0.1718, Total Loss: 30.5593\n",
      "Epoch 8/10, Batch 140/4401, Batch Loss: 0.2455, Total Loss: 32.8014\n",
      "Epoch 8/10, Batch 150/4401, Batch Loss: 0.0487, Total Loss: 35.3178\n",
      "Epoch 8/10, Batch 160/4401, Batch Loss: 0.1373, Total Loss: 36.9671\n",
      "Epoch 8/10, Batch 170/4401, Batch Loss: 0.1758, Total Loss: 39.7357\n",
      "Epoch 8/10, Batch 180/4401, Batch Loss: 0.1751, Total Loss: 41.9869\n",
      "Epoch 8/10, Batch 190/4401, Batch Loss: 0.2476, Total Loss: 43.8835\n",
      "Epoch 8/10, Batch 200/4401, Batch Loss: 0.1212, Total Loss: 46.2434\n",
      "Epoch 8/10, Batch 210/4401, Batch Loss: 0.2979, Total Loss: 49.0416\n",
      "Epoch 8/10, Batch 220/4401, Batch Loss: 0.0018, Total Loss: 51.7966\n",
      "Epoch 8/10, Batch 230/4401, Batch Loss: 0.3385, Total Loss: 54.0829\n",
      "Epoch 8/10, Batch 240/4401, Batch Loss: 0.0011, Total Loss: 56.8819\n",
      "Epoch 8/10, Batch 250/4401, Batch Loss: 0.2270, Total Loss: 59.4567\n",
      "Epoch 8/10, Batch 260/4401, Batch Loss: 0.2773, Total Loss: 62.0926\n",
      "Epoch 8/10, Batch 270/4401, Batch Loss: 0.2738, Total Loss: 65.4757\n",
      "Epoch 8/10, Batch 280/4401, Batch Loss: 0.4744, Total Loss: 67.6126\n",
      "Epoch 8/10, Batch 290/4401, Batch Loss: 0.0892, Total Loss: 70.4469\n",
      "Epoch 8/10, Batch 300/4401, Batch Loss: 0.3711, Total Loss: 73.0061\n",
      "Epoch 8/10, Batch 310/4401, Batch Loss: 0.1868, Total Loss: 75.5789\n",
      "Epoch 8/10, Batch 320/4401, Batch Loss: 0.0007, Total Loss: 77.7967\n",
      "Epoch 8/10, Batch 330/4401, Batch Loss: 0.1370, Total Loss: 80.5145\n",
      "Epoch 8/10, Batch 340/4401, Batch Loss: 0.0730, Total Loss: 83.5005\n",
      "Epoch 8/10, Batch 350/4401, Batch Loss: 0.1303, Total Loss: 85.4356\n",
      "Epoch 8/10, Batch 360/4401, Batch Loss: 0.6132, Total Loss: 88.4597\n",
      "Epoch 8/10, Batch 370/4401, Batch Loss: 0.1563, Total Loss: 90.8189\n",
      "Epoch 8/10, Batch 380/4401, Batch Loss: 0.3828, Total Loss: 92.6676\n",
      "Epoch 8/10, Batch 390/4401, Batch Loss: 0.4207, Total Loss: 94.7687\n",
      "Epoch 8/10, Batch 400/4401, Batch Loss: 0.0436, Total Loss: 96.2603\n",
      "Epoch 8/10, Batch 410/4401, Batch Loss: 0.1566, Total Loss: 97.9486\n",
      "Epoch 8/10, Batch 420/4401, Batch Loss: 0.0022, Total Loss: 99.9607\n",
      "Epoch 8/10, Batch 430/4401, Batch Loss: 0.3077, Total Loss: 102.1088\n",
      "Epoch 8/10, Batch 440/4401, Batch Loss: 0.1025, Total Loss: 104.2188\n",
      "Epoch 8/10, Batch 450/4401, Batch Loss: 0.2397, Total Loss: 106.8325\n",
      "Epoch 8/10, Batch 460/4401, Batch Loss: 1.3060, Total Loss: 111.2854\n",
      "Epoch 8/10, Batch 470/4401, Batch Loss: 0.3297, Total Loss: 114.4380\n",
      "Epoch 8/10, Batch 480/4401, Batch Loss: 0.4418, Total Loss: 117.7297\n",
      "Epoch 8/10, Batch 490/4401, Batch Loss: 0.1230, Total Loss: 119.9244\n",
      "Epoch 8/10, Batch 500/4401, Batch Loss: 0.2177, Total Loss: 122.4280\n",
      "Epoch 8/10, Batch 510/4401, Batch Loss: 0.0013, Total Loss: 123.7309\n",
      "Epoch 8/10, Batch 520/4401, Batch Loss: 0.1143, Total Loss: 125.2920\n",
      "Epoch 8/10, Batch 530/4401, Batch Loss: 0.4420, Total Loss: 126.8351\n",
      "Epoch 8/10, Batch 540/4401, Batch Loss: 0.0987, Total Loss: 129.1048\n",
      "Epoch 8/10, Batch 550/4401, Batch Loss: 0.2369, Total Loss: 131.3886\n",
      "Epoch 8/10, Batch 560/4401, Batch Loss: 0.0507, Total Loss: 132.8708\n",
      "Epoch 8/10, Batch 570/4401, Batch Loss: 0.6189, Total Loss: 135.2836\n",
      "Epoch 8/10, Batch 580/4401, Batch Loss: 0.4198, Total Loss: 137.7540\n",
      "Epoch 8/10, Batch 590/4401, Batch Loss: 0.4755, Total Loss: 140.6822\n",
      "Epoch 8/10, Batch 600/4401, Batch Loss: 0.2002, Total Loss: 142.6620\n",
      "Epoch 8/10, Batch 610/4401, Batch Loss: 0.1358, Total Loss: 145.4178\n",
      "Epoch 8/10, Batch 620/4401, Batch Loss: 0.2766, Total Loss: 147.7685\n",
      "Epoch 8/10, Batch 630/4401, Batch Loss: 0.1882, Total Loss: 149.5833\n",
      "Epoch 8/10, Batch 640/4401, Batch Loss: 0.0777, Total Loss: 151.1933\n",
      "Epoch 8/10, Batch 650/4401, Batch Loss: 0.3247, Total Loss: 154.1650\n",
      "Epoch 8/10, Batch 660/4401, Batch Loss: 0.0661, Total Loss: 155.6160\n",
      "Epoch 8/10, Batch 670/4401, Batch Loss: 0.2408, Total Loss: 158.4017\n",
      "Epoch 8/10, Batch 680/4401, Batch Loss: 0.1174, Total Loss: 160.9054\n",
      "Epoch 8/10, Batch 690/4401, Batch Loss: 0.2665, Total Loss: 163.5937\n",
      "Epoch 8/10, Batch 700/4401, Batch Loss: 0.3875, Total Loss: 165.3805\n",
      "Epoch 8/10, Batch 710/4401, Batch Loss: 0.1714, Total Loss: 168.1005\n",
      "Epoch 8/10, Batch 720/4401, Batch Loss: 0.2953, Total Loss: 171.1316\n",
      "Epoch 8/10, Batch 730/4401, Batch Loss: 0.2044, Total Loss: 176.2011\n",
      "Epoch 8/10, Batch 740/4401, Batch Loss: 0.0946, Total Loss: 178.9524\n",
      "Epoch 8/10, Batch 750/4401, Batch Loss: 0.4475, Total Loss: 181.5367\n",
      "Epoch 8/10, Batch 760/4401, Batch Loss: 0.3440, Total Loss: 183.3233\n",
      "Epoch 8/10, Batch 770/4401, Batch Loss: 0.1235, Total Loss: 185.2187\n",
      "Epoch 8/10, Batch 780/4401, Batch Loss: 0.2148, Total Loss: 187.1207\n",
      "Epoch 8/10, Batch 790/4401, Batch Loss: 0.2635, Total Loss: 189.6966\n",
      "Epoch 8/10, Batch 800/4401, Batch Loss: 0.4149, Total Loss: 192.4195\n",
      "Epoch 8/10, Batch 810/4401, Batch Loss: 0.2207, Total Loss: 195.3994\n",
      "Epoch 8/10, Batch 820/4401, Batch Loss: 0.0156, Total Loss: 197.6769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 830/4401, Batch Loss: 0.1028, Total Loss: 200.6218\n",
      "Epoch 8/10, Batch 840/4401, Batch Loss: 0.3218, Total Loss: 202.9386\n",
      "Epoch 8/10, Batch 850/4401, Batch Loss: 0.1884, Total Loss: 205.1460\n",
      "Epoch 8/10, Batch 860/4401, Batch Loss: 0.1004, Total Loss: 206.7498\n",
      "Epoch 8/10, Batch 870/4401, Batch Loss: 0.1594, Total Loss: 209.2943\n",
      "Epoch 8/10, Batch 880/4401, Batch Loss: 0.4441, Total Loss: 212.1303\n",
      "Epoch 8/10, Batch 890/4401, Batch Loss: 0.3764, Total Loss: 213.9552\n",
      "Epoch 8/10, Batch 900/4401, Batch Loss: 0.3019, Total Loss: 215.7103\n",
      "Epoch 8/10, Batch 910/4401, Batch Loss: 0.0594, Total Loss: 219.0407\n",
      "Epoch 8/10, Batch 920/4401, Batch Loss: 0.1897, Total Loss: 221.3756\n",
      "Epoch 8/10, Batch 930/4401, Batch Loss: 0.2171, Total Loss: 223.6686\n",
      "Epoch 8/10, Batch 940/4401, Batch Loss: 0.0534, Total Loss: 225.9314\n",
      "Epoch 8/10, Batch 950/4401, Batch Loss: 0.2613, Total Loss: 228.1715\n",
      "Epoch 8/10, Batch 960/4401, Batch Loss: 0.2571, Total Loss: 230.2165\n",
      "Epoch 8/10, Batch 970/4401, Batch Loss: 0.2862, Total Loss: 232.7184\n",
      "Epoch 8/10, Batch 980/4401, Batch Loss: 0.3886, Total Loss: 235.2988\n",
      "Epoch 8/10, Batch 990/4401, Batch Loss: 0.0559, Total Loss: 236.7400\n",
      "Epoch 8/10, Batch 1000/4401, Batch Loss: 0.0871, Total Loss: 238.4754\n",
      "Epoch 8/10, Batch 1010/4401, Batch Loss: 0.0919, Total Loss: 240.3637\n",
      "Epoch 8/10, Batch 1020/4401, Batch Loss: 0.4130, Total Loss: 243.5604\n",
      "Epoch 8/10, Batch 1030/4401, Batch Loss: 0.2053, Total Loss: 245.5254\n",
      "Epoch 8/10, Batch 1040/4401, Batch Loss: 0.3498, Total Loss: 248.2238\n",
      "Epoch 8/10, Batch 1050/4401, Batch Loss: 0.0747, Total Loss: 250.3803\n",
      "Epoch 8/10, Batch 1060/4401, Batch Loss: 0.4523, Total Loss: 252.7228\n",
      "Epoch 8/10, Batch 1070/4401, Batch Loss: 0.0549, Total Loss: 254.3447\n",
      "Epoch 8/10, Batch 1080/4401, Batch Loss: 0.1343, Total Loss: 256.7278\n",
      "Epoch 8/10, Batch 1090/4401, Batch Loss: 0.0032, Total Loss: 258.0749\n",
      "Epoch 8/10, Batch 1100/4401, Batch Loss: 0.0947, Total Loss: 260.8990\n",
      "Epoch 8/10, Batch 1110/4401, Batch Loss: 0.7615, Total Loss: 263.7503\n",
      "Epoch 8/10, Batch 1120/4401, Batch Loss: 0.2218, Total Loss: 266.1777\n",
      "Epoch 8/10, Batch 1130/4401, Batch Loss: 0.4248, Total Loss: 268.8485\n",
      "Epoch 8/10, Batch 1140/4401, Batch Loss: 0.4109, Total Loss: 271.2295\n",
      "Epoch 8/10, Batch 1150/4401, Batch Loss: 0.3122, Total Loss: 273.8412\n",
      "Epoch 8/10, Batch 1160/4401, Batch Loss: 0.0008, Total Loss: 277.6353\n",
      "Epoch 8/10, Batch 1170/4401, Batch Loss: 0.3082, Total Loss: 280.4901\n",
      "Epoch 8/10, Batch 1180/4401, Batch Loss: 0.4267, Total Loss: 283.2229\n",
      "Epoch 8/10, Batch 1190/4401, Batch Loss: 0.0634, Total Loss: 285.8606\n",
      "Epoch 8/10, Batch 1200/4401, Batch Loss: 0.3863, Total Loss: 288.1526\n",
      "Epoch 8/10, Batch 1210/4401, Batch Loss: 0.2677, Total Loss: 289.8014\n",
      "Epoch 8/10, Batch 1220/4401, Batch Loss: 0.4438, Total Loss: 292.6432\n",
      "Epoch 8/10, Batch 1230/4401, Batch Loss: 0.4171, Total Loss: 295.7287\n",
      "Epoch 8/10, Batch 1240/4401, Batch Loss: 0.4377, Total Loss: 298.4867\n",
      "Epoch 8/10, Batch 1250/4401, Batch Loss: 0.3869, Total Loss: 300.8735\n",
      "Epoch 8/10, Batch 1260/4401, Batch Loss: 0.1744, Total Loss: 303.2336\n",
      "Epoch 8/10, Batch 1270/4401, Batch Loss: 0.4440, Total Loss: 305.9579\n",
      "Epoch 8/10, Batch 1280/4401, Batch Loss: 0.1558, Total Loss: 307.9175\n",
      "Epoch 8/10, Batch 1290/4401, Batch Loss: 0.7082, Total Loss: 310.6274\n",
      "Epoch 8/10, Batch 1300/4401, Batch Loss: 0.2700, Total Loss: 313.2317\n",
      "Epoch 8/10, Batch 1310/4401, Batch Loss: 0.0662, Total Loss: 315.4947\n",
      "Epoch 8/10, Batch 1320/4401, Batch Loss: 0.2024, Total Loss: 317.7838\n",
      "Epoch 8/10, Batch 1330/4401, Batch Loss: 0.0186, Total Loss: 320.3841\n",
      "Epoch 8/10, Batch 1340/4401, Batch Loss: 0.5255, Total Loss: 322.4447\n",
      "Epoch 8/10, Batch 1350/4401, Batch Loss: 0.1274, Total Loss: 323.9289\n",
      "Epoch 8/10, Batch 1360/4401, Batch Loss: 0.2079, Total Loss: 325.9397\n",
      "Epoch 8/10, Batch 1370/4401, Batch Loss: 0.3370, Total Loss: 328.1391\n",
      "Epoch 8/10, Batch 1380/4401, Batch Loss: 0.0785, Total Loss: 330.6694\n",
      "Epoch 8/10, Batch 1390/4401, Batch Loss: 0.1783, Total Loss: 334.3404\n",
      "Epoch 8/10, Batch 1400/4401, Batch Loss: 0.0884, Total Loss: 337.2746\n",
      "Epoch 8/10, Batch 1410/4401, Batch Loss: 0.7645, Total Loss: 340.1563\n",
      "Epoch 8/10, Batch 1420/4401, Batch Loss: 0.1842, Total Loss: 342.2909\n",
      "Epoch 8/10, Batch 1430/4401, Batch Loss: 0.1855, Total Loss: 344.5368\n",
      "Epoch 8/10, Batch 1440/4401, Batch Loss: 0.1175, Total Loss: 346.7494\n",
      "Epoch 8/10, Batch 1450/4401, Batch Loss: 0.2865, Total Loss: 349.1423\n",
      "Epoch 8/10, Batch 1460/4401, Batch Loss: 0.1116, Total Loss: 351.2472\n",
      "Epoch 8/10, Batch 1470/4401, Batch Loss: 0.0876, Total Loss: 353.2555\n",
      "Epoch 8/10, Batch 1480/4401, Batch Loss: 0.1143, Total Loss: 355.3221\n",
      "Epoch 8/10, Batch 1490/4401, Batch Loss: 0.1848, Total Loss: 357.8485\n",
      "Epoch 8/10, Batch 1500/4401, Batch Loss: 0.0721, Total Loss: 360.4156\n",
      "Epoch 8/10, Batch 1510/4401, Batch Loss: 0.3011, Total Loss: 362.9119\n",
      "Epoch 8/10, Batch 1520/4401, Batch Loss: 0.3565, Total Loss: 364.6904\n",
      "Epoch 8/10, Batch 1530/4401, Batch Loss: 0.2023, Total Loss: 367.2531\n",
      "Epoch 8/10, Batch 1540/4401, Batch Loss: 1.3290, Total Loss: 370.6570\n",
      "Epoch 8/10, Batch 1550/4401, Batch Loss: 0.1180, Total Loss: 373.2597\n",
      "Epoch 8/10, Batch 1560/4401, Batch Loss: 0.1540, Total Loss: 375.8503\n",
      "Epoch 8/10, Batch 1570/4401, Batch Loss: 0.2385, Total Loss: 377.7369\n",
      "Epoch 8/10, Batch 1580/4401, Batch Loss: 0.2265, Total Loss: 380.1584\n",
      "Epoch 8/10, Batch 1590/4401, Batch Loss: 0.1239, Total Loss: 382.0324\n",
      "Epoch 8/10, Batch 1600/4401, Batch Loss: 0.2619, Total Loss: 384.9723\n",
      "Epoch 8/10, Batch 1610/4401, Batch Loss: 0.3547, Total Loss: 386.9429\n",
      "Epoch 8/10, Batch 1620/4401, Batch Loss: 0.2254, Total Loss: 388.9323\n",
      "Epoch 8/10, Batch 1630/4401, Batch Loss: 0.1502, Total Loss: 390.3720\n",
      "Epoch 8/10, Batch 1640/4401, Batch Loss: 0.2333, Total Loss: 393.4302\n",
      "Epoch 8/10, Batch 1650/4401, Batch Loss: 0.4876, Total Loss: 396.2974\n",
      "Epoch 8/10, Batch 1660/4401, Batch Loss: 0.4863, Total Loss: 399.4662\n",
      "Epoch 8/10, Batch 1670/4401, Batch Loss: 0.1668, Total Loss: 401.6771\n",
      "Epoch 8/10, Batch 1680/4401, Batch Loss: 0.0936, Total Loss: 403.5974\n",
      "Epoch 8/10, Batch 1690/4401, Batch Loss: 0.1599, Total Loss: 406.5401\n",
      "Epoch 8/10, Batch 1700/4401, Batch Loss: 0.3425, Total Loss: 408.8672\n",
      "Epoch 8/10, Batch 1710/4401, Batch Loss: 0.0582, Total Loss: 410.7973\n",
      "Epoch 8/10, Batch 1720/4401, Batch Loss: 0.1007, Total Loss: 413.3105\n",
      "Epoch 8/10, Batch 1730/4401, Batch Loss: 0.0936, Total Loss: 415.1570\n",
      "Epoch 8/10, Batch 1740/4401, Batch Loss: 0.1821, Total Loss: 418.0628\n",
      "Epoch 8/10, Batch 1750/4401, Batch Loss: 0.1142, Total Loss: 421.3233\n",
      "Epoch 8/10, Batch 1760/4401, Batch Loss: 0.0030, Total Loss: 424.1570\n",
      "Epoch 8/10, Batch 1770/4401, Batch Loss: 0.1602, Total Loss: 427.1836\n",
      "Epoch 8/10, Batch 1780/4401, Batch Loss: 0.0877, Total Loss: 429.2599\n",
      "Epoch 8/10, Batch 1790/4401, Batch Loss: 0.2870, Total Loss: 432.3503\n",
      "Epoch 8/10, Batch 1800/4401, Batch Loss: 0.1975, Total Loss: 434.2005\n",
      "Epoch 8/10, Batch 1810/4401, Batch Loss: 0.1864, Total Loss: 436.7256\n",
      "Epoch 8/10, Batch 1820/4401, Batch Loss: 0.2610, Total Loss: 439.2374\n",
      "Epoch 8/10, Batch 1830/4401, Batch Loss: 0.3046, Total Loss: 442.0368\n",
      "Epoch 8/10, Batch 1840/4401, Batch Loss: 0.2010, Total Loss: 444.8992\n",
      "Epoch 8/10, Batch 1850/4401, Batch Loss: 0.2462, Total Loss: 446.7975\n",
      "Epoch 8/10, Batch 1860/4401, Batch Loss: 0.0980, Total Loss: 448.1983\n",
      "Epoch 8/10, Batch 1870/4401, Batch Loss: 0.1828, Total Loss: 450.4820\n",
      "Epoch 8/10, Batch 1880/4401, Batch Loss: 0.0861, Total Loss: 453.2964\n",
      "Epoch 8/10, Batch 1890/4401, Batch Loss: 0.2568, Total Loss: 455.4859\n",
      "Epoch 8/10, Batch 1900/4401, Batch Loss: 0.1447, Total Loss: 458.3364\n",
      "Epoch 8/10, Batch 1910/4401, Batch Loss: 0.3099, Total Loss: 460.9135\n",
      "Epoch 8/10, Batch 1920/4401, Batch Loss: 0.1343, Total Loss: 463.2848\n",
      "Epoch 8/10, Batch 1930/4401, Batch Loss: 0.0019, Total Loss: 465.8452\n",
      "Epoch 8/10, Batch 1940/4401, Batch Loss: 0.1907, Total Loss: 467.4205\n",
      "Epoch 8/10, Batch 1950/4401, Batch Loss: 0.1054, Total Loss: 469.7832\n",
      "Epoch 8/10, Batch 1960/4401, Batch Loss: 0.3354, Total Loss: 471.7951\n",
      "Epoch 8/10, Batch 1970/4401, Batch Loss: 0.1666, Total Loss: 473.6682\n",
      "Epoch 8/10, Batch 1980/4401, Batch Loss: 0.1785, Total Loss: 475.8300\n",
      "Epoch 8/10, Batch 1990/4401, Batch Loss: 0.2414, Total Loss: 479.1203\n",
      "Epoch 8/10, Batch 2000/4401, Batch Loss: 0.3825, Total Loss: 481.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 2010/4401, Batch Loss: 0.2616, Total Loss: 483.5091\n",
      "Epoch 8/10, Batch 2020/4401, Batch Loss: 0.5054, Total Loss: 486.1318\n",
      "Epoch 8/10, Batch 2030/4401, Batch Loss: 0.1174, Total Loss: 489.1941\n",
      "Epoch 8/10, Batch 2040/4401, Batch Loss: 0.1258, Total Loss: 491.3928\n",
      "Epoch 8/10, Batch 2050/4401, Batch Loss: 0.2197, Total Loss: 494.3967\n",
      "Epoch 8/10, Batch 2060/4401, Batch Loss: 0.2668, Total Loss: 496.7698\n",
      "Epoch 8/10, Batch 2070/4401, Batch Loss: 0.0307, Total Loss: 499.9571\n",
      "Epoch 8/10, Batch 2080/4401, Batch Loss: 0.1282, Total Loss: 502.0454\n",
      "Epoch 8/10, Batch 2090/4401, Batch Loss: 0.3117, Total Loss: 504.2637\n",
      "Epoch 8/10, Batch 2100/4401, Batch Loss: 0.1552, Total Loss: 507.1516\n",
      "Epoch 8/10, Batch 2110/4401, Batch Loss: 0.4973, Total Loss: 510.2409\n",
      "Epoch 8/10, Batch 2120/4401, Batch Loss: 0.1694, Total Loss: 512.2790\n",
      "Epoch 8/10, Batch 2130/4401, Batch Loss: 0.1751, Total Loss: 514.5807\n",
      "Epoch 8/10, Batch 2140/4401, Batch Loss: 0.1559, Total Loss: 516.4675\n",
      "Epoch 8/10, Batch 2150/4401, Batch Loss: 0.1314, Total Loss: 519.5609\n",
      "Epoch 8/10, Batch 2160/4401, Batch Loss: 0.2630, Total Loss: 522.4464\n",
      "Epoch 8/10, Batch 2170/4401, Batch Loss: 0.1506, Total Loss: 524.5277\n",
      "Epoch 8/10, Batch 2180/4401, Batch Loss: 0.2584, Total Loss: 526.8784\n",
      "Epoch 8/10, Batch 2190/4401, Batch Loss: 0.4163, Total Loss: 530.3254\n",
      "Epoch 8/10, Batch 2200/4401, Batch Loss: 0.2480, Total Loss: 532.4725\n",
      "Epoch 8/10, Batch 2210/4401, Batch Loss: 0.0909, Total Loss: 534.2616\n",
      "Epoch 8/10, Batch 2220/4401, Batch Loss: 0.0558, Total Loss: 536.0236\n",
      "Epoch 8/10, Batch 2230/4401, Batch Loss: 0.1793, Total Loss: 538.1680\n",
      "Epoch 8/10, Batch 2240/4401, Batch Loss: 0.1553, Total Loss: 540.2453\n",
      "Epoch 8/10, Batch 2250/4401, Batch Loss: 0.0216, Total Loss: 542.4944\n",
      "Epoch 8/10, Batch 2260/4401, Batch Loss: 0.3215, Total Loss: 545.3975\n",
      "Epoch 8/10, Batch 2270/4401, Batch Loss: 0.3216, Total Loss: 546.7650\n",
      "Epoch 8/10, Batch 2280/4401, Batch Loss: 0.3460, Total Loss: 549.3525\n",
      "Epoch 8/10, Batch 2290/4401, Batch Loss: 0.0547, Total Loss: 551.7313\n",
      "Epoch 8/10, Batch 2300/4401, Batch Loss: 0.0894, Total Loss: 554.0421\n",
      "Epoch 8/10, Batch 2310/4401, Batch Loss: 0.1465, Total Loss: 556.5643\n",
      "Epoch 8/10, Batch 2320/4401, Batch Loss: 0.3742, Total Loss: 559.4670\n",
      "Epoch 8/10, Batch 2330/4401, Batch Loss: 0.0582, Total Loss: 561.3018\n",
      "Epoch 8/10, Batch 2340/4401, Batch Loss: 0.4453, Total Loss: 563.9355\n",
      "Epoch 8/10, Batch 2350/4401, Batch Loss: 0.1563, Total Loss: 566.9471\n",
      "Epoch 8/10, Batch 2360/4401, Batch Loss: 0.2158, Total Loss: 569.7932\n",
      "Epoch 8/10, Batch 2370/4401, Batch Loss: 1.0025, Total Loss: 572.8589\n",
      "Epoch 8/10, Batch 2380/4401, Batch Loss: 0.2972, Total Loss: 575.2119\n",
      "Epoch 8/10, Batch 2390/4401, Batch Loss: 0.3950, Total Loss: 578.0356\n",
      "Epoch 8/10, Batch 2400/4401, Batch Loss: 0.4200, Total Loss: 580.6800\n",
      "Epoch 8/10, Batch 2410/4401, Batch Loss: 0.2240, Total Loss: 582.9019\n",
      "Epoch 8/10, Batch 2420/4401, Batch Loss: 0.1618, Total Loss: 586.0429\n",
      "Epoch 8/10, Batch 2430/4401, Batch Loss: 0.7896, Total Loss: 588.6661\n",
      "Epoch 8/10, Batch 2440/4401, Batch Loss: 0.0991, Total Loss: 590.2909\n",
      "Epoch 8/10, Batch 2450/4401, Batch Loss: 0.2353, Total Loss: 592.8589\n",
      "Epoch 8/10, Batch 2460/4401, Batch Loss: 0.0905, Total Loss: 594.0522\n",
      "Epoch 8/10, Batch 2470/4401, Batch Loss: 0.1108, Total Loss: 595.7858\n",
      "Epoch 8/10, Batch 2480/4401, Batch Loss: 0.1918, Total Loss: 598.1411\n",
      "Epoch 8/10, Batch 2490/4401, Batch Loss: 0.0907, Total Loss: 600.7474\n",
      "Epoch 8/10, Batch 2500/4401, Batch Loss: 0.3358, Total Loss: 603.8360\n",
      "Epoch 8/10, Batch 2510/4401, Batch Loss: 0.1612, Total Loss: 605.6394\n",
      "Epoch 8/10, Batch 2520/4401, Batch Loss: 0.0421, Total Loss: 607.2456\n",
      "Epoch 8/10, Batch 2530/4401, Batch Loss: 0.2656, Total Loss: 609.2858\n",
      "Epoch 8/10, Batch 2540/4401, Batch Loss: 0.0146, Total Loss: 611.1981\n",
      "Epoch 8/10, Batch 2550/4401, Batch Loss: 0.2872, Total Loss: 613.8743\n",
      "Epoch 8/10, Batch 2560/4401, Batch Loss: 0.2403, Total Loss: 615.9139\n",
      "Epoch 8/10, Batch 2570/4401, Batch Loss: 0.3078, Total Loss: 618.3828\n",
      "Epoch 8/10, Batch 2580/4401, Batch Loss: 0.1844, Total Loss: 620.6823\n",
      "Epoch 8/10, Batch 2590/4401, Batch Loss: 0.2762, Total Loss: 623.5266\n",
      "Epoch 8/10, Batch 2600/4401, Batch Loss: 0.2274, Total Loss: 625.5276\n",
      "Epoch 8/10, Batch 2610/4401, Batch Loss: 0.1408, Total Loss: 628.1589\n",
      "Epoch 8/10, Batch 2620/4401, Batch Loss: 0.2879, Total Loss: 631.2413\n",
      "Epoch 8/10, Batch 2630/4401, Batch Loss: 0.0010, Total Loss: 632.9454\n",
      "Epoch 8/10, Batch 2640/4401, Batch Loss: 0.0928, Total Loss: 635.2641\n",
      "Epoch 8/10, Batch 2650/4401, Batch Loss: 0.1942, Total Loss: 637.8346\n",
      "Epoch 8/10, Batch 2660/4401, Batch Loss: 0.4993, Total Loss: 639.7533\n",
      "Epoch 8/10, Batch 2670/4401, Batch Loss: 0.1603, Total Loss: 641.6519\n",
      "Epoch 8/10, Batch 2680/4401, Batch Loss: 0.0575, Total Loss: 643.5742\n",
      "Epoch 8/10, Batch 2690/4401, Batch Loss: 0.2362, Total Loss: 646.2121\n",
      "Epoch 8/10, Batch 2700/4401, Batch Loss: 0.1719, Total Loss: 649.3354\n",
      "Epoch 8/10, Batch 2710/4401, Batch Loss: 0.1801, Total Loss: 651.4566\n",
      "Epoch 8/10, Batch 2720/4401, Batch Loss: 0.2287, Total Loss: 653.7687\n",
      "Epoch 8/10, Batch 2730/4401, Batch Loss: 0.4606, Total Loss: 656.1296\n",
      "Epoch 8/10, Batch 2740/4401, Batch Loss: 0.6604, Total Loss: 658.7574\n",
      "Epoch 8/10, Batch 2750/4401, Batch Loss: 0.3002, Total Loss: 660.8683\n",
      "Epoch 8/10, Batch 2760/4401, Batch Loss: 0.0650, Total Loss: 662.8009\n",
      "Epoch 8/10, Batch 2770/4401, Batch Loss: 0.2908, Total Loss: 665.7754\n",
      "Epoch 8/10, Batch 2780/4401, Batch Loss: 0.3268, Total Loss: 668.8879\n",
      "Epoch 8/10, Batch 2790/4401, Batch Loss: 0.2733, Total Loss: 671.3746\n",
      "Epoch 8/10, Batch 2800/4401, Batch Loss: 0.5184, Total Loss: 673.5944\n",
      "Epoch 8/10, Batch 2810/4401, Batch Loss: 0.2558, Total Loss: 675.6850\n",
      "Epoch 8/10, Batch 2820/4401, Batch Loss: 0.1915, Total Loss: 678.6874\n",
      "Epoch 8/10, Batch 2830/4401, Batch Loss: 0.1816, Total Loss: 681.7741\n",
      "Epoch 8/10, Batch 2840/4401, Batch Loss: 0.1980, Total Loss: 684.9207\n",
      "Epoch 8/10, Batch 2850/4401, Batch Loss: 0.3069, Total Loss: 687.2896\n",
      "Epoch 8/10, Batch 2860/4401, Batch Loss: 0.3382, Total Loss: 689.1294\n",
      "Epoch 8/10, Batch 2870/4401, Batch Loss: 0.3371, Total Loss: 692.0904\n",
      "Epoch 8/10, Batch 2880/4401, Batch Loss: 0.2709, Total Loss: 695.8918\n",
      "Epoch 8/10, Batch 2890/4401, Batch Loss: 0.3037, Total Loss: 698.6709\n",
      "Epoch 8/10, Batch 2900/4401, Batch Loss: 0.3057, Total Loss: 701.3943\n",
      "Epoch 8/10, Batch 2910/4401, Batch Loss: 0.1766, Total Loss: 704.0315\n",
      "Epoch 8/10, Batch 2920/4401, Batch Loss: 0.0081, Total Loss: 706.7230\n",
      "Epoch 8/10, Batch 2930/4401, Batch Loss: 0.1109, Total Loss: 708.9842\n",
      "Epoch 8/10, Batch 2940/4401, Batch Loss: 0.1898, Total Loss: 711.9212\n",
      "Epoch 8/10, Batch 2950/4401, Batch Loss: 0.2532, Total Loss: 713.6833\n",
      "Epoch 8/10, Batch 2960/4401, Batch Loss: 0.1616, Total Loss: 716.3840\n",
      "Epoch 8/10, Batch 2970/4401, Batch Loss: 0.1239, Total Loss: 719.0524\n",
      "Epoch 8/10, Batch 2980/4401, Batch Loss: 0.4643, Total Loss: 721.5535\n",
      "Epoch 8/10, Batch 2990/4401, Batch Loss: 0.1385, Total Loss: 723.9198\n",
      "Epoch 8/10, Batch 3000/4401, Batch Loss: 0.1587, Total Loss: 727.2796\n",
      "Epoch 8/10, Batch 3010/4401, Batch Loss: 0.2127, Total Loss: 729.3165\n",
      "Epoch 8/10, Batch 3020/4401, Batch Loss: 0.1096, Total Loss: 731.3364\n",
      "Epoch 8/10, Batch 3030/4401, Batch Loss: 0.3195, Total Loss: 733.9936\n",
      "Epoch 8/10, Batch 3040/4401, Batch Loss: 0.3257, Total Loss: 736.8430\n",
      "Epoch 8/10, Batch 3050/4401, Batch Loss: 0.4288, Total Loss: 739.7178\n",
      "Epoch 8/10, Batch 3060/4401, Batch Loss: 0.3660, Total Loss: 741.2418\n",
      "Epoch 8/10, Batch 3070/4401, Batch Loss: 0.3176, Total Loss: 743.2995\n",
      "Epoch 8/10, Batch 3080/4401, Batch Loss: 0.1944, Total Loss: 745.6943\n",
      "Epoch 8/10, Batch 3090/4401, Batch Loss: 0.1823, Total Loss: 748.4309\n",
      "Epoch 8/10, Batch 3100/4401, Batch Loss: 0.5122, Total Loss: 750.8009\n",
      "Epoch 8/10, Batch 3110/4401, Batch Loss: 0.3985, Total Loss: 752.7955\n",
      "Epoch 8/10, Batch 3120/4401, Batch Loss: 0.1038, Total Loss: 755.4373\n",
      "Epoch 8/10, Batch 3130/4401, Batch Loss: 0.3383, Total Loss: 756.9799\n",
      "Epoch 8/10, Batch 3140/4401, Batch Loss: 0.0424, Total Loss: 759.1330\n",
      "Epoch 8/10, Batch 3150/4401, Batch Loss: 0.1555, Total Loss: 760.8233\n",
      "Epoch 8/10, Batch 3160/4401, Batch Loss: 0.2845, Total Loss: 762.8998\n",
      "Epoch 8/10, Batch 3170/4401, Batch Loss: 0.1975, Total Loss: 765.6783\n",
      "Epoch 8/10, Batch 3180/4401, Batch Loss: 0.2230, Total Loss: 767.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 3190/4401, Batch Loss: 0.0010, Total Loss: 770.1437\n",
      "Epoch 8/10, Batch 3200/4401, Batch Loss: 0.2344, Total Loss: 772.7951\n",
      "Epoch 8/10, Batch 3210/4401, Batch Loss: 0.1941, Total Loss: 775.1918\n",
      "Epoch 8/10, Batch 3220/4401, Batch Loss: 0.2329, Total Loss: 777.4232\n",
      "Epoch 8/10, Batch 3230/4401, Batch Loss: 0.4479, Total Loss: 779.2253\n",
      "Epoch 8/10, Batch 3240/4401, Batch Loss: 0.5502, Total Loss: 782.4457\n",
      "Epoch 8/10, Batch 3250/4401, Batch Loss: 0.2117, Total Loss: 785.2801\n",
      "Epoch 8/10, Batch 3260/4401, Batch Loss: 0.3112, Total Loss: 788.5445\n",
      "Epoch 8/10, Batch 3270/4401, Batch Loss: 0.3937, Total Loss: 791.8930\n",
      "Epoch 8/10, Batch 3280/4401, Batch Loss: 0.3825, Total Loss: 795.2968\n",
      "Epoch 8/10, Batch 3290/4401, Batch Loss: 0.2493, Total Loss: 797.7335\n",
      "Epoch 8/10, Batch 3300/4401, Batch Loss: 0.0954, Total Loss: 800.5685\n",
      "Epoch 8/10, Batch 3310/4401, Batch Loss: 0.2693, Total Loss: 803.9745\n",
      "Epoch 8/10, Batch 3320/4401, Batch Loss: 0.0974, Total Loss: 806.6130\n",
      "Epoch 8/10, Batch 3330/4401, Batch Loss: 0.1863, Total Loss: 808.4209\n",
      "Epoch 8/10, Batch 3340/4401, Batch Loss: 0.2755, Total Loss: 810.9511\n",
      "Epoch 8/10, Batch 3350/4401, Batch Loss: 0.3139, Total Loss: 814.5649\n",
      "Epoch 8/10, Batch 3360/4401, Batch Loss: 0.2508, Total Loss: 817.2726\n",
      "Epoch 8/10, Batch 3370/4401, Batch Loss: 0.3830, Total Loss: 819.3688\n",
      "Epoch 8/10, Batch 3380/4401, Batch Loss: 0.2323, Total Loss: 821.2583\n",
      "Epoch 8/10, Batch 3390/4401, Batch Loss: 0.3766, Total Loss: 823.5613\n",
      "Epoch 8/10, Batch 3400/4401, Batch Loss: 0.0606, Total Loss: 826.0251\n",
      "Epoch 8/10, Batch 3410/4401, Batch Loss: 0.2467, Total Loss: 828.3353\n",
      "Epoch 8/10, Batch 3420/4401, Batch Loss: 0.5314, Total Loss: 831.7528\n",
      "Epoch 8/10, Batch 3430/4401, Batch Loss: 0.4627, Total Loss: 833.9043\n",
      "Epoch 8/10, Batch 3440/4401, Batch Loss: 0.1153, Total Loss: 836.4723\n",
      "Epoch 8/10, Batch 3450/4401, Batch Loss: 0.3219, Total Loss: 838.7800\n",
      "Epoch 8/10, Batch 3460/4401, Batch Loss: 0.1112, Total Loss: 841.5046\n",
      "Epoch 8/10, Batch 3470/4401, Batch Loss: 0.1375, Total Loss: 843.9109\n",
      "Epoch 8/10, Batch 3480/4401, Batch Loss: 0.2592, Total Loss: 846.0630\n",
      "Epoch 8/10, Batch 3490/4401, Batch Loss: 0.1380, Total Loss: 848.5677\n",
      "Epoch 8/10, Batch 3500/4401, Batch Loss: 0.1616, Total Loss: 850.8681\n",
      "Epoch 8/10, Batch 3510/4401, Batch Loss: 0.1794, Total Loss: 852.9404\n",
      "Epoch 8/10, Batch 3520/4401, Batch Loss: 0.3511, Total Loss: 855.4324\n",
      "Epoch 8/10, Batch 3530/4401, Batch Loss: 0.2052, Total Loss: 857.7739\n",
      "Epoch 8/10, Batch 3540/4401, Batch Loss: 0.2644, Total Loss: 860.1301\n",
      "Epoch 8/10, Batch 3550/4401, Batch Loss: 0.1924, Total Loss: 862.5892\n",
      "Epoch 8/10, Batch 3560/4401, Batch Loss: 0.0725, Total Loss: 864.9672\n",
      "Epoch 8/10, Batch 3570/4401, Batch Loss: 0.3474, Total Loss: 867.4367\n",
      "Epoch 8/10, Batch 3580/4401, Batch Loss: 0.3206, Total Loss: 869.7618\n",
      "Epoch 8/10, Batch 3590/4401, Batch Loss: 0.2710, Total Loss: 872.2621\n",
      "Epoch 8/10, Batch 3600/4401, Batch Loss: 0.4301, Total Loss: 875.1247\n",
      "Epoch 8/10, Batch 3610/4401, Batch Loss: 0.0742, Total Loss: 876.6989\n",
      "Epoch 8/10, Batch 3620/4401, Batch Loss: 0.2615, Total Loss: 878.5528\n",
      "Epoch 8/10, Batch 3630/4401, Batch Loss: 0.0603, Total Loss: 880.4093\n",
      "Epoch 8/10, Batch 3640/4401, Batch Loss: 0.2924, Total Loss: 882.8294\n",
      "Epoch 8/10, Batch 3650/4401, Batch Loss: 0.1354, Total Loss: 884.8111\n",
      "Epoch 8/10, Batch 3660/4401, Batch Loss: 0.1887, Total Loss: 887.1688\n",
      "Epoch 8/10, Batch 3670/4401, Batch Loss: 0.2815, Total Loss: 890.0725\n",
      "Epoch 8/10, Batch 3680/4401, Batch Loss: 0.4480, Total Loss: 893.0067\n",
      "Epoch 8/10, Batch 3690/4401, Batch Loss: 0.2129, Total Loss: 896.1828\n",
      "Epoch 8/10, Batch 3700/4401, Batch Loss: 0.3670, Total Loss: 898.7529\n",
      "Epoch 8/10, Batch 3710/4401, Batch Loss: 0.1218, Total Loss: 901.1169\n",
      "Epoch 8/10, Batch 3720/4401, Batch Loss: 0.5828, Total Loss: 904.1430\n",
      "Epoch 8/10, Batch 3730/4401, Batch Loss: 0.0154, Total Loss: 906.2001\n",
      "Epoch 8/10, Batch 3740/4401, Batch Loss: 0.3362, Total Loss: 908.1475\n",
      "Epoch 8/10, Batch 3750/4401, Batch Loss: 0.1179, Total Loss: 910.4768\n",
      "Epoch 8/10, Batch 3760/4401, Batch Loss: 0.1880, Total Loss: 912.7755\n",
      "Epoch 8/10, Batch 3770/4401, Batch Loss: 0.0504, Total Loss: 914.3433\n",
      "Epoch 8/10, Batch 3780/4401, Batch Loss: 0.0485, Total Loss: 916.8266\n",
      "Epoch 8/10, Batch 3790/4401, Batch Loss: 0.1145, Total Loss: 919.4548\n",
      "Epoch 8/10, Batch 3800/4401, Batch Loss: 0.1158, Total Loss: 922.7260\n",
      "Epoch 8/10, Batch 3810/4401, Batch Loss: 0.2350, Total Loss: 925.0784\n",
      "Epoch 8/10, Batch 3820/4401, Batch Loss: 0.0322, Total Loss: 926.7587\n",
      "Epoch 8/10, Batch 3830/4401, Batch Loss: 0.4481, Total Loss: 929.2679\n",
      "Epoch 8/10, Batch 3840/4401, Batch Loss: 0.4783, Total Loss: 933.0304\n",
      "Epoch 8/10, Batch 3850/4401, Batch Loss: 0.3743, Total Loss: 934.8000\n",
      "Epoch 8/10, Batch 3860/4401, Batch Loss: 0.1055, Total Loss: 937.3479\n",
      "Epoch 8/10, Batch 3870/4401, Batch Loss: 0.3285, Total Loss: 939.9793\n",
      "Epoch 8/10, Batch 3880/4401, Batch Loss: 0.0645, Total Loss: 942.0111\n",
      "Epoch 8/10, Batch 3890/4401, Batch Loss: 0.2527, Total Loss: 944.0064\n",
      "Epoch 8/10, Batch 3900/4401, Batch Loss: 0.1812, Total Loss: 946.1185\n",
      "Epoch 8/10, Batch 3910/4401, Batch Loss: 0.0031, Total Loss: 947.7543\n",
      "Epoch 8/10, Batch 3920/4401, Batch Loss: 0.4105, Total Loss: 950.1166\n",
      "Epoch 8/10, Batch 3930/4401, Batch Loss: 0.3670, Total Loss: 952.0380\n",
      "Epoch 8/10, Batch 3940/4401, Batch Loss: 0.0679, Total Loss: 954.5059\n",
      "Epoch 8/10, Batch 3950/4401, Batch Loss: 0.1818, Total Loss: 957.0055\n",
      "Epoch 8/10, Batch 3960/4401, Batch Loss: 0.2626, Total Loss: 959.6079\n",
      "Epoch 8/10, Batch 3970/4401, Batch Loss: 0.3997, Total Loss: 962.5303\n",
      "Epoch 8/10, Batch 3980/4401, Batch Loss: 0.2838, Total Loss: 964.3372\n",
      "Epoch 8/10, Batch 3990/4401, Batch Loss: 0.0996, Total Loss: 965.6638\n",
      "Epoch 8/10, Batch 4000/4401, Batch Loss: 0.0913, Total Loss: 968.6761\n",
      "Epoch 8/10, Batch 4010/4401, Batch Loss: 0.1026, Total Loss: 970.7514\n",
      "Epoch 8/10, Batch 4020/4401, Batch Loss: 0.1842, Total Loss: 973.0915\n",
      "Epoch 8/10, Batch 4030/4401, Batch Loss: 0.2946, Total Loss: 976.5218\n",
      "Epoch 8/10, Batch 4040/4401, Batch Loss: 0.2011, Total Loss: 978.3059\n",
      "Epoch 8/10, Batch 4050/4401, Batch Loss: 0.1276, Total Loss: 980.8737\n",
      "Epoch 8/10, Batch 4060/4401, Batch Loss: 0.2084, Total Loss: 983.2728\n",
      "Epoch 8/10, Batch 4070/4401, Batch Loss: 0.0463, Total Loss: 985.6421\n",
      "Epoch 8/10, Batch 4080/4401, Batch Loss: 0.3269, Total Loss: 987.6604\n",
      "Epoch 8/10, Batch 4090/4401, Batch Loss: 0.0067, Total Loss: 989.8916\n",
      "Epoch 8/10, Batch 4100/4401, Batch Loss: 0.3232, Total Loss: 993.6646\n",
      "Epoch 8/10, Batch 4110/4401, Batch Loss: 0.1243, Total Loss: 995.7621\n",
      "Epoch 8/10, Batch 4120/4401, Batch Loss: 0.2514, Total Loss: 998.2612\n",
      "Epoch 8/10, Batch 4130/4401, Batch Loss: 0.5507, Total Loss: 1001.3759\n",
      "Epoch 8/10, Batch 4140/4401, Batch Loss: 0.2228, Total Loss: 1003.2248\n",
      "Epoch 8/10, Batch 4150/4401, Batch Loss: 0.0009, Total Loss: 1005.6747\n",
      "Epoch 8/10, Batch 4160/4401, Batch Loss: 0.0022, Total Loss: 1007.9105\n",
      "Epoch 8/10, Batch 4170/4401, Batch Loss: 0.4211, Total Loss: 1010.2409\n",
      "Epoch 8/10, Batch 4180/4401, Batch Loss: 0.0767, Total Loss: 1012.5048\n",
      "Epoch 8/10, Batch 4190/4401, Batch Loss: 0.1509, Total Loss: 1014.7735\n",
      "Epoch 8/10, Batch 4200/4401, Batch Loss: 0.1468, Total Loss: 1017.4285\n",
      "Epoch 8/10, Batch 4210/4401, Batch Loss: 0.4587, Total Loss: 1019.6869\n",
      "Epoch 8/10, Batch 4220/4401, Batch Loss: 0.1303, Total Loss: 1021.4556\n",
      "Epoch 8/10, Batch 4230/4401, Batch Loss: 0.1922, Total Loss: 1024.7372\n",
      "Epoch 8/10, Batch 4240/4401, Batch Loss: 0.1414, Total Loss: 1027.2911\n",
      "Epoch 8/10, Batch 4250/4401, Batch Loss: 0.1495, Total Loss: 1030.0730\n",
      "Epoch 8/10, Batch 4260/4401, Batch Loss: 0.0640, Total Loss: 1031.9515\n",
      "Epoch 8/10, Batch 4270/4401, Batch Loss: 0.3795, Total Loss: 1034.6346\n",
      "Epoch 8/10, Batch 4280/4401, Batch Loss: 0.4251, Total Loss: 1037.5249\n",
      "Epoch 8/10, Batch 4290/4401, Batch Loss: 0.1197, Total Loss: 1040.2643\n",
      "Epoch 8/10, Batch 4300/4401, Batch Loss: 0.1392, Total Loss: 1043.0819\n",
      "Epoch 8/10, Batch 4310/4401, Batch Loss: 0.2537, Total Loss: 1045.3870\n",
      "Epoch 8/10, Batch 4320/4401, Batch Loss: 0.5092, Total Loss: 1047.7938\n",
      "Epoch 8/10, Batch 4330/4401, Batch Loss: 0.3226, Total Loss: 1050.5126\n",
      "Epoch 8/10, Batch 4340/4401, Batch Loss: 0.4391, Total Loss: 1054.0142\n",
      "Epoch 8/10, Batch 4350/4401, Batch Loss: 0.2224, Total Loss: 1056.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 4360/4401, Batch Loss: 0.2396, Total Loss: 1060.1247\n",
      "Epoch 8/10, Batch 4370/4401, Batch Loss: 0.1444, Total Loss: 1062.5148\n",
      "Epoch 8/10, Batch 4380/4401, Batch Loss: 0.1800, Total Loss: 1065.5702\n",
      "Epoch 8/10, Batch 4390/4401, Batch Loss: 0.1450, Total Loss: 1068.7604\n",
      "Epoch 8/10, Batch 4400/4401, Batch Loss: 0.4189, Total Loss: 1072.0656\n",
      "Epoch 8/10, Batch 4401/4401, Batch Loss: 0.2815, Total Loss: 1072.3471\n",
      "Epoch 8/10 completed. Total Loss: 1072.3471\n",
      "\n",
      "Epoch 9/10 running...\n",
      "cuda:0\n",
      "Epoch 9/10, Batch 10/4401, Batch Loss: 0.3349, Total Loss: 2.6798\n",
      "Epoch 9/10, Batch 20/4401, Batch Loss: 0.2892, Total Loss: 4.5110\n",
      "Epoch 9/10, Batch 30/4401, Batch Loss: 0.1883, Total Loss: 6.7336\n",
      "Epoch 9/10, Batch 40/4401, Batch Loss: 0.8918, Total Loss: 10.4860\n",
      "Epoch 9/10, Batch 50/4401, Batch Loss: 0.4129, Total Loss: 13.3251\n",
      "Epoch 9/10, Batch 60/4401, Batch Loss: 0.1848, Total Loss: 14.8560\n",
      "Epoch 9/10, Batch 70/4401, Batch Loss: 0.2825, Total Loss: 17.9066\n",
      "Epoch 9/10, Batch 80/4401, Batch Loss: 0.2269, Total Loss: 20.6011\n",
      "Epoch 9/10, Batch 90/4401, Batch Loss: 0.1700, Total Loss: 22.8845\n",
      "Epoch 9/10, Batch 100/4401, Batch Loss: 0.5875, Total Loss: 24.7753\n",
      "Epoch 9/10, Batch 110/4401, Batch Loss: 0.4968, Total Loss: 27.7202\n",
      "Epoch 9/10, Batch 120/4401, Batch Loss: 0.0998, Total Loss: 30.9476\n",
      "Epoch 9/10, Batch 130/4401, Batch Loss: 0.1752, Total Loss: 32.8526\n",
      "Epoch 9/10, Batch 140/4401, Batch Loss: 0.1630, Total Loss: 35.3711\n",
      "Epoch 9/10, Batch 150/4401, Batch Loss: 0.4751, Total Loss: 38.5126\n",
      "Epoch 9/10, Batch 160/4401, Batch Loss: 0.3919, Total Loss: 41.2054\n",
      "Epoch 9/10, Batch 170/4401, Batch Loss: 0.4074, Total Loss: 43.2693\n",
      "Epoch 9/10, Batch 180/4401, Batch Loss: 0.0462, Total Loss: 45.5564\n",
      "Epoch 9/10, Batch 190/4401, Batch Loss: 0.0624, Total Loss: 47.5748\n",
      "Epoch 9/10, Batch 200/4401, Batch Loss: 0.3722, Total Loss: 50.0359\n",
      "Epoch 9/10, Batch 210/4401, Batch Loss: 0.1733, Total Loss: 52.2637\n",
      "Epoch 9/10, Batch 220/4401, Batch Loss: 0.1542, Total Loss: 55.2255\n",
      "Epoch 9/10, Batch 230/4401, Batch Loss: 0.0897, Total Loss: 57.6910\n",
      "Epoch 9/10, Batch 240/4401, Batch Loss: 0.0816, Total Loss: 60.5540\n",
      "Epoch 9/10, Batch 250/4401, Batch Loss: 0.2783, Total Loss: 62.2631\n",
      "Epoch 9/10, Batch 260/4401, Batch Loss: 0.1149, Total Loss: 64.3799\n",
      "Epoch 9/10, Batch 270/4401, Batch Loss: 0.0044, Total Loss: 66.4475\n",
      "Epoch 9/10, Batch 280/4401, Batch Loss: 0.0784, Total Loss: 68.1893\n",
      "Epoch 9/10, Batch 290/4401, Batch Loss: 0.4450, Total Loss: 70.6846\n",
      "Epoch 9/10, Batch 300/4401, Batch Loss: 0.2265, Total Loss: 73.0142\n",
      "Epoch 9/10, Batch 310/4401, Batch Loss: 0.4636, Total Loss: 75.4331\n",
      "Epoch 9/10, Batch 320/4401, Batch Loss: 0.2070, Total Loss: 77.7517\n",
      "Epoch 9/10, Batch 330/4401, Batch Loss: 0.1933, Total Loss: 79.9098\n",
      "Epoch 9/10, Batch 340/4401, Batch Loss: 0.0659, Total Loss: 82.1728\n",
      "Epoch 9/10, Batch 350/4401, Batch Loss: 0.1556, Total Loss: 84.6093\n",
      "Epoch 9/10, Batch 360/4401, Batch Loss: 0.4797, Total Loss: 87.1715\n",
      "Epoch 9/10, Batch 370/4401, Batch Loss: 0.2903, Total Loss: 90.5088\n",
      "Epoch 9/10, Batch 380/4401, Batch Loss: 0.0570, Total Loss: 92.3446\n",
      "Epoch 9/10, Batch 390/4401, Batch Loss: 0.3553, Total Loss: 94.5441\n",
      "Epoch 9/10, Batch 400/4401, Batch Loss: 0.2045, Total Loss: 96.4174\n",
      "Epoch 9/10, Batch 410/4401, Batch Loss: 0.4724, Total Loss: 98.7537\n",
      "Epoch 9/10, Batch 420/4401, Batch Loss: 0.1697, Total Loss: 100.2325\n",
      "Epoch 9/10, Batch 430/4401, Batch Loss: 0.1779, Total Loss: 102.4745\n",
      "Epoch 9/10, Batch 440/4401, Batch Loss: 0.2343, Total Loss: 104.7778\n",
      "Epoch 9/10, Batch 450/4401, Batch Loss: 0.1871, Total Loss: 107.0481\n",
      "Epoch 9/10, Batch 460/4401, Batch Loss: 0.2531, Total Loss: 109.3265\n",
      "Epoch 9/10, Batch 470/4401, Batch Loss: 0.1963, Total Loss: 111.5110\n",
      "Epoch 9/10, Batch 480/4401, Batch Loss: 0.2072, Total Loss: 114.3335\n",
      "Epoch 9/10, Batch 490/4401, Batch Loss: 0.0021, Total Loss: 117.0377\n",
      "Epoch 9/10, Batch 500/4401, Batch Loss: 0.4013, Total Loss: 119.1117\n",
      "Epoch 9/10, Batch 510/4401, Batch Loss: 0.2775, Total Loss: 121.3519\n",
      "Epoch 9/10, Batch 520/4401, Batch Loss: 0.2588, Total Loss: 123.8773\n",
      "Epoch 9/10, Batch 530/4401, Batch Loss: 0.0878, Total Loss: 126.8851\n",
      "Epoch 9/10, Batch 540/4401, Batch Loss: 0.3058, Total Loss: 128.8864\n",
      "Epoch 9/10, Batch 550/4401, Batch Loss: 0.2194, Total Loss: 130.8779\n",
      "Epoch 9/10, Batch 560/4401, Batch Loss: 0.1612, Total Loss: 132.7876\n",
      "Epoch 9/10, Batch 570/4401, Batch Loss: 0.1934, Total Loss: 135.5056\n",
      "Epoch 9/10, Batch 580/4401, Batch Loss: 0.3120, Total Loss: 137.8434\n",
      "Epoch 9/10, Batch 590/4401, Batch Loss: 0.1647, Total Loss: 140.2656\n",
      "Epoch 9/10, Batch 600/4401, Batch Loss: 0.2500, Total Loss: 142.1612\n",
      "Epoch 9/10, Batch 610/4401, Batch Loss: 0.1814, Total Loss: 144.2376\n",
      "Epoch 9/10, Batch 620/4401, Batch Loss: 0.0988, Total Loss: 146.2145\n",
      "Epoch 9/10, Batch 630/4401, Batch Loss: 0.2901, Total Loss: 148.6420\n",
      "Epoch 9/10, Batch 640/4401, Batch Loss: 0.1552, Total Loss: 150.6012\n",
      "Epoch 9/10, Batch 650/4401, Batch Loss: 0.0318, Total Loss: 152.4603\n",
      "Epoch 9/10, Batch 660/4401, Batch Loss: 0.0006, Total Loss: 154.5476\n",
      "Epoch 9/10, Batch 670/4401, Batch Loss: 0.4629, Total Loss: 157.6496\n",
      "Epoch 9/10, Batch 680/4401, Batch Loss: 0.2405, Total Loss: 159.9124\n",
      "Epoch 9/10, Batch 690/4401, Batch Loss: 0.0718, Total Loss: 162.2708\n",
      "Epoch 9/10, Batch 700/4401, Batch Loss: 0.2550, Total Loss: 164.7517\n",
      "Epoch 9/10, Batch 710/4401, Batch Loss: 0.1021, Total Loss: 167.4246\n",
      "Epoch 9/10, Batch 720/4401, Batch Loss: 0.2124, Total Loss: 169.8232\n",
      "Epoch 9/10, Batch 730/4401, Batch Loss: 0.4218, Total Loss: 172.4933\n",
      "Epoch 9/10, Batch 740/4401, Batch Loss: 0.3238, Total Loss: 174.7140\n",
      "Epoch 9/10, Batch 750/4401, Batch Loss: 0.1497, Total Loss: 177.1773\n",
      "Epoch 9/10, Batch 760/4401, Batch Loss: 0.1714, Total Loss: 179.9011\n",
      "Epoch 9/10, Batch 770/4401, Batch Loss: 0.0859, Total Loss: 181.8258\n",
      "Epoch 9/10, Batch 780/4401, Batch Loss: 0.0352, Total Loss: 184.0529\n",
      "Epoch 9/10, Batch 790/4401, Batch Loss: 0.2740, Total Loss: 186.6950\n",
      "Epoch 9/10, Batch 800/4401, Batch Loss: 0.0816, Total Loss: 188.5126\n",
      "Epoch 9/10, Batch 810/4401, Batch Loss: 0.2280, Total Loss: 190.6682\n",
      "Epoch 9/10, Batch 820/4401, Batch Loss: 0.3101, Total Loss: 192.3807\n",
      "Epoch 9/10, Batch 830/4401, Batch Loss: 0.1899, Total Loss: 194.4421\n",
      "Epoch 9/10, Batch 840/4401, Batch Loss: 0.1244, Total Loss: 196.3974\n",
      "Epoch 9/10, Batch 850/4401, Batch Loss: 0.5173, Total Loss: 198.9332\n",
      "Epoch 9/10, Batch 860/4401, Batch Loss: 0.0101, Total Loss: 201.0148\n",
      "Epoch 9/10, Batch 870/4401, Batch Loss: 0.1116, Total Loss: 202.5660\n",
      "Epoch 9/10, Batch 880/4401, Batch Loss: 0.3374, Total Loss: 204.6866\n",
      "Epoch 9/10, Batch 890/4401, Batch Loss: 0.0396, Total Loss: 206.2247\n",
      "Epoch 9/10, Batch 900/4401, Batch Loss: 0.1873, Total Loss: 208.5551\n",
      "Epoch 9/10, Batch 910/4401, Batch Loss: 0.3702, Total Loss: 211.4210\n",
      "Epoch 9/10, Batch 920/4401, Batch Loss: 0.3991, Total Loss: 213.4452\n",
      "Epoch 9/10, Batch 930/4401, Batch Loss: 0.0618, Total Loss: 215.2486\n",
      "Epoch 9/10, Batch 940/4401, Batch Loss: 0.2247, Total Loss: 218.0632\n",
      "Epoch 9/10, Batch 950/4401, Batch Loss: 0.2928, Total Loss: 219.8436\n",
      "Epoch 9/10, Batch 960/4401, Batch Loss: 0.4329, Total Loss: 221.9136\n",
      "Epoch 9/10, Batch 970/4401, Batch Loss: 0.2995, Total Loss: 224.3108\n",
      "Epoch 9/10, Batch 980/4401, Batch Loss: 0.2156, Total Loss: 226.3536\n",
      "Epoch 9/10, Batch 990/4401, Batch Loss: 0.2198, Total Loss: 228.4684\n",
      "Epoch 9/10, Batch 1000/4401, Batch Loss: 0.3098, Total Loss: 231.8788\n",
      "Epoch 9/10, Batch 1010/4401, Batch Loss: 0.2401, Total Loss: 234.3354\n",
      "Epoch 9/10, Batch 1020/4401, Batch Loss: 0.2161, Total Loss: 236.8504\n",
      "Epoch 9/10, Batch 1030/4401, Batch Loss: 0.0763, Total Loss: 238.6821\n",
      "Epoch 9/10, Batch 1040/4401, Batch Loss: 0.3230, Total Loss: 240.9082\n",
      "Epoch 9/10, Batch 1050/4401, Batch Loss: 0.1158, Total Loss: 243.0284\n",
      "Epoch 9/10, Batch 1060/4401, Batch Loss: 0.1915, Total Loss: 245.3946\n",
      "Epoch 9/10, Batch 1070/4401, Batch Loss: 0.4235, Total Loss: 248.0173\n",
      "Epoch 9/10, Batch 1080/4401, Batch Loss: 0.1386, Total Loss: 249.9995\n",
      "Epoch 9/10, Batch 1090/4401, Batch Loss: 0.1366, Total Loss: 252.2609\n",
      "Epoch 9/10, Batch 1100/4401, Batch Loss: 0.1187, Total Loss: 254.4016\n",
      "Epoch 9/10, Batch 1110/4401, Batch Loss: 0.2906, Total Loss: 256.0197\n",
      "Epoch 9/10, Batch 1120/4401, Batch Loss: 0.1445, Total Loss: 258.0380\n",
      "Epoch 9/10, Batch 1130/4401, Batch Loss: 0.1078, Total Loss: 260.4827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1140/4401, Batch Loss: 0.2423, Total Loss: 263.1778\n",
      "Epoch 9/10, Batch 1150/4401, Batch Loss: 0.3354, Total Loss: 265.7375\n",
      "Epoch 9/10, Batch 1160/4401, Batch Loss: 0.1930, Total Loss: 268.0820\n",
      "Epoch 9/10, Batch 1170/4401, Batch Loss: 0.0995, Total Loss: 270.6796\n",
      "Epoch 9/10, Batch 1180/4401, Batch Loss: 0.3647, Total Loss: 272.5700\n",
      "Epoch 9/10, Batch 1190/4401, Batch Loss: 0.1330, Total Loss: 275.3752\n",
      "Epoch 9/10, Batch 1200/4401, Batch Loss: 0.1765, Total Loss: 278.5205\n",
      "Epoch 9/10, Batch 1210/4401, Batch Loss: 0.2616, Total Loss: 281.2116\n",
      "Epoch 9/10, Batch 1220/4401, Batch Loss: 0.2502, Total Loss: 283.7265\n",
      "Epoch 9/10, Batch 1230/4401, Batch Loss: 0.0717, Total Loss: 285.4574\n",
      "Epoch 9/10, Batch 1240/4401, Batch Loss: 0.2358, Total Loss: 287.9701\n",
      "Epoch 9/10, Batch 1250/4401, Batch Loss: 0.6003, Total Loss: 290.3855\n",
      "Epoch 9/10, Batch 1260/4401, Batch Loss: 0.1887, Total Loss: 293.4685\n",
      "Epoch 9/10, Batch 1270/4401, Batch Loss: 0.2554, Total Loss: 296.1246\n",
      "Epoch 9/10, Batch 1280/4401, Batch Loss: 0.3671, Total Loss: 299.9728\n",
      "Epoch 9/10, Batch 1290/4401, Batch Loss: 0.1821, Total Loss: 302.9874\n",
      "Epoch 9/10, Batch 1300/4401, Batch Loss: 0.1958, Total Loss: 305.2846\n",
      "Epoch 9/10, Batch 1310/4401, Batch Loss: 0.1135, Total Loss: 307.8090\n",
      "Epoch 9/10, Batch 1320/4401, Batch Loss: 0.3314, Total Loss: 309.9096\n",
      "Epoch 9/10, Batch 1330/4401, Batch Loss: 0.5602, Total Loss: 313.4174\n",
      "Epoch 9/10, Batch 1340/4401, Batch Loss: 0.2622, Total Loss: 316.3753\n",
      "Epoch 9/10, Batch 1350/4401, Batch Loss: 0.1632, Total Loss: 317.9602\n",
      "Epoch 9/10, Batch 1360/4401, Batch Loss: 0.4364, Total Loss: 320.1929\n",
      "Epoch 9/10, Batch 1370/4401, Batch Loss: 0.1694, Total Loss: 321.8543\n",
      "Epoch 9/10, Batch 1380/4401, Batch Loss: 0.0855, Total Loss: 323.6285\n",
      "Epoch 9/10, Batch 1390/4401, Batch Loss: 0.3456, Total Loss: 326.1976\n",
      "Epoch 9/10, Batch 1400/4401, Batch Loss: 0.0009, Total Loss: 328.1261\n",
      "Epoch 9/10, Batch 1410/4401, Batch Loss: 0.1491, Total Loss: 330.4913\n",
      "Epoch 9/10, Batch 1420/4401, Batch Loss: 0.2179, Total Loss: 332.8122\n",
      "Epoch 9/10, Batch 1430/4401, Batch Loss: 0.1956, Total Loss: 335.7181\n",
      "Epoch 9/10, Batch 1440/4401, Batch Loss: 0.6887, Total Loss: 338.0616\n",
      "Epoch 9/10, Batch 1450/4401, Batch Loss: 0.2749, Total Loss: 340.5133\n",
      "Epoch 9/10, Batch 1460/4401, Batch Loss: 0.0489, Total Loss: 342.3796\n",
      "Epoch 9/10, Batch 1470/4401, Batch Loss: 0.3296, Total Loss: 345.5171\n",
      "Epoch 9/10, Batch 1480/4401, Batch Loss: 0.3885, Total Loss: 347.6334\n",
      "Epoch 9/10, Batch 1490/4401, Batch Loss: 0.1544, Total Loss: 349.8567\n",
      "Epoch 9/10, Batch 1500/4401, Batch Loss: 0.2235, Total Loss: 351.8881\n",
      "Epoch 9/10, Batch 1510/4401, Batch Loss: 0.0641, Total Loss: 354.6867\n",
      "Epoch 9/10, Batch 1520/4401, Batch Loss: 0.2928, Total Loss: 357.1825\n",
      "Epoch 9/10, Batch 1530/4401, Batch Loss: 0.0769, Total Loss: 359.3485\n",
      "Epoch 9/10, Batch 1540/4401, Batch Loss: 0.1979, Total Loss: 361.6500\n",
      "Epoch 9/10, Batch 1550/4401, Batch Loss: 0.3096, Total Loss: 363.7250\n",
      "Epoch 9/10, Batch 1560/4401, Batch Loss: 0.0452, Total Loss: 365.7032\n",
      "Epoch 9/10, Batch 1570/4401, Batch Loss: 0.0438, Total Loss: 367.6936\n",
      "Epoch 9/10, Batch 1580/4401, Batch Loss: 0.2670, Total Loss: 369.9990\n",
      "Epoch 9/10, Batch 1590/4401, Batch Loss: 0.0470, Total Loss: 372.1116\n",
      "Epoch 9/10, Batch 1600/4401, Batch Loss: 0.2137, Total Loss: 373.6490\n",
      "Epoch 9/10, Batch 1610/4401, Batch Loss: 0.5086, Total Loss: 376.5574\n",
      "Epoch 9/10, Batch 1620/4401, Batch Loss: 0.0786, Total Loss: 377.8921\n",
      "Epoch 9/10, Batch 1630/4401, Batch Loss: 0.0466, Total Loss: 379.6194\n",
      "Epoch 9/10, Batch 1640/4401, Batch Loss: 0.3515, Total Loss: 382.8342\n",
      "Epoch 9/10, Batch 1650/4401, Batch Loss: 0.2368, Total Loss: 386.8053\n",
      "Epoch 9/10, Batch 1660/4401, Batch Loss: 0.2714, Total Loss: 390.2439\n",
      "Epoch 9/10, Batch 1670/4401, Batch Loss: 0.0696, Total Loss: 392.5217\n",
      "Epoch 9/10, Batch 1680/4401, Batch Loss: 0.3475, Total Loss: 396.0933\n",
      "Epoch 9/10, Batch 1690/4401, Batch Loss: 0.3754, Total Loss: 398.6356\n",
      "Epoch 9/10, Batch 1700/4401, Batch Loss: 0.2066, Total Loss: 401.0790\n",
      "Epoch 9/10, Batch 1710/4401, Batch Loss: 0.0954, Total Loss: 403.9332\n",
      "Epoch 9/10, Batch 1720/4401, Batch Loss: 0.0607, Total Loss: 406.7649\n",
      "Epoch 9/10, Batch 1730/4401, Batch Loss: 0.5396, Total Loss: 409.9907\n",
      "Epoch 9/10, Batch 1740/4401, Batch Loss: 0.2380, Total Loss: 412.0111\n",
      "Epoch 9/10, Batch 1750/4401, Batch Loss: 0.5054, Total Loss: 414.5390\n",
      "Epoch 9/10, Batch 1760/4401, Batch Loss: 0.0871, Total Loss: 417.2348\n",
      "Epoch 9/10, Batch 1770/4401, Batch Loss: 0.1867, Total Loss: 419.7505\n",
      "Epoch 9/10, Batch 1780/4401, Batch Loss: 0.2488, Total Loss: 421.8160\n",
      "Epoch 9/10, Batch 1790/4401, Batch Loss: 0.0025, Total Loss: 424.1077\n",
      "Epoch 9/10, Batch 1800/4401, Batch Loss: 0.2048, Total Loss: 426.4833\n",
      "Epoch 9/10, Batch 1810/4401, Batch Loss: 0.0527, Total Loss: 428.5913\n",
      "Epoch 9/10, Batch 1820/4401, Batch Loss: 0.3710, Total Loss: 431.5443\n",
      "Epoch 9/10, Batch 1830/4401, Batch Loss: 0.1487, Total Loss: 433.4705\n",
      "Epoch 9/10, Batch 1840/4401, Batch Loss: 0.1226, Total Loss: 436.5467\n",
      "Epoch 9/10, Batch 1850/4401, Batch Loss: 0.0964, Total Loss: 438.2749\n",
      "Epoch 9/10, Batch 1860/4401, Batch Loss: 0.0550, Total Loss: 440.5984\n",
      "Epoch 9/10, Batch 1870/4401, Batch Loss: 0.2090, Total Loss: 442.2602\n",
      "Epoch 9/10, Batch 1880/4401, Batch Loss: 0.1171, Total Loss: 444.4055\n",
      "Epoch 9/10, Batch 1890/4401, Batch Loss: 0.2609, Total Loss: 447.1104\n",
      "Epoch 9/10, Batch 1900/4401, Batch Loss: 0.0453, Total Loss: 449.1301\n",
      "Epoch 9/10, Batch 1910/4401, Batch Loss: 0.2768, Total Loss: 451.5974\n",
      "Epoch 9/10, Batch 1920/4401, Batch Loss: 0.1736, Total Loss: 453.3777\n",
      "Epoch 9/10, Batch 1930/4401, Batch Loss: 0.2267, Total Loss: 455.3656\n",
      "Epoch 9/10, Batch 1940/4401, Batch Loss: 0.7228, Total Loss: 457.3081\n",
      "Epoch 9/10, Batch 1950/4401, Batch Loss: 0.1743, Total Loss: 459.6294\n",
      "Epoch 9/10, Batch 1960/4401, Batch Loss: 0.1193, Total Loss: 461.3652\n",
      "Epoch 9/10, Batch 1970/4401, Batch Loss: 0.1962, Total Loss: 462.9387\n",
      "Epoch 9/10, Batch 1980/4401, Batch Loss: 0.1019, Total Loss: 465.4513\n",
      "Epoch 9/10, Batch 1990/4401, Batch Loss: 0.3408, Total Loss: 467.9040\n",
      "Epoch 9/10, Batch 2000/4401, Batch Loss: 0.6459, Total Loss: 470.8081\n",
      "Epoch 9/10, Batch 2010/4401, Batch Loss: 0.1908, Total Loss: 474.6056\n",
      "Epoch 9/10, Batch 2020/4401, Batch Loss: 0.2001, Total Loss: 477.1068\n",
      "Epoch 9/10, Batch 2030/4401, Batch Loss: 0.0659, Total Loss: 479.8067\n",
      "Epoch 9/10, Batch 2040/4401, Batch Loss: 0.0705, Total Loss: 482.8743\n",
      "Epoch 9/10, Batch 2050/4401, Batch Loss: 0.0531, Total Loss: 484.9977\n",
      "Epoch 9/10, Batch 2060/4401, Batch Loss: 0.2996, Total Loss: 487.4223\n",
      "Epoch 9/10, Batch 2070/4401, Batch Loss: 0.0955, Total Loss: 489.4980\n",
      "Epoch 9/10, Batch 2080/4401, Batch Loss: 0.1884, Total Loss: 490.7130\n",
      "Epoch 9/10, Batch 2090/4401, Batch Loss: 0.0453, Total Loss: 492.2255\n",
      "Epoch 9/10, Batch 2100/4401, Batch Loss: 0.2891, Total Loss: 494.7265\n",
      "Epoch 9/10, Batch 2110/4401, Batch Loss: 0.0423, Total Loss: 496.8526\n",
      "Epoch 9/10, Batch 2120/4401, Batch Loss: 0.3113, Total Loss: 499.1944\n",
      "Epoch 9/10, Batch 2130/4401, Batch Loss: 0.1913, Total Loss: 501.5119\n",
      "Epoch 9/10, Batch 2140/4401, Batch Loss: 0.1352, Total Loss: 503.4939\n",
      "Epoch 9/10, Batch 2150/4401, Batch Loss: 0.2468, Total Loss: 505.5167\n",
      "Epoch 9/10, Batch 2160/4401, Batch Loss: 0.3101, Total Loss: 508.6267\n",
      "Epoch 9/10, Batch 2170/4401, Batch Loss: 0.1273, Total Loss: 511.2200\n",
      "Epoch 9/10, Batch 2180/4401, Batch Loss: 0.1245, Total Loss: 513.4683\n",
      "Epoch 9/10, Batch 2190/4401, Batch Loss: 0.1700, Total Loss: 515.1858\n",
      "Epoch 9/10, Batch 2200/4401, Batch Loss: 0.1055, Total Loss: 516.7380\n",
      "Epoch 9/10, Batch 2210/4401, Batch Loss: 0.0019, Total Loss: 518.5238\n",
      "Epoch 9/10, Batch 2220/4401, Batch Loss: 0.2922, Total Loss: 520.6279\n",
      "Epoch 9/10, Batch 2230/4401, Batch Loss: 0.1369, Total Loss: 523.2407\n",
      "Epoch 9/10, Batch 2240/4401, Batch Loss: 0.2542, Total Loss: 525.2721\n",
      "Epoch 9/10, Batch 2250/4401, Batch Loss: 0.3767, Total Loss: 527.8888\n",
      "Epoch 9/10, Batch 2260/4401, Batch Loss: 0.3567, Total Loss: 529.9958\n",
      "Epoch 9/10, Batch 2270/4401, Batch Loss: 0.3649, Total Loss: 532.1883\n",
      "Epoch 9/10, Batch 2280/4401, Batch Loss: 0.0668, Total Loss: 534.0367\n",
      "Epoch 9/10, Batch 2290/4401, Batch Loss: 0.2697, Total Loss: 536.4398\n",
      "Epoch 9/10, Batch 2300/4401, Batch Loss: 0.2934, Total Loss: 538.8043\n",
      "Epoch 9/10, Batch 2310/4401, Batch Loss: 0.2877, Total Loss: 541.4948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 2320/4401, Batch Loss: 0.0656, Total Loss: 544.1089\n",
      "Epoch 9/10, Batch 2330/4401, Batch Loss: 0.4038, Total Loss: 546.7105\n",
      "Epoch 9/10, Batch 2340/4401, Batch Loss: 0.1439, Total Loss: 548.4548\n",
      "Epoch 9/10, Batch 2350/4401, Batch Loss: 0.4665, Total Loss: 551.8017\n",
      "Epoch 9/10, Batch 2360/4401, Batch Loss: 0.1845, Total Loss: 553.8777\n",
      "Epoch 9/10, Batch 2370/4401, Batch Loss: 0.0526, Total Loss: 556.0510\n",
      "Epoch 9/10, Batch 2380/4401, Batch Loss: 0.1003, Total Loss: 558.2858\n",
      "Epoch 9/10, Batch 2390/4401, Batch Loss: 0.1845, Total Loss: 561.5117\n",
      "Epoch 9/10, Batch 2400/4401, Batch Loss: 0.3497, Total Loss: 563.5099\n",
      "Epoch 9/10, Batch 2410/4401, Batch Loss: 0.4804, Total Loss: 567.8701\n",
      "Epoch 9/10, Batch 2420/4401, Batch Loss: 0.9723, Total Loss: 570.3382\n",
      "Epoch 9/10, Batch 2430/4401, Batch Loss: 0.2983, Total Loss: 573.0738\n",
      "Epoch 9/10, Batch 2440/4401, Batch Loss: 0.1605, Total Loss: 575.7324\n",
      "Epoch 9/10, Batch 2450/4401, Batch Loss: 0.1672, Total Loss: 578.1535\n",
      "Epoch 9/10, Batch 2460/4401, Batch Loss: 0.3485, Total Loss: 581.6086\n",
      "Epoch 9/10, Batch 2470/4401, Batch Loss: 0.2309, Total Loss: 584.7439\n",
      "Epoch 9/10, Batch 2480/4401, Batch Loss: 0.2194, Total Loss: 586.7181\n",
      "Epoch 9/10, Batch 2490/4401, Batch Loss: 0.3115, Total Loss: 589.1139\n",
      "Epoch 9/10, Batch 2500/4401, Batch Loss: 0.1116, Total Loss: 591.1852\n",
      "Epoch 9/10, Batch 2510/4401, Batch Loss: 0.5513, Total Loss: 593.0460\n",
      "Epoch 9/10, Batch 2520/4401, Batch Loss: 0.0730, Total Loss: 594.5146\n",
      "Epoch 9/10, Batch 2530/4401, Batch Loss: 0.3400, Total Loss: 596.9001\n",
      "Epoch 9/10, Batch 2540/4401, Batch Loss: 0.2416, Total Loss: 599.0961\n",
      "Epoch 9/10, Batch 2550/4401, Batch Loss: 0.2593, Total Loss: 601.2452\n",
      "Epoch 9/10, Batch 2560/4401, Batch Loss: 0.2657, Total Loss: 603.3409\n",
      "Epoch 9/10, Batch 2570/4401, Batch Loss: 0.0966, Total Loss: 605.4290\n",
      "Epoch 9/10, Batch 2580/4401, Batch Loss: 0.3508, Total Loss: 607.6826\n",
      "Epoch 9/10, Batch 2590/4401, Batch Loss: 0.2511, Total Loss: 609.6901\n",
      "Epoch 9/10, Batch 2600/4401, Batch Loss: 0.3941, Total Loss: 611.4852\n",
      "Epoch 9/10, Batch 2610/4401, Batch Loss: 1.0976, Total Loss: 613.6702\n",
      "Epoch 9/10, Batch 2620/4401, Batch Loss: 0.4018, Total Loss: 616.9114\n",
      "Epoch 9/10, Batch 2630/4401, Batch Loss: 0.1558, Total Loss: 618.2858\n",
      "Epoch 9/10, Batch 2640/4401, Batch Loss: 0.2494, Total Loss: 620.4952\n",
      "Epoch 9/10, Batch 2650/4401, Batch Loss: 0.2029, Total Loss: 622.5985\n",
      "Epoch 9/10, Batch 2660/4401, Batch Loss: 0.8872, Total Loss: 625.3152\n",
      "Epoch 9/10, Batch 2670/4401, Batch Loss: 0.0336, Total Loss: 627.9665\n",
      "Epoch 9/10, Batch 2680/4401, Batch Loss: 0.3249, Total Loss: 629.6142\n",
      "Epoch 9/10, Batch 2690/4401, Batch Loss: 0.0729, Total Loss: 631.6982\n",
      "Epoch 9/10, Batch 2700/4401, Batch Loss: 0.2067, Total Loss: 633.2190\n",
      "Epoch 9/10, Batch 2710/4401, Batch Loss: 0.0827, Total Loss: 635.3233\n",
      "Epoch 9/10, Batch 2720/4401, Batch Loss: 0.1326, Total Loss: 637.3739\n",
      "Epoch 9/10, Batch 2730/4401, Batch Loss: 0.3248, Total Loss: 640.3529\n",
      "Epoch 9/10, Batch 2740/4401, Batch Loss: 0.1698, Total Loss: 641.4274\n",
      "Epoch 9/10, Batch 2750/4401, Batch Loss: 0.3287, Total Loss: 643.5188\n",
      "Epoch 9/10, Batch 2760/4401, Batch Loss: 0.1418, Total Loss: 645.7691\n",
      "Epoch 9/10, Batch 2770/4401, Batch Loss: 0.1953, Total Loss: 647.2408\n",
      "Epoch 9/10, Batch 2780/4401, Batch Loss: 0.1570, Total Loss: 648.9445\n",
      "Epoch 9/10, Batch 2790/4401, Batch Loss: 0.0966, Total Loss: 651.5010\n",
      "Epoch 9/10, Batch 2800/4401, Batch Loss: 0.0946, Total Loss: 653.4716\n",
      "Epoch 9/10, Batch 2810/4401, Batch Loss: 0.2232, Total Loss: 655.6733\n",
      "Epoch 9/10, Batch 2820/4401, Batch Loss: 0.1028, Total Loss: 657.5563\n",
      "Epoch 9/10, Batch 2830/4401, Batch Loss: 0.2168, Total Loss: 659.2979\n",
      "Epoch 9/10, Batch 2840/4401, Batch Loss: 0.3775, Total Loss: 663.0137\n",
      "Epoch 9/10, Batch 2850/4401, Batch Loss: 0.1490, Total Loss: 664.9595\n",
      "Epoch 9/10, Batch 2860/4401, Batch Loss: 0.3120, Total Loss: 667.2821\n",
      "Epoch 9/10, Batch 2870/4401, Batch Loss: 0.2038, Total Loss: 669.1282\n",
      "Epoch 9/10, Batch 2880/4401, Batch Loss: 0.2222, Total Loss: 671.5750\n",
      "Epoch 9/10, Batch 2890/4401, Batch Loss: 0.2340, Total Loss: 674.0030\n",
      "Epoch 9/10, Batch 2900/4401, Batch Loss: 0.1296, Total Loss: 676.0604\n",
      "Epoch 9/10, Batch 2910/4401, Batch Loss: 0.5058, Total Loss: 679.2016\n",
      "Epoch 9/10, Batch 2920/4401, Batch Loss: 0.1436, Total Loss: 681.5250\n",
      "Epoch 9/10, Batch 2930/4401, Batch Loss: 0.1289, Total Loss: 684.5410\n",
      "Epoch 9/10, Batch 2940/4401, Batch Loss: 0.0623, Total Loss: 686.8968\n",
      "Epoch 9/10, Batch 2950/4401, Batch Loss: 0.0653, Total Loss: 689.5005\n",
      "Epoch 9/10, Batch 2960/4401, Batch Loss: 0.4124, Total Loss: 691.6471\n",
      "Epoch 9/10, Batch 2970/4401, Batch Loss: 0.1945, Total Loss: 694.0281\n",
      "Epoch 9/10, Batch 2980/4401, Batch Loss: 0.1302, Total Loss: 695.8152\n",
      "Epoch 9/10, Batch 2990/4401, Batch Loss: 0.1860, Total Loss: 697.9056\n",
      "Epoch 9/10, Batch 3000/4401, Batch Loss: 0.0990, Total Loss: 700.0540\n",
      "Epoch 9/10, Batch 3010/4401, Batch Loss: 0.3647, Total Loss: 701.9540\n",
      "Epoch 9/10, Batch 3020/4401, Batch Loss: 0.2992, Total Loss: 704.4768\n",
      "Epoch 9/10, Batch 3030/4401, Batch Loss: 0.3630, Total Loss: 706.3853\n",
      "Epoch 9/10, Batch 3040/4401, Batch Loss: 0.1115, Total Loss: 708.1958\n",
      "Epoch 9/10, Batch 3050/4401, Batch Loss: 0.2626, Total Loss: 710.4707\n",
      "Epoch 9/10, Batch 3060/4401, Batch Loss: 0.1304, Total Loss: 712.6514\n",
      "Epoch 9/10, Batch 3070/4401, Batch Loss: 0.2720, Total Loss: 714.3341\n",
      "Epoch 9/10, Batch 3080/4401, Batch Loss: 0.2787, Total Loss: 717.4449\n",
      "Epoch 9/10, Batch 3090/4401, Batch Loss: 0.0011, Total Loss: 719.7655\n",
      "Epoch 9/10, Batch 3100/4401, Batch Loss: 0.1794, Total Loss: 722.4144\n",
      "Epoch 9/10, Batch 3110/4401, Batch Loss: 0.2164, Total Loss: 725.0988\n",
      "Epoch 9/10, Batch 3120/4401, Batch Loss: 0.2654, Total Loss: 727.9086\n",
      "Epoch 9/10, Batch 3130/4401, Batch Loss: 0.3705, Total Loss: 730.4764\n",
      "Epoch 9/10, Batch 3140/4401, Batch Loss: 0.2030, Total Loss: 732.9687\n",
      "Epoch 9/10, Batch 3150/4401, Batch Loss: 0.3182, Total Loss: 735.4595\n",
      "Epoch 9/10, Batch 3160/4401, Batch Loss: 0.2359, Total Loss: 737.2331\n",
      "Epoch 9/10, Batch 3170/4401, Batch Loss: 0.2133, Total Loss: 739.4802\n",
      "Epoch 9/10, Batch 3180/4401, Batch Loss: 0.2365, Total Loss: 742.1671\n",
      "Epoch 9/10, Batch 3190/4401, Batch Loss: 0.1536, Total Loss: 744.2722\n",
      "Epoch 9/10, Batch 3200/4401, Batch Loss: 0.1696, Total Loss: 746.3489\n",
      "Epoch 9/10, Batch 3210/4401, Batch Loss: 0.2396, Total Loss: 748.7476\n",
      "Epoch 9/10, Batch 3220/4401, Batch Loss: 0.1694, Total Loss: 750.5157\n",
      "Epoch 9/10, Batch 3230/4401, Batch Loss: 0.2005, Total Loss: 752.9539\n",
      "Epoch 9/10, Batch 3240/4401, Batch Loss: 0.1027, Total Loss: 755.1370\n",
      "Epoch 9/10, Batch 3250/4401, Batch Loss: 0.1035, Total Loss: 757.5736\n",
      "Epoch 9/10, Batch 3260/4401, Batch Loss: 0.3151, Total Loss: 759.6621\n",
      "Epoch 9/10, Batch 3270/4401, Batch Loss: 0.1097, Total Loss: 761.9012\n",
      "Epoch 9/10, Batch 3280/4401, Batch Loss: 0.7590, Total Loss: 764.9288\n",
      "Epoch 9/10, Batch 3290/4401, Batch Loss: 0.3191, Total Loss: 766.7771\n",
      "Epoch 9/10, Batch 3300/4401, Batch Loss: 0.2214, Total Loss: 769.3195\n",
      "Epoch 9/10, Batch 3310/4401, Batch Loss: 0.1729, Total Loss: 771.6815\n",
      "Epoch 9/10, Batch 3320/4401, Batch Loss: 0.1121, Total Loss: 774.0939\n",
      "Epoch 9/10, Batch 3330/4401, Batch Loss: 0.3338, Total Loss: 776.5072\n",
      "Epoch 9/10, Batch 3340/4401, Batch Loss: 0.0848, Total Loss: 779.0019\n",
      "Epoch 9/10, Batch 3350/4401, Batch Loss: 0.4129, Total Loss: 781.3990\n",
      "Epoch 9/10, Batch 3360/4401, Batch Loss: 0.1295, Total Loss: 783.0191\n",
      "Epoch 9/10, Batch 3370/4401, Batch Loss: 0.3288, Total Loss: 784.5402\n",
      "Epoch 9/10, Batch 3380/4401, Batch Loss: 0.2016, Total Loss: 786.5632\n",
      "Epoch 9/10, Batch 3390/4401, Batch Loss: 0.0594, Total Loss: 788.4719\n",
      "Epoch 9/10, Batch 3400/4401, Batch Loss: 0.0023, Total Loss: 790.8141\n",
      "Epoch 9/10, Batch 3410/4401, Batch Loss: 0.3415, Total Loss: 794.1061\n",
      "Epoch 9/10, Batch 3420/4401, Batch Loss: 0.3019, Total Loss: 796.9934\n",
      "Epoch 9/10, Batch 3430/4401, Batch Loss: 0.0994, Total Loss: 799.9574\n",
      "Epoch 9/10, Batch 3440/4401, Batch Loss: 0.0393, Total Loss: 801.7639\n",
      "Epoch 9/10, Batch 3450/4401, Batch Loss: 0.3549, Total Loss: 803.4028\n",
      "Epoch 9/10, Batch 3460/4401, Batch Loss: 0.0600, Total Loss: 806.1422\n",
      "Epoch 9/10, Batch 3470/4401, Batch Loss: 0.0574, Total Loss: 808.5833\n",
      "Epoch 9/10, Batch 3480/4401, Batch Loss: 0.1022, Total Loss: 810.5323\n",
      "Epoch 9/10, Batch 3490/4401, Batch Loss: 0.2357, Total Loss: 813.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 3500/4401, Batch Loss: 0.0673, Total Loss: 815.0632\n",
      "Epoch 9/10, Batch 3510/4401, Batch Loss: 0.2112, Total Loss: 817.1694\n",
      "Epoch 9/10, Batch 3520/4401, Batch Loss: 0.2584, Total Loss: 819.5013\n",
      "Epoch 9/10, Batch 3530/4401, Batch Loss: 0.0512, Total Loss: 821.4305\n",
      "Epoch 9/10, Batch 3540/4401, Batch Loss: 0.2940, Total Loss: 824.3834\n",
      "Epoch 9/10, Batch 3550/4401, Batch Loss: 0.0727, Total Loss: 826.8433\n",
      "Epoch 9/10, Batch 3560/4401, Batch Loss: 0.1861, Total Loss: 828.7506\n",
      "Epoch 9/10, Batch 3570/4401, Batch Loss: 0.3066, Total Loss: 831.3508\n",
      "Epoch 9/10, Batch 3580/4401, Batch Loss: 0.6017, Total Loss: 833.7189\n",
      "Epoch 9/10, Batch 3590/4401, Batch Loss: 0.5515, Total Loss: 837.4603\n",
      "Epoch 9/10, Batch 3600/4401, Batch Loss: 0.2366, Total Loss: 840.3428\n",
      "Epoch 9/10, Batch 3610/4401, Batch Loss: 0.3771, Total Loss: 842.2323\n",
      "Epoch 9/10, Batch 3620/4401, Batch Loss: 0.2635, Total Loss: 844.2911\n",
      "Epoch 9/10, Batch 3630/4401, Batch Loss: 0.0566, Total Loss: 846.8643\n",
      "Epoch 9/10, Batch 3640/4401, Batch Loss: 0.0431, Total Loss: 849.3125\n",
      "Epoch 9/10, Batch 3650/4401, Batch Loss: 0.3288, Total Loss: 851.0389\n",
      "Epoch 9/10, Batch 3660/4401, Batch Loss: 0.1631, Total Loss: 853.6589\n",
      "Epoch 9/10, Batch 3670/4401, Batch Loss: 0.0406, Total Loss: 856.5716\n",
      "Epoch 9/10, Batch 3680/4401, Batch Loss: 0.2799, Total Loss: 859.6145\n",
      "Epoch 9/10, Batch 3690/4401, Batch Loss: 0.2004, Total Loss: 861.9849\n",
      "Epoch 9/10, Batch 3700/4401, Batch Loss: 0.1848, Total Loss: 864.4825\n",
      "Epoch 9/10, Batch 3710/4401, Batch Loss: 0.1527, Total Loss: 865.9762\n",
      "Epoch 9/10, Batch 3720/4401, Batch Loss: 0.0062, Total Loss: 868.2305\n",
      "Epoch 9/10, Batch 3730/4401, Batch Loss: 0.1278, Total Loss: 870.4408\n",
      "Epoch 9/10, Batch 3740/4401, Batch Loss: 0.4372, Total Loss: 873.5453\n",
      "Epoch 9/10, Batch 3750/4401, Batch Loss: 0.1045, Total Loss: 875.7198\n",
      "Epoch 9/10, Batch 3760/4401, Batch Loss: 0.0012, Total Loss: 877.5485\n",
      "Epoch 9/10, Batch 3770/4401, Batch Loss: 0.6042, Total Loss: 879.5674\n",
      "Epoch 9/10, Batch 3780/4401, Batch Loss: 0.2201, Total Loss: 881.5034\n",
      "Epoch 9/10, Batch 3790/4401, Batch Loss: 0.0015, Total Loss: 883.5874\n",
      "Epoch 9/10, Batch 3800/4401, Batch Loss: 0.6385, Total Loss: 888.2577\n",
      "Epoch 9/10, Batch 3810/4401, Batch Loss: 0.1972, Total Loss: 890.5954\n",
      "Epoch 9/10, Batch 3820/4401, Batch Loss: 0.1271, Total Loss: 892.8201\n",
      "Epoch 9/10, Batch 3830/4401, Batch Loss: 0.1462, Total Loss: 894.7801\n",
      "Epoch 9/10, Batch 3840/4401, Batch Loss: 0.0578, Total Loss: 896.3567\n",
      "Epoch 9/10, Batch 3850/4401, Batch Loss: 0.3313, Total Loss: 898.6895\n",
      "Epoch 9/10, Batch 3860/4401, Batch Loss: 0.4013, Total Loss: 901.2756\n",
      "Epoch 9/10, Batch 3870/4401, Batch Loss: 0.2203, Total Loss: 904.3043\n",
      "Epoch 9/10, Batch 3880/4401, Batch Loss: 0.3221, Total Loss: 906.3467\n",
      "Epoch 9/10, Batch 3890/4401, Batch Loss: 0.3257, Total Loss: 909.0191\n",
      "Epoch 9/10, Batch 3900/4401, Batch Loss: 0.1022, Total Loss: 910.9043\n",
      "Epoch 9/10, Batch 3910/4401, Batch Loss: 0.2956, Total Loss: 913.5065\n",
      "Epoch 9/10, Batch 3920/4401, Batch Loss: 0.2809, Total Loss: 915.6036\n",
      "Epoch 9/10, Batch 3930/4401, Batch Loss: 0.1807, Total Loss: 917.7394\n",
      "Epoch 9/10, Batch 3940/4401, Batch Loss: 0.1371, Total Loss: 919.9701\n",
      "Epoch 9/10, Batch 3950/4401, Batch Loss: 0.2542, Total Loss: 922.8023\n",
      "Epoch 9/10, Batch 3960/4401, Batch Loss: 0.0560, Total Loss: 924.8049\n",
      "Epoch 9/10, Batch 3970/4401, Batch Loss: 0.2763, Total Loss: 927.0111\n",
      "Epoch 9/10, Batch 3980/4401, Batch Loss: 0.1603, Total Loss: 929.7579\n",
      "Epoch 9/10, Batch 3990/4401, Batch Loss: 0.5232, Total Loss: 931.7368\n",
      "Epoch 9/10, Batch 4000/4401, Batch Loss: 0.4336, Total Loss: 934.5687\n",
      "Epoch 9/10, Batch 4010/4401, Batch Loss: 0.2390, Total Loss: 936.1815\n",
      "Epoch 9/10, Batch 4020/4401, Batch Loss: 0.1175, Total Loss: 937.9383\n",
      "Epoch 9/10, Batch 4030/4401, Batch Loss: 0.1535, Total Loss: 941.3827\n",
      "Epoch 9/10, Batch 4040/4401, Batch Loss: 0.1998, Total Loss: 944.3710\n",
      "Epoch 9/10, Batch 4050/4401, Batch Loss: 0.1239, Total Loss: 946.5250\n",
      "Epoch 9/10, Batch 4060/4401, Batch Loss: 0.6855, Total Loss: 949.3224\n",
      "Epoch 9/10, Batch 4070/4401, Batch Loss: 0.0626, Total Loss: 951.8085\n",
      "Epoch 9/10, Batch 4080/4401, Batch Loss: 0.1985, Total Loss: 954.3798\n",
      "Epoch 9/10, Batch 4090/4401, Batch Loss: 0.0473, Total Loss: 958.1569\n",
      "Epoch 9/10, Batch 4100/4401, Batch Loss: 0.5669, Total Loss: 961.2815\n",
      "Epoch 9/10, Batch 4110/4401, Batch Loss: 0.2591, Total Loss: 963.4189\n",
      "Epoch 9/10, Batch 4120/4401, Batch Loss: 0.1154, Total Loss: 965.5092\n",
      "Epoch 9/10, Batch 4130/4401, Batch Loss: 0.1733, Total Loss: 968.3775\n",
      "Epoch 9/10, Batch 4140/4401, Batch Loss: 0.1625, Total Loss: 970.3522\n",
      "Epoch 9/10, Batch 4150/4401, Batch Loss: 0.2333, Total Loss: 972.6706\n",
      "Epoch 9/10, Batch 4160/4401, Batch Loss: 0.1780, Total Loss: 975.4796\n",
      "Epoch 9/10, Batch 4170/4401, Batch Loss: 0.3513, Total Loss: 977.8688\n",
      "Epoch 9/10, Batch 4180/4401, Batch Loss: 0.3855, Total Loss: 980.1140\n",
      "Epoch 9/10, Batch 4190/4401, Batch Loss: 0.6042, Total Loss: 982.7143\n",
      "Epoch 9/10, Batch 4200/4401, Batch Loss: 0.2866, Total Loss: 984.9171\n",
      "Epoch 9/10, Batch 4210/4401, Batch Loss: 0.0834, Total Loss: 986.7747\n",
      "Epoch 9/10, Batch 4220/4401, Batch Loss: 0.0998, Total Loss: 988.7420\n",
      "Epoch 9/10, Batch 4230/4401, Batch Loss: 0.2636, Total Loss: 990.7260\n",
      "Epoch 9/10, Batch 4240/4401, Batch Loss: 0.0369, Total Loss: 992.5012\n",
      "Epoch 9/10, Batch 4250/4401, Batch Loss: 0.2758, Total Loss: 995.2507\n",
      "Epoch 9/10, Batch 4260/4401, Batch Loss: 0.3655, Total Loss: 997.6960\n",
      "Epoch 9/10, Batch 4270/4401, Batch Loss: 0.5976, Total Loss: 1001.0481\n",
      "Epoch 9/10, Batch 4280/4401, Batch Loss: 0.3032, Total Loss: 1003.7015\n",
      "Epoch 9/10, Batch 4290/4401, Batch Loss: 0.2301, Total Loss: 1006.7243\n",
      "Epoch 9/10, Batch 4300/4401, Batch Loss: 0.1778, Total Loss: 1009.4532\n",
      "Epoch 9/10, Batch 4310/4401, Batch Loss: 0.2451, Total Loss: 1011.7009\n",
      "Epoch 9/10, Batch 4320/4401, Batch Loss: 0.2058, Total Loss: 1014.5770\n",
      "Epoch 9/10, Batch 4330/4401, Batch Loss: 1.1823, Total Loss: 1017.9984\n",
      "Epoch 9/10, Batch 4340/4401, Batch Loss: 0.1052, Total Loss: 1022.2788\n",
      "Epoch 9/10, Batch 4350/4401, Batch Loss: 0.2867, Total Loss: 1025.3710\n",
      "Epoch 9/10, Batch 4360/4401, Batch Loss: 0.2543, Total Loss: 1027.7461\n",
      "Epoch 9/10, Batch 4370/4401, Batch Loss: 0.3517, Total Loss: 1030.4813\n",
      "Epoch 9/10, Batch 4380/4401, Batch Loss: 0.3143, Total Loss: 1033.7612\n",
      "Epoch 9/10, Batch 4390/4401, Batch Loss: 0.2860, Total Loss: 1036.2984\n",
      "Epoch 9/10, Batch 4400/4401, Batch Loss: 0.4727, Total Loss: 1038.6333\n",
      "Epoch 9/10, Batch 4401/4401, Batch Loss: 0.0985, Total Loss: 1038.7319\n",
      "Epoch 9/10 completed. Total Loss: 1038.7319\n",
      "\n",
      "Epoch 10/10 running...\n",
      "cuda:0\n",
      "Epoch 10/10, Batch 10/4401, Batch Loss: 0.2247, Total Loss: 1.7736\n",
      "Epoch 10/10, Batch 20/4401, Batch Loss: 0.0967, Total Loss: 3.7761\n",
      "Epoch 10/10, Batch 30/4401, Batch Loss: 0.1448, Total Loss: 5.9591\n",
      "Epoch 10/10, Batch 40/4401, Batch Loss: 0.3023, Total Loss: 7.7232\n",
      "Epoch 10/10, Batch 50/4401, Batch Loss: 0.0484, Total Loss: 10.0839\n",
      "Epoch 10/10, Batch 60/4401, Batch Loss: 0.2330, Total Loss: 12.8184\n",
      "Epoch 10/10, Batch 70/4401, Batch Loss: 0.2372, Total Loss: 14.3665\n",
      "Epoch 10/10, Batch 80/4401, Batch Loss: 0.0457, Total Loss: 16.4636\n",
      "Epoch 10/10, Batch 90/4401, Batch Loss: 0.1882, Total Loss: 18.8451\n",
      "Epoch 10/10, Batch 100/4401, Batch Loss: 0.2162, Total Loss: 21.4816\n",
      "Epoch 10/10, Batch 110/4401, Batch Loss: 0.2224, Total Loss: 24.5044\n",
      "Epoch 10/10, Batch 120/4401, Batch Loss: 0.2150, Total Loss: 26.9102\n",
      "Epoch 10/10, Batch 130/4401, Batch Loss: 0.2590, Total Loss: 28.9855\n",
      "Epoch 10/10, Batch 140/4401, Batch Loss: 0.1824, Total Loss: 31.2297\n",
      "Epoch 10/10, Batch 150/4401, Batch Loss: 0.3476, Total Loss: 33.4989\n",
      "Epoch 10/10, Batch 160/4401, Batch Loss: 0.0010, Total Loss: 35.5554\n",
      "Epoch 10/10, Batch 170/4401, Batch Loss: 0.4158, Total Loss: 37.4480\n",
      "Epoch 10/10, Batch 180/4401, Batch Loss: 0.5931, Total Loss: 40.0290\n",
      "Epoch 10/10, Batch 190/4401, Batch Loss: 0.3539, Total Loss: 42.3891\n",
      "Epoch 10/10, Batch 200/4401, Batch Loss: 0.1911, Total Loss: 44.9916\n",
      "Epoch 10/10, Batch 210/4401, Batch Loss: 0.1315, Total Loss: 47.3177\n",
      "Epoch 10/10, Batch 220/4401, Batch Loss: 0.1561, Total Loss: 49.2025\n",
      "Epoch 10/10, Batch 230/4401, Batch Loss: 0.2862, Total Loss: 51.6547\n",
      "Epoch 10/10, Batch 240/4401, Batch Loss: 0.5076, Total Loss: 54.1144\n",
      "Epoch 10/10, Batch 250/4401, Batch Loss: 0.2606, Total Loss: 56.5379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 260/4401, Batch Loss: 0.1653, Total Loss: 59.1267\n",
      "Epoch 10/10, Batch 270/4401, Batch Loss: 0.1195, Total Loss: 60.7099\n",
      "Epoch 10/10, Batch 280/4401, Batch Loss: 0.1801, Total Loss: 62.6622\n",
      "Epoch 10/10, Batch 290/4401, Batch Loss: 0.1021, Total Loss: 64.7747\n",
      "Epoch 10/10, Batch 300/4401, Batch Loss: 0.2502, Total Loss: 67.2597\n",
      "Epoch 10/10, Batch 310/4401, Batch Loss: 0.1070, Total Loss: 69.5061\n",
      "Epoch 10/10, Batch 320/4401, Batch Loss: 0.1092, Total Loss: 71.1709\n",
      "Epoch 10/10, Batch 330/4401, Batch Loss: 0.4047, Total Loss: 73.7520\n",
      "Epoch 10/10, Batch 340/4401, Batch Loss: 0.4289, Total Loss: 76.4354\n",
      "Epoch 10/10, Batch 350/4401, Batch Loss: 0.0591, Total Loss: 78.5963\n",
      "Epoch 10/10, Batch 360/4401, Batch Loss: 0.3055, Total Loss: 80.1864\n",
      "Epoch 10/10, Batch 370/4401, Batch Loss: 0.2090, Total Loss: 82.4856\n",
      "Epoch 10/10, Batch 380/4401, Batch Loss: 0.2227, Total Loss: 84.1772\n",
      "Epoch 10/10, Batch 390/4401, Batch Loss: 0.4424, Total Loss: 86.6151\n",
      "Epoch 10/10, Batch 400/4401, Batch Loss: 0.0557, Total Loss: 88.7093\n",
      "Epoch 10/10, Batch 410/4401, Batch Loss: 0.2431, Total Loss: 91.1070\n",
      "Epoch 10/10, Batch 420/4401, Batch Loss: 0.0491, Total Loss: 93.2530\n",
      "Epoch 10/10, Batch 430/4401, Batch Loss: 0.0926, Total Loss: 96.2925\n",
      "Epoch 10/10, Batch 440/4401, Batch Loss: 0.2374, Total Loss: 98.5067\n",
      "Epoch 10/10, Batch 450/4401, Batch Loss: 0.0009, Total Loss: 100.6076\n",
      "Epoch 10/10, Batch 460/4401, Batch Loss: 0.5270, Total Loss: 103.4597\n",
      "Epoch 10/10, Batch 470/4401, Batch Loss: 0.2834, Total Loss: 106.5222\n",
      "Epoch 10/10, Batch 480/4401, Batch Loss: 0.3713, Total Loss: 108.7002\n",
      "Epoch 10/10, Batch 490/4401, Batch Loss: 0.0757, Total Loss: 111.0237\n",
      "Epoch 10/10, Batch 500/4401, Batch Loss: 0.1464, Total Loss: 113.6345\n",
      "Epoch 10/10, Batch 510/4401, Batch Loss: 0.1103, Total Loss: 115.8578\n",
      "Epoch 10/10, Batch 520/4401, Batch Loss: 0.3205, Total Loss: 117.4142\n",
      "Epoch 10/10, Batch 530/4401, Batch Loss: 0.0931, Total Loss: 119.4115\n",
      "Epoch 10/10, Batch 540/4401, Batch Loss: 0.1804, Total Loss: 121.9294\n",
      "Epoch 10/10, Batch 550/4401, Batch Loss: 0.2217, Total Loss: 123.7823\n",
      "Epoch 10/10, Batch 560/4401, Batch Loss: 0.2651, Total Loss: 125.7353\n",
      "Epoch 10/10, Batch 570/4401, Batch Loss: 0.2186, Total Loss: 128.1792\n",
      "Epoch 10/10, Batch 580/4401, Batch Loss: 0.8562, Total Loss: 132.2054\n",
      "Epoch 10/10, Batch 590/4401, Batch Loss: 0.1762, Total Loss: 134.4477\n",
      "Epoch 10/10, Batch 600/4401, Batch Loss: 0.3797, Total Loss: 137.1782\n",
      "Epoch 10/10, Batch 610/4401, Batch Loss: 0.2804, Total Loss: 139.8982\n",
      "Epoch 10/10, Batch 620/4401, Batch Loss: 0.2542, Total Loss: 142.0415\n",
      "Epoch 10/10, Batch 630/4401, Batch Loss: 0.1892, Total Loss: 144.0959\n",
      "Epoch 10/10, Batch 640/4401, Batch Loss: 0.1076, Total Loss: 146.5849\n",
      "Epoch 10/10, Batch 650/4401, Batch Loss: 0.4406, Total Loss: 150.0175\n",
      "Epoch 10/10, Batch 660/4401, Batch Loss: 0.1917, Total Loss: 152.7360\n",
      "Epoch 10/10, Batch 670/4401, Batch Loss: 0.0590, Total Loss: 155.4304\n",
      "Epoch 10/10, Batch 680/4401, Batch Loss: 0.0590, Total Loss: 157.2008\n",
      "Epoch 10/10, Batch 690/4401, Batch Loss: 0.0700, Total Loss: 159.8939\n",
      "Epoch 10/10, Batch 700/4401, Batch Loss: 0.1991, Total Loss: 162.3305\n",
      "Epoch 10/10, Batch 710/4401, Batch Loss: 0.0779, Total Loss: 164.1835\n",
      "Epoch 10/10, Batch 720/4401, Batch Loss: 0.2005, Total Loss: 166.2122\n",
      "Epoch 10/10, Batch 730/4401, Batch Loss: 0.1413, Total Loss: 168.2839\n",
      "Epoch 10/10, Batch 740/4401, Batch Loss: 0.4513, Total Loss: 170.2789\n",
      "Epoch 10/10, Batch 750/4401, Batch Loss: 0.1328, Total Loss: 172.0945\n",
      "Epoch 10/10, Batch 760/4401, Batch Loss: 0.1075, Total Loss: 173.9909\n",
      "Epoch 10/10, Batch 770/4401, Batch Loss: 0.0741, Total Loss: 175.8016\n",
      "Epoch 10/10, Batch 780/4401, Batch Loss: 0.0757, Total Loss: 178.0306\n",
      "Epoch 10/10, Batch 790/4401, Batch Loss: 0.0044, Total Loss: 180.1869\n",
      "Epoch 10/10, Batch 800/4401, Batch Loss: 0.2177, Total Loss: 182.7908\n",
      "Epoch 10/10, Batch 810/4401, Batch Loss: 0.1855, Total Loss: 185.4417\n",
      "Epoch 10/10, Batch 820/4401, Batch Loss: 0.1827, Total Loss: 187.7340\n",
      "Epoch 10/10, Batch 830/4401, Batch Loss: 0.0897, Total Loss: 189.8170\n",
      "Epoch 10/10, Batch 840/4401, Batch Loss: 0.0489, Total Loss: 191.9162\n",
      "Epoch 10/10, Batch 850/4401, Batch Loss: 0.2575, Total Loss: 193.7383\n",
      "Epoch 10/10, Batch 860/4401, Batch Loss: 0.1706, Total Loss: 196.5937\n",
      "Epoch 10/10, Batch 870/4401, Batch Loss: 0.3895, Total Loss: 199.1275\n",
      "Epoch 10/10, Batch 880/4401, Batch Loss: 0.0482, Total Loss: 200.6347\n",
      "Epoch 10/10, Batch 890/4401, Batch Loss: 0.1410, Total Loss: 203.7686\n",
      "Epoch 10/10, Batch 900/4401, Batch Loss: 0.4717, Total Loss: 205.7281\n",
      "Epoch 10/10, Batch 910/4401, Batch Loss: 0.0592, Total Loss: 207.6649\n",
      "Epoch 10/10, Batch 920/4401, Batch Loss: 0.2073, Total Loss: 209.6447\n",
      "Epoch 10/10, Batch 930/4401, Batch Loss: 0.0831, Total Loss: 211.3345\n",
      "Epoch 10/10, Batch 940/4401, Batch Loss: 0.1639, Total Loss: 212.8468\n",
      "Epoch 10/10, Batch 950/4401, Batch Loss: 0.3456, Total Loss: 215.2759\n",
      "Epoch 10/10, Batch 960/4401, Batch Loss: 0.0664, Total Loss: 216.8468\n",
      "Epoch 10/10, Batch 970/4401, Batch Loss: 0.0031, Total Loss: 219.0275\n",
      "Epoch 10/10, Batch 980/4401, Batch Loss: 0.0575, Total Loss: 222.0879\n",
      "Epoch 10/10, Batch 990/4401, Batch Loss: 0.3547, Total Loss: 224.8455\n",
      "Epoch 10/10, Batch 1000/4401, Batch Loss: 0.5803, Total Loss: 227.0015\n",
      "Epoch 10/10, Batch 1010/4401, Batch Loss: 0.2149, Total Loss: 229.3678\n",
      "Epoch 10/10, Batch 1020/4401, Batch Loss: 0.4086, Total Loss: 230.9504\n",
      "Epoch 10/10, Batch 1030/4401, Batch Loss: 0.3102, Total Loss: 233.2781\n",
      "Epoch 10/10, Batch 1040/4401, Batch Loss: 0.5556, Total Loss: 236.4049\n",
      "Epoch 10/10, Batch 1050/4401, Batch Loss: 0.0967, Total Loss: 238.9013\n",
      "Epoch 10/10, Batch 1060/4401, Batch Loss: 0.3905, Total Loss: 241.0010\n",
      "Epoch 10/10, Batch 1070/4401, Batch Loss: 0.1502, Total Loss: 242.5167\n",
      "Epoch 10/10, Batch 1080/4401, Batch Loss: 0.2208, Total Loss: 245.3045\n",
      "Epoch 10/10, Batch 1090/4401, Batch Loss: 0.2639, Total Loss: 248.4572\n",
      "Epoch 10/10, Batch 1100/4401, Batch Loss: 0.3701, Total Loss: 251.8242\n",
      "Epoch 10/10, Batch 1110/4401, Batch Loss: 0.1133, Total Loss: 253.1382\n",
      "Epoch 10/10, Batch 1120/4401, Batch Loss: 0.0950, Total Loss: 255.7950\n",
      "Epoch 10/10, Batch 1130/4401, Batch Loss: 0.2309, Total Loss: 257.8544\n",
      "Epoch 10/10, Batch 1140/4401, Batch Loss: 0.2786, Total Loss: 260.1884\n",
      "Epoch 10/10, Batch 1150/4401, Batch Loss: 0.1151, Total Loss: 263.2488\n",
      "Epoch 10/10, Batch 1160/4401, Batch Loss: 0.3025, Total Loss: 264.9202\n",
      "Epoch 10/10, Batch 1170/4401, Batch Loss: 0.1332, Total Loss: 267.1727\n",
      "Epoch 10/10, Batch 1180/4401, Batch Loss: 0.3071, Total Loss: 269.0480\n",
      "Epoch 10/10, Batch 1190/4401, Batch Loss: 0.1772, Total Loss: 271.4857\n",
      "Epoch 10/10, Batch 1200/4401, Batch Loss: 0.2075, Total Loss: 274.0918\n",
      "Epoch 10/10, Batch 1210/4401, Batch Loss: 0.3938, Total Loss: 276.1710\n",
      "Epoch 10/10, Batch 1220/4401, Batch Loss: 0.2002, Total Loss: 277.5938\n",
      "Epoch 10/10, Batch 1230/4401, Batch Loss: 0.2609, Total Loss: 280.5354\n",
      "Epoch 10/10, Batch 1240/4401, Batch Loss: 0.1062, Total Loss: 283.6974\n",
      "Epoch 10/10, Batch 1250/4401, Batch Loss: 0.2843, Total Loss: 286.6236\n",
      "Epoch 10/10, Batch 1260/4401, Batch Loss: 0.1664, Total Loss: 288.6757\n",
      "Epoch 10/10, Batch 1270/4401, Batch Loss: 0.0576, Total Loss: 291.3115\n",
      "Epoch 10/10, Batch 1280/4401, Batch Loss: 0.0612, Total Loss: 294.2723\n",
      "Epoch 10/10, Batch 1290/4401, Batch Loss: 0.4386, Total Loss: 297.4083\n",
      "Epoch 10/10, Batch 1300/4401, Batch Loss: 0.5899, Total Loss: 300.0234\n",
      "Epoch 10/10, Batch 1310/4401, Batch Loss: 0.1810, Total Loss: 302.4405\n",
      "Epoch 10/10, Batch 1320/4401, Batch Loss: 0.4751, Total Loss: 305.0740\n",
      "Epoch 10/10, Batch 1330/4401, Batch Loss: 0.0929, Total Loss: 306.5133\n",
      "Epoch 10/10, Batch 1340/4401, Batch Loss: 0.4695, Total Loss: 308.2301\n",
      "Epoch 10/10, Batch 1350/4401, Batch Loss: 0.2568, Total Loss: 309.9164\n",
      "Epoch 10/10, Batch 1360/4401, Batch Loss: 0.3570, Total Loss: 312.0117\n",
      "Epoch 10/10, Batch 1370/4401, Batch Loss: 0.3812, Total Loss: 314.7407\n",
      "Epoch 10/10, Batch 1380/4401, Batch Loss: 0.1311, Total Loss: 317.2936\n",
      "Epoch 10/10, Batch 1390/4401, Batch Loss: 0.0780, Total Loss: 319.4034\n",
      "Epoch 10/10, Batch 1400/4401, Batch Loss: 0.3110, Total Loss: 321.6843\n",
      "Epoch 10/10, Batch 1410/4401, Batch Loss: 0.0468, Total Loss: 325.0544\n",
      "Epoch 10/10, Batch 1420/4401, Batch Loss: 0.1256, Total Loss: 327.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1430/4401, Batch Loss: 0.1792, Total Loss: 330.2415\n",
      "Epoch 10/10, Batch 1440/4401, Batch Loss: 0.1322, Total Loss: 332.1977\n",
      "Epoch 10/10, Batch 1450/4401, Batch Loss: 0.1025, Total Loss: 334.2768\n",
      "Epoch 10/10, Batch 1460/4401, Batch Loss: 0.1054, Total Loss: 336.0343\n",
      "Epoch 10/10, Batch 1470/4401, Batch Loss: 0.0821, Total Loss: 338.0347\n",
      "Epoch 10/10, Batch 1480/4401, Batch Loss: 0.2223, Total Loss: 339.3797\n",
      "Epoch 10/10, Batch 1490/4401, Batch Loss: 0.1148, Total Loss: 341.0700\n",
      "Epoch 10/10, Batch 1500/4401, Batch Loss: 0.0968, Total Loss: 344.6944\n",
      "Epoch 10/10, Batch 1510/4401, Batch Loss: 0.2343, Total Loss: 347.2680\n",
      "Epoch 10/10, Batch 1520/4401, Batch Loss: 0.2517, Total Loss: 349.6224\n",
      "Epoch 10/10, Batch 1530/4401, Batch Loss: 0.4280, Total Loss: 352.1408\n",
      "Epoch 10/10, Batch 1540/4401, Batch Loss: 0.2602, Total Loss: 354.6379\n",
      "Epoch 10/10, Batch 1550/4401, Batch Loss: 0.0801, Total Loss: 356.7597\n",
      "Epoch 10/10, Batch 1560/4401, Batch Loss: 0.0865, Total Loss: 359.4519\n",
      "Epoch 10/10, Batch 1570/4401, Batch Loss: 0.2433, Total Loss: 362.1711\n",
      "Epoch 10/10, Batch 1580/4401, Batch Loss: 0.1577, Total Loss: 364.3495\n",
      "Epoch 10/10, Batch 1590/4401, Batch Loss: 0.1994, Total Loss: 365.9329\n",
      "Epoch 10/10, Batch 1600/4401, Batch Loss: 0.1165, Total Loss: 367.6808\n",
      "Epoch 10/10, Batch 1610/4401, Batch Loss: 0.2052, Total Loss: 370.2458\n",
      "Epoch 10/10, Batch 1620/4401, Batch Loss: 0.3208, Total Loss: 371.9782\n",
      "Epoch 10/10, Batch 1630/4401, Batch Loss: 0.2333, Total Loss: 373.4366\n",
      "Epoch 10/10, Batch 1640/4401, Batch Loss: 0.3144, Total Loss: 375.7972\n",
      "Epoch 10/10, Batch 1650/4401, Batch Loss: 0.1645, Total Loss: 378.1045\n",
      "Epoch 10/10, Batch 1660/4401, Batch Loss: 0.0638, Total Loss: 380.6177\n",
      "Epoch 10/10, Batch 1670/4401, Batch Loss: 0.3372, Total Loss: 383.5070\n",
      "Epoch 10/10, Batch 1680/4401, Batch Loss: 0.1311, Total Loss: 385.8662\n",
      "Epoch 10/10, Batch 1690/4401, Batch Loss: 0.2863, Total Loss: 388.5016\n",
      "Epoch 10/10, Batch 1700/4401, Batch Loss: 0.0081, Total Loss: 390.3302\n",
      "Epoch 10/10, Batch 1710/4401, Batch Loss: 0.1395, Total Loss: 393.3059\n",
      "Epoch 10/10, Batch 1720/4401, Batch Loss: 0.3556, Total Loss: 395.5593\n",
      "Epoch 10/10, Batch 1730/4401, Batch Loss: 0.1550, Total Loss: 397.6219\n",
      "Epoch 10/10, Batch 1740/4401, Batch Loss: 0.2557, Total Loss: 400.4469\n",
      "Epoch 10/10, Batch 1750/4401, Batch Loss: 0.1050, Total Loss: 402.3591\n",
      "Epoch 10/10, Batch 1760/4401, Batch Loss: 0.2167, Total Loss: 403.9702\n",
      "Epoch 10/10, Batch 1770/4401, Batch Loss: 0.1392, Total Loss: 405.1359\n",
      "Epoch 10/10, Batch 1780/4401, Batch Loss: 0.1724, Total Loss: 407.0450\n",
      "Epoch 10/10, Batch 1790/4401, Batch Loss: 0.2092, Total Loss: 409.7299\n",
      "Epoch 10/10, Batch 1800/4401, Batch Loss: 0.0979, Total Loss: 411.8067\n",
      "Epoch 10/10, Batch 1810/4401, Batch Loss: 0.3172, Total Loss: 413.9175\n",
      "Epoch 10/10, Batch 1820/4401, Batch Loss: 0.2955, Total Loss: 415.9995\n",
      "Epoch 10/10, Batch 1830/4401, Batch Loss: 0.0379, Total Loss: 419.1155\n",
      "Epoch 10/10, Batch 1840/4401, Batch Loss: 0.2033, Total Loss: 421.0778\n",
      "Epoch 10/10, Batch 1850/4401, Batch Loss: 0.0014, Total Loss: 422.8001\n",
      "Epoch 10/10, Batch 1860/4401, Batch Loss: 0.3280, Total Loss: 424.8105\n",
      "Epoch 10/10, Batch 1870/4401, Batch Loss: 0.4178, Total Loss: 426.9020\n",
      "Epoch 10/10, Batch 1880/4401, Batch Loss: 0.5191, Total Loss: 429.3841\n",
      "Epoch 10/10, Batch 1890/4401, Batch Loss: 0.1120, Total Loss: 431.0718\n",
      "Epoch 10/10, Batch 1900/4401, Batch Loss: 0.2077, Total Loss: 433.3400\n",
      "Epoch 10/10, Batch 1910/4401, Batch Loss: 0.0009, Total Loss: 435.1520\n",
      "Epoch 10/10, Batch 1920/4401, Batch Loss: 0.2580, Total Loss: 437.8417\n",
      "Epoch 10/10, Batch 1930/4401, Batch Loss: 0.3044, Total Loss: 440.1352\n",
      "Epoch 10/10, Batch 1940/4401, Batch Loss: 0.0688, Total Loss: 442.7459\n",
      "Epoch 10/10, Batch 1950/4401, Batch Loss: 0.2453, Total Loss: 444.7386\n",
      "Epoch 10/10, Batch 1960/4401, Batch Loss: 0.2848, Total Loss: 447.2427\n",
      "Epoch 10/10, Batch 1970/4401, Batch Loss: 0.4909, Total Loss: 450.5214\n",
      "Epoch 10/10, Batch 1980/4401, Batch Loss: 0.0023, Total Loss: 453.8239\n",
      "Epoch 10/10, Batch 1990/4401, Batch Loss: 0.3974, Total Loss: 457.3078\n",
      "Epoch 10/10, Batch 2000/4401, Batch Loss: 0.1167, Total Loss: 459.7894\n",
      "Epoch 10/10, Batch 2010/4401, Batch Loss: 0.3168, Total Loss: 461.8770\n",
      "Epoch 10/10, Batch 2020/4401, Batch Loss: 0.1418, Total Loss: 465.1199\n",
      "Epoch 10/10, Batch 2030/4401, Batch Loss: 0.1471, Total Loss: 467.7054\n",
      "Epoch 10/10, Batch 2040/4401, Batch Loss: 0.3227, Total Loss: 469.8714\n",
      "Epoch 10/10, Batch 2050/4401, Batch Loss: 0.1254, Total Loss: 472.2931\n",
      "Epoch 10/10, Batch 2060/4401, Batch Loss: 0.0743, Total Loss: 474.4765\n",
      "Epoch 10/10, Batch 2070/4401, Batch Loss: 0.2390, Total Loss: 476.9399\n",
      "Epoch 10/10, Batch 2080/4401, Batch Loss: 0.3745, Total Loss: 478.7108\n",
      "Epoch 10/10, Batch 2090/4401, Batch Loss: 0.0517, Total Loss: 480.4385\n",
      "Epoch 10/10, Batch 2100/4401, Batch Loss: 0.3282, Total Loss: 482.9975\n",
      "Epoch 10/10, Batch 2110/4401, Batch Loss: 0.1499, Total Loss: 485.4045\n",
      "Epoch 10/10, Batch 2120/4401, Batch Loss: 0.2423, Total Loss: 488.0406\n",
      "Epoch 10/10, Batch 2130/4401, Batch Loss: 0.1222, Total Loss: 490.0262\n",
      "Epoch 10/10, Batch 2140/4401, Batch Loss: 0.0419, Total Loss: 491.7497\n",
      "Epoch 10/10, Batch 2150/4401, Batch Loss: 0.0693, Total Loss: 493.9847\n",
      "Epoch 10/10, Batch 2160/4401, Batch Loss: 0.1693, Total Loss: 497.4936\n",
      "Epoch 10/10, Batch 2170/4401, Batch Loss: 0.2490, Total Loss: 499.6378\n",
      "Epoch 10/10, Batch 2180/4401, Batch Loss: 0.0021, Total Loss: 501.2926\n",
      "Epoch 10/10, Batch 2190/4401, Batch Loss: 0.0620, Total Loss: 503.4259\n",
      "Epoch 10/10, Batch 2200/4401, Batch Loss: 0.1379, Total Loss: 505.0017\n",
      "Epoch 10/10, Batch 2210/4401, Batch Loss: 0.0914, Total Loss: 507.1799\n",
      "Epoch 10/10, Batch 2220/4401, Batch Loss: 0.0564, Total Loss: 509.1328\n",
      "Epoch 10/10, Batch 2230/4401, Batch Loss: 0.1550, Total Loss: 511.3402\n",
      "Epoch 10/10, Batch 2240/4401, Batch Loss: 0.3631, Total Loss: 513.4605\n",
      "Epoch 10/10, Batch 2250/4401, Batch Loss: 0.4150, Total Loss: 516.4464\n",
      "Epoch 10/10, Batch 2260/4401, Batch Loss: 0.3329, Total Loss: 519.2007\n",
      "Epoch 10/10, Batch 2270/4401, Batch Loss: 0.4066, Total Loss: 522.4440\n",
      "Epoch 10/10, Batch 2280/4401, Batch Loss: 0.0751, Total Loss: 525.2907\n",
      "Epoch 10/10, Batch 2290/4401, Batch Loss: 0.1717, Total Loss: 527.9499\n",
      "Epoch 10/10, Batch 2300/4401, Batch Loss: 0.0651, Total Loss: 530.1094\n",
      "Epoch 10/10, Batch 2310/4401, Batch Loss: 0.1644, Total Loss: 532.9698\n",
      "Epoch 10/10, Batch 2320/4401, Batch Loss: 0.2599, Total Loss: 536.3279\n",
      "Epoch 10/10, Batch 2330/4401, Batch Loss: 0.2010, Total Loss: 538.5542\n",
      "Epoch 10/10, Batch 2340/4401, Batch Loss: 0.4355, Total Loss: 541.4450\n",
      "Epoch 10/10, Batch 2350/4401, Batch Loss: 0.3118, Total Loss: 543.9377\n",
      "Epoch 10/10, Batch 2360/4401, Batch Loss: 0.2850, Total Loss: 546.9424\n",
      "Epoch 10/10, Batch 2370/4401, Batch Loss: 0.1320, Total Loss: 549.2855\n",
      "Epoch 10/10, Batch 2380/4401, Batch Loss: 0.2323, Total Loss: 551.6809\n",
      "Epoch 10/10, Batch 2390/4401, Batch Loss: 0.1908, Total Loss: 555.0996\n",
      "Epoch 10/10, Batch 2400/4401, Batch Loss: 0.2407, Total Loss: 557.6831\n",
      "Epoch 10/10, Batch 2410/4401, Batch Loss: 0.1594, Total Loss: 560.1587\n",
      "Epoch 10/10, Batch 2420/4401, Batch Loss: 0.1120, Total Loss: 562.3757\n",
      "Epoch 10/10, Batch 2430/4401, Batch Loss: 0.2412, Total Loss: 565.2351\n",
      "Epoch 10/10, Batch 2440/4401, Batch Loss: 0.1426, Total Loss: 567.6950\n",
      "Epoch 10/10, Batch 2450/4401, Batch Loss: 0.2573, Total Loss: 570.4352\n",
      "Epoch 10/10, Batch 2460/4401, Batch Loss: 0.3181, Total Loss: 573.1363\n",
      "Epoch 10/10, Batch 2470/4401, Batch Loss: 0.0005, Total Loss: 575.0346\n",
      "Epoch 10/10, Batch 2480/4401, Batch Loss: 0.1682, Total Loss: 577.2028\n",
      "Epoch 10/10, Batch 2490/4401, Batch Loss: 0.2021, Total Loss: 578.9913\n",
      "Epoch 10/10, Batch 2500/4401, Batch Loss: 0.2942, Total Loss: 580.9802\n",
      "Epoch 10/10, Batch 2510/4401, Batch Loss: 0.1744, Total Loss: 583.6876\n",
      "Epoch 10/10, Batch 2520/4401, Batch Loss: 0.1537, Total Loss: 585.8090\n",
      "Epoch 10/10, Batch 2530/4401, Batch Loss: 0.3486, Total Loss: 589.2108\n",
      "Epoch 10/10, Batch 2540/4401, Batch Loss: 0.1502, Total Loss: 591.6209\n",
      "Epoch 10/10, Batch 2550/4401, Batch Loss: 0.5233, Total Loss: 594.2588\n",
      "Epoch 10/10, Batch 2560/4401, Batch Loss: 0.2217, Total Loss: 596.7672\n",
      "Epoch 10/10, Batch 2570/4401, Batch Loss: 0.1233, Total Loss: 599.2217\n",
      "Epoch 10/10, Batch 2580/4401, Batch Loss: 0.2021, Total Loss: 600.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 2590/4401, Batch Loss: 0.1516, Total Loss: 603.1671\n",
      "Epoch 10/10, Batch 2600/4401, Batch Loss: 0.3548, Total Loss: 605.5223\n",
      "Epoch 10/10, Batch 2610/4401, Batch Loss: 0.1600, Total Loss: 607.9139\n",
      "Epoch 10/10, Batch 2620/4401, Batch Loss: 0.3528, Total Loss: 610.0436\n",
      "Epoch 10/10, Batch 2630/4401, Batch Loss: 0.4556, Total Loss: 612.5338\n",
      "Epoch 10/10, Batch 2640/4401, Batch Loss: 0.1822, Total Loss: 614.6340\n",
      "Epoch 10/10, Batch 2650/4401, Batch Loss: 0.1662, Total Loss: 616.9624\n",
      "Epoch 10/10, Batch 2660/4401, Batch Loss: 0.0549, Total Loss: 619.1421\n",
      "Epoch 10/10, Batch 2670/4401, Batch Loss: 0.0730, Total Loss: 621.4479\n",
      "Epoch 10/10, Batch 2680/4401, Batch Loss: 0.2094, Total Loss: 623.4793\n",
      "Epoch 10/10, Batch 2690/4401, Batch Loss: 0.4473, Total Loss: 626.0532\n",
      "Epoch 10/10, Batch 2700/4401, Batch Loss: 0.3214, Total Loss: 627.8452\n",
      "Epoch 10/10, Batch 2710/4401, Batch Loss: 0.2046, Total Loss: 630.1609\n",
      "Epoch 10/10, Batch 2720/4401, Batch Loss: 0.1531, Total Loss: 632.7928\n",
      "Epoch 10/10, Batch 2730/4401, Batch Loss: 0.0023, Total Loss: 634.6792\n",
      "Epoch 10/10, Batch 2740/4401, Batch Loss: 0.3548, Total Loss: 636.8238\n",
      "Epoch 10/10, Batch 2750/4401, Batch Loss: 0.5237, Total Loss: 639.9215\n",
      "Epoch 10/10, Batch 2760/4401, Batch Loss: 0.1812, Total Loss: 642.3459\n",
      "Epoch 10/10, Batch 2770/4401, Batch Loss: 0.3539, Total Loss: 644.8654\n",
      "Epoch 10/10, Batch 2780/4401, Batch Loss: 0.1474, Total Loss: 647.8845\n",
      "Epoch 10/10, Batch 2790/4401, Batch Loss: 0.1776, Total Loss: 650.1226\n",
      "Epoch 10/10, Batch 2800/4401, Batch Loss: 0.1750, Total Loss: 652.4365\n",
      "Epoch 10/10, Batch 2810/4401, Batch Loss: 0.0128, Total Loss: 654.1582\n",
      "Epoch 10/10, Batch 2820/4401, Batch Loss: 0.1044, Total Loss: 655.5600\n",
      "Epoch 10/10, Batch 2830/4401, Batch Loss: 0.1191, Total Loss: 657.8319\n",
      "Epoch 10/10, Batch 2840/4401, Batch Loss: 0.0515, Total Loss: 659.3030\n",
      "Epoch 10/10, Batch 2850/4401, Batch Loss: 0.9022, Total Loss: 663.1669\n",
      "Epoch 10/10, Batch 2860/4401, Batch Loss: 0.0691, Total Loss: 666.7317\n",
      "Epoch 10/10, Batch 2870/4401, Batch Loss: 0.2021, Total Loss: 669.3545\n",
      "Epoch 10/10, Batch 2880/4401, Batch Loss: 0.2487, Total Loss: 672.0532\n",
      "Epoch 10/10, Batch 2890/4401, Batch Loss: 0.0015, Total Loss: 674.9926\n",
      "Epoch 10/10, Batch 2900/4401, Batch Loss: 0.0646, Total Loss: 677.7368\n",
      "Epoch 10/10, Batch 2910/4401, Batch Loss: 0.3666, Total Loss: 679.7938\n",
      "Epoch 10/10, Batch 2920/4401, Batch Loss: 0.1083, Total Loss: 681.6794\n",
      "Epoch 10/10, Batch 2930/4401, Batch Loss: 0.5256, Total Loss: 684.1681\n",
      "Epoch 10/10, Batch 2940/4401, Batch Loss: 0.3436, Total Loss: 686.0321\n",
      "Epoch 10/10, Batch 2950/4401, Batch Loss: 0.4089, Total Loss: 688.6629\n",
      "Epoch 10/10, Batch 2960/4401, Batch Loss: 0.2949, Total Loss: 691.3881\n",
      "Epoch 10/10, Batch 2970/4401, Batch Loss: 0.1316, Total Loss: 693.5790\n",
      "Epoch 10/10, Batch 2980/4401, Batch Loss: 0.1475, Total Loss: 695.8391\n",
      "Epoch 10/10, Batch 2990/4401, Batch Loss: 0.1748, Total Loss: 698.2967\n",
      "Epoch 10/10, Batch 3000/4401, Batch Loss: 0.2282, Total Loss: 701.1353\n",
      "Epoch 10/10, Batch 3010/4401, Batch Loss: 0.1709, Total Loss: 703.0786\n",
      "Epoch 10/10, Batch 3020/4401, Batch Loss: 0.1277, Total Loss: 706.4985\n",
      "Epoch 10/10, Batch 3030/4401, Batch Loss: 0.0604, Total Loss: 709.0363\n",
      "Epoch 10/10, Batch 3040/4401, Batch Loss: 0.1593, Total Loss: 711.2380\n",
      "Epoch 10/10, Batch 3050/4401, Batch Loss: 0.4584, Total Loss: 713.4926\n",
      "Epoch 10/10, Batch 3060/4401, Batch Loss: 0.3062, Total Loss: 716.6834\n",
      "Epoch 10/10, Batch 3070/4401, Batch Loss: 0.0438, Total Loss: 719.4529\n",
      "Epoch 10/10, Batch 3080/4401, Batch Loss: 0.1736, Total Loss: 721.7225\n",
      "Epoch 10/10, Batch 3090/4401, Batch Loss: 0.1693, Total Loss: 724.2523\n",
      "Epoch 10/10, Batch 3100/4401, Batch Loss: 0.0537, Total Loss: 726.5422\n",
      "Epoch 10/10, Batch 3110/4401, Batch Loss: 0.3449, Total Loss: 728.8041\n",
      "Epoch 10/10, Batch 3120/4401, Batch Loss: 0.0823, Total Loss: 730.9072\n",
      "Epoch 10/10, Batch 3130/4401, Batch Loss: 0.1843, Total Loss: 732.4973\n",
      "Epoch 10/10, Batch 3140/4401, Batch Loss: 0.1047, Total Loss: 734.7469\n",
      "Epoch 10/10, Batch 3150/4401, Batch Loss: 0.3787, Total Loss: 737.7309\n",
      "Epoch 10/10, Batch 3160/4401, Batch Loss: 0.1921, Total Loss: 739.9772\n",
      "Epoch 10/10, Batch 3170/4401, Batch Loss: 0.5279, Total Loss: 742.3490\n",
      "Epoch 10/10, Batch 3180/4401, Batch Loss: 0.3577, Total Loss: 744.5944\n",
      "Epoch 10/10, Batch 3190/4401, Batch Loss: 0.2591, Total Loss: 746.1227\n",
      "Epoch 10/10, Batch 3200/4401, Batch Loss: 0.4274, Total Loss: 748.1076\n",
      "Epoch 10/10, Batch 3210/4401, Batch Loss: 0.3920, Total Loss: 750.7179\n",
      "Epoch 10/10, Batch 3220/4401, Batch Loss: 0.1365, Total Loss: 752.8566\n",
      "Epoch 10/10, Batch 3230/4401, Batch Loss: 0.2485, Total Loss: 755.1749\n",
      "Epoch 10/10, Batch 3240/4401, Batch Loss: 0.0602, Total Loss: 757.9954\n",
      "Epoch 10/10, Batch 3250/4401, Batch Loss: 0.0655, Total Loss: 760.6088\n",
      "Epoch 10/10, Batch 3260/4401, Batch Loss: 0.1805, Total Loss: 762.4379\n",
      "Epoch 10/10, Batch 3270/4401, Batch Loss: 0.1938, Total Loss: 764.1258\n",
      "Epoch 10/10, Batch 3280/4401, Batch Loss: 0.1607, Total Loss: 766.3015\n",
      "Epoch 10/10, Batch 3290/4401, Batch Loss: 0.2534, Total Loss: 768.7934\n",
      "Epoch 10/10, Batch 3300/4401, Batch Loss: 0.3243, Total Loss: 771.5432\n",
      "Epoch 10/10, Batch 3310/4401, Batch Loss: 0.2648, Total Loss: 773.2859\n",
      "Epoch 10/10, Batch 3320/4401, Batch Loss: 0.0369, Total Loss: 775.5519\n",
      "Epoch 10/10, Batch 3330/4401, Batch Loss: 0.2269, Total Loss: 778.4339\n",
      "Epoch 10/10, Batch 3340/4401, Batch Loss: 0.2673, Total Loss: 780.9144\n",
      "Epoch 10/10, Batch 3350/4401, Batch Loss: 0.2869, Total Loss: 783.4277\n",
      "Epoch 10/10, Batch 3360/4401, Batch Loss: 0.2572, Total Loss: 786.0711\n",
      "Epoch 10/10, Batch 3370/4401, Batch Loss: 0.1304, Total Loss: 788.5092\n",
      "Epoch 10/10, Batch 3380/4401, Batch Loss: 0.3379, Total Loss: 790.4752\n",
      "Epoch 10/10, Batch 3390/4401, Batch Loss: 0.1210, Total Loss: 792.0819\n",
      "Epoch 10/10, Batch 3400/4401, Batch Loss: 0.4613, Total Loss: 794.2713\n",
      "Epoch 10/10, Batch 3410/4401, Batch Loss: 0.2291, Total Loss: 796.7599\n",
      "Epoch 10/10, Batch 3420/4401, Batch Loss: 0.2556, Total Loss: 799.5119\n",
      "Epoch 10/10, Batch 3430/4401, Batch Loss: 0.4145, Total Loss: 801.2508\n",
      "Epoch 10/10, Batch 3440/4401, Batch Loss: 0.1049, Total Loss: 803.9786\n",
      "Epoch 10/10, Batch 3450/4401, Batch Loss: 0.2119, Total Loss: 806.0961\n",
      "Epoch 10/10, Batch 3460/4401, Batch Loss: 0.3020, Total Loss: 808.8060\n",
      "Epoch 10/10, Batch 3470/4401, Batch Loss: 0.1491, Total Loss: 811.4071\n",
      "Epoch 10/10, Batch 3480/4401, Batch Loss: 0.2588, Total Loss: 813.3992\n",
      "Epoch 10/10, Batch 3490/4401, Batch Loss: 0.0607, Total Loss: 815.6244\n",
      "Epoch 10/10, Batch 3500/4401, Batch Loss: 0.1140, Total Loss: 818.0591\n",
      "Epoch 10/10, Batch 3510/4401, Batch Loss: 0.1939, Total Loss: 820.0333\n",
      "Epoch 10/10, Batch 3520/4401, Batch Loss: 0.1360, Total Loss: 822.5568\n",
      "Epoch 10/10, Batch 3530/4401, Batch Loss: 0.3216, Total Loss: 825.0599\n",
      "Epoch 10/10, Batch 3540/4401, Batch Loss: 0.1140, Total Loss: 826.7196\n",
      "Epoch 10/10, Batch 3550/4401, Batch Loss: 0.4089, Total Loss: 829.7617\n",
      "Epoch 10/10, Batch 3560/4401, Batch Loss: 0.1348, Total Loss: 831.4341\n",
      "Epoch 10/10, Batch 3570/4401, Batch Loss: 0.1597, Total Loss: 833.8758\n",
      "Epoch 10/10, Batch 3580/4401, Batch Loss: 0.2485, Total Loss: 836.7224\n",
      "Epoch 10/10, Batch 3590/4401, Batch Loss: 0.4060, Total Loss: 839.0405\n",
      "Epoch 10/10, Batch 3600/4401, Batch Loss: 0.2383, Total Loss: 842.0555\n",
      "Epoch 10/10, Batch 3610/4401, Batch Loss: 1.0065, Total Loss: 844.8963\n",
      "Epoch 10/10, Batch 3620/4401, Batch Loss: 0.0908, Total Loss: 846.5040\n",
      "Epoch 10/10, Batch 3630/4401, Batch Loss: 0.2384, Total Loss: 848.5918\n",
      "Epoch 10/10, Batch 3640/4401, Batch Loss: 0.0504, Total Loss: 850.9586\n",
      "Epoch 10/10, Batch 3650/4401, Batch Loss: 0.1054, Total Loss: 853.1747\n",
      "Epoch 10/10, Batch 3660/4401, Batch Loss: 0.2196, Total Loss: 854.9082\n",
      "Epoch 10/10, Batch 3670/4401, Batch Loss: 0.0034, Total Loss: 857.9522\n",
      "Epoch 10/10, Batch 3680/4401, Batch Loss: 0.3296, Total Loss: 860.7050\n",
      "Epoch 10/10, Batch 3690/4401, Batch Loss: 0.2166, Total Loss: 862.9104\n",
      "Epoch 10/10, Batch 3700/4401, Batch Loss: 0.3978, Total Loss: 866.7190\n",
      "Epoch 10/10, Batch 3710/4401, Batch Loss: 0.1067, Total Loss: 869.4552\n",
      "Epoch 10/10, Batch 3720/4401, Batch Loss: 0.0492, Total Loss: 870.9753\n",
      "Epoch 10/10, Batch 3730/4401, Batch Loss: 0.1662, Total Loss: 872.9864\n",
      "Epoch 10/10, Batch 3740/4401, Batch Loss: 0.0983, Total Loss: 876.3011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 3750/4401, Batch Loss: 0.3366, Total Loss: 878.5667\n",
      "Epoch 10/10, Batch 3760/4401, Batch Loss: 0.3819, Total Loss: 880.6856\n",
      "Epoch 10/10, Batch 3770/4401, Batch Loss: 0.4367, Total Loss: 883.7261\n",
      "Epoch 10/10, Batch 3780/4401, Batch Loss: 0.0375, Total Loss: 886.1279\n",
      "Epoch 10/10, Batch 3790/4401, Batch Loss: 0.3635, Total Loss: 890.1154\n",
      "Epoch 10/10, Batch 3800/4401, Batch Loss: 0.3710, Total Loss: 892.8368\n",
      "Epoch 10/10, Batch 3810/4401, Batch Loss: 0.5131, Total Loss: 895.0605\n",
      "Epoch 10/10, Batch 3820/4401, Batch Loss: 0.1970, Total Loss: 897.4108\n",
      "Epoch 10/10, Batch 3830/4401, Batch Loss: 0.2383, Total Loss: 899.4557\n",
      "Epoch 10/10, Batch 3840/4401, Batch Loss: 0.2000, Total Loss: 900.8695\n",
      "Epoch 10/10, Batch 3850/4401, Batch Loss: 0.2633, Total Loss: 903.4729\n",
      "Epoch 10/10, Batch 3860/4401, Batch Loss: 0.2393, Total Loss: 905.2097\n",
      "Epoch 10/10, Batch 3870/4401, Batch Loss: 0.5569, Total Loss: 907.1315\n",
      "Epoch 10/10, Batch 3880/4401, Batch Loss: 0.2878, Total Loss: 909.5174\n",
      "Epoch 10/10, Batch 3890/4401, Batch Loss: 0.0002, Total Loss: 911.6799\n",
      "Epoch 10/10, Batch 3900/4401, Batch Loss: 0.2445, Total Loss: 913.5363\n",
      "Epoch 10/10, Batch 3910/4401, Batch Loss: 0.4317, Total Loss: 915.5184\n",
      "Epoch 10/10, Batch 3920/4401, Batch Loss: 0.3170, Total Loss: 917.4035\n",
      "Epoch 10/10, Batch 3930/4401, Batch Loss: 0.4816, Total Loss: 919.4674\n",
      "Epoch 10/10, Batch 3940/4401, Batch Loss: 0.1695, Total Loss: 921.2476\n",
      "Epoch 10/10, Batch 3950/4401, Batch Loss: 0.4061, Total Loss: 923.3718\n",
      "Epoch 10/10, Batch 3960/4401, Batch Loss: 0.3730, Total Loss: 925.9885\n",
      "Epoch 10/10, Batch 3970/4401, Batch Loss: 0.4934, Total Loss: 928.3276\n",
      "Epoch 10/10, Batch 3980/4401, Batch Loss: 0.4422, Total Loss: 930.8357\n",
      "Epoch 10/10, Batch 3990/4401, Batch Loss: 0.2200, Total Loss: 933.4956\n",
      "Epoch 10/10, Batch 4000/4401, Batch Loss: 0.2514, Total Loss: 935.6159\n",
      "Epoch 10/10, Batch 4010/4401, Batch Loss: 0.0471, Total Loss: 938.3486\n",
      "Epoch 10/10, Batch 4020/4401, Batch Loss: 0.2035, Total Loss: 939.7086\n",
      "Epoch 10/10, Batch 4030/4401, Batch Loss: 1.3389, Total Loss: 943.1094\n",
      "Epoch 10/10, Batch 4040/4401, Batch Loss: 0.0448, Total Loss: 946.0644\n",
      "Epoch 10/10, Batch 4050/4401, Batch Loss: 0.0463, Total Loss: 948.2130\n",
      "Epoch 10/10, Batch 4060/4401, Batch Loss: 0.9852, Total Loss: 951.0655\n",
      "Epoch 10/10, Batch 4070/4401, Batch Loss: 0.3578, Total Loss: 953.3483\n",
      "Epoch 10/10, Batch 4080/4401, Batch Loss: 0.4529, Total Loss: 955.1482\n",
      "Epoch 10/10, Batch 4090/4401, Batch Loss: 0.2156, Total Loss: 957.2363\n",
      "Epoch 10/10, Batch 4100/4401, Batch Loss: 0.0916, Total Loss: 958.8014\n",
      "Epoch 10/10, Batch 4110/4401, Batch Loss: 0.1777, Total Loss: 961.4993\n",
      "Epoch 10/10, Batch 4120/4401, Batch Loss: 0.1543, Total Loss: 964.5876\n",
      "Epoch 10/10, Batch 4130/4401, Batch Loss: 0.5418, Total Loss: 966.9807\n",
      "Epoch 10/10, Batch 4140/4401, Batch Loss: 0.1734, Total Loss: 969.3575\n",
      "Epoch 10/10, Batch 4150/4401, Batch Loss: 0.2347, Total Loss: 970.9555\n",
      "Epoch 10/10, Batch 4160/4401, Batch Loss: 0.2726, Total Loss: 973.4865\n",
      "Epoch 10/10, Batch 4170/4401, Batch Loss: 0.4567, Total Loss: 976.1805\n",
      "Epoch 10/10, Batch 4180/4401, Batch Loss: 0.1586, Total Loss: 978.9645\n",
      "Epoch 10/10, Batch 4190/4401, Batch Loss: 0.3420, Total Loss: 981.8087\n",
      "Epoch 10/10, Batch 4200/4401, Batch Loss: 0.1744, Total Loss: 984.5924\n",
      "Epoch 10/10, Batch 4210/4401, Batch Loss: 0.4366, Total Loss: 986.8281\n",
      "Epoch 10/10, Batch 4220/4401, Batch Loss: 0.2954, Total Loss: 989.6489\n",
      "Epoch 10/10, Batch 4230/4401, Batch Loss: 0.1174, Total Loss: 991.7657\n",
      "Epoch 10/10, Batch 4240/4401, Batch Loss: 0.2728, Total Loss: 994.5423\n",
      "Epoch 10/10, Batch 4250/4401, Batch Loss: 0.1407, Total Loss: 996.9013\n",
      "Epoch 10/10, Batch 4260/4401, Batch Loss: 0.1310, Total Loss: 998.9443\n",
      "Epoch 10/10, Batch 4270/4401, Batch Loss: 0.1312, Total Loss: 1001.0636\n",
      "Epoch 10/10, Batch 4280/4401, Batch Loss: 0.3135, Total Loss: 1003.1905\n",
      "Epoch 10/10, Batch 4290/4401, Batch Loss: 0.1339, Total Loss: 1005.0281\n",
      "Epoch 10/10, Batch 4300/4401, Batch Loss: 0.3329, Total Loss: 1006.7533\n",
      "Epoch 10/10, Batch 4310/4401, Batch Loss: 0.0878, Total Loss: 1008.4896\n",
      "Epoch 10/10, Batch 4320/4401, Batch Loss: 0.2067, Total Loss: 1010.5631\n",
      "Epoch 10/10, Batch 4330/4401, Batch Loss: 0.2312, Total Loss: 1012.1492\n",
      "Epoch 10/10, Batch 4340/4401, Batch Loss: 0.1881, Total Loss: 1014.2024\n",
      "Epoch 10/10, Batch 4350/4401, Batch Loss: 0.2172, Total Loss: 1016.7302\n",
      "Epoch 10/10, Batch 4360/4401, Batch Loss: 0.1441, Total Loss: 1018.8970\n",
      "Epoch 10/10, Batch 4370/4401, Batch Loss: 0.3164, Total Loss: 1020.9948\n",
      "Epoch 10/10, Batch 4380/4401, Batch Loss: 0.1028, Total Loss: 1022.8512\n",
      "Epoch 10/10, Batch 4390/4401, Batch Loss: 0.0594, Total Loss: 1025.1488\n",
      "Epoch 10/10, Batch 4400/4401, Batch Loss: 0.2853, Total Loss: 1027.7258\n",
      "Epoch 10/10, Batch 4401/4401, Batch Loss: 0.2307, Total Loss: 1027.9566\n",
      "Epoch 10/10 completed. Total Loss: 1027.9566\n"
     ]
    }
   ],
   "source": [
    "print(\"Training BERT\")  \n",
    "train_model_with_logs(bert_model, bert_criterion, bert_optimizer, train_loader, epochs=10, is_bert=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating BERT\n",
      "\n",
      "Running Validation...\n",
      "Validation Batch 10/1101 completed.\n",
      "Validation Batch 20/1101 completed.\n",
      "Validation Batch 30/1101 completed.\n",
      "Validation Batch 40/1101 completed.\n",
      "Validation Batch 50/1101 completed.\n",
      "Validation Batch 60/1101 completed.\n",
      "Validation Batch 70/1101 completed.\n",
      "Validation Batch 80/1101 completed.\n",
      "Validation Batch 90/1101 completed.\n",
      "Validation Batch 100/1101 completed.\n",
      "Validation Batch 110/1101 completed.\n",
      "Validation Batch 120/1101 completed.\n",
      "Validation Batch 130/1101 completed.\n",
      "Validation Batch 140/1101 completed.\n",
      "Validation Batch 150/1101 completed.\n",
      "Validation Batch 160/1101 completed.\n",
      "Validation Batch 170/1101 completed.\n",
      "Validation Batch 180/1101 completed.\n",
      "Validation Batch 190/1101 completed.\n",
      "Validation Batch 200/1101 completed.\n",
      "Validation Batch 210/1101 completed.\n",
      "Validation Batch 220/1101 completed.\n",
      "Validation Batch 230/1101 completed.\n",
      "Validation Batch 240/1101 completed.\n",
      "Validation Batch 250/1101 completed.\n",
      "Validation Batch 260/1101 completed.\n",
      "Validation Batch 270/1101 completed.\n",
      "Validation Batch 280/1101 completed.\n",
      "Validation Batch 290/1101 completed.\n",
      "Validation Batch 300/1101 completed.\n",
      "Validation Batch 310/1101 completed.\n",
      "Validation Batch 320/1101 completed.\n",
      "Validation Batch 330/1101 completed.\n",
      "Validation Batch 340/1101 completed.\n",
      "Validation Batch 350/1101 completed.\n",
      "Validation Batch 360/1101 completed.\n",
      "Validation Batch 370/1101 completed.\n",
      "Validation Batch 380/1101 completed.\n",
      "Validation Batch 390/1101 completed.\n",
      "Validation Batch 400/1101 completed.\n",
      "Validation Batch 410/1101 completed.\n",
      "Validation Batch 420/1101 completed.\n",
      "Validation Batch 430/1101 completed.\n",
      "Validation Batch 440/1101 completed.\n",
      "Validation Batch 450/1101 completed.\n",
      "Validation Batch 460/1101 completed.\n",
      "Validation Batch 470/1101 completed.\n",
      "Validation Batch 480/1101 completed.\n",
      "Validation Batch 490/1101 completed.\n",
      "Validation Batch 500/1101 completed.\n",
      "Validation Batch 510/1101 completed.\n",
      "Validation Batch 520/1101 completed.\n",
      "Validation Batch 530/1101 completed.\n",
      "Validation Batch 540/1101 completed.\n",
      "Validation Batch 550/1101 completed.\n",
      "Validation Batch 560/1101 completed.\n",
      "Validation Batch 570/1101 completed.\n",
      "Validation Batch 580/1101 completed.\n",
      "Validation Batch 590/1101 completed.\n",
      "Validation Batch 600/1101 completed.\n",
      "Validation Batch 610/1101 completed.\n",
      "Validation Batch 620/1101 completed.\n",
      "Validation Batch 630/1101 completed.\n",
      "Validation Batch 640/1101 completed.\n",
      "Validation Batch 650/1101 completed.\n",
      "Validation Batch 660/1101 completed.\n",
      "Validation Batch 670/1101 completed.\n",
      "Validation Batch 680/1101 completed.\n",
      "Validation Batch 690/1101 completed.\n",
      "Validation Batch 700/1101 completed.\n",
      "Validation Batch 710/1101 completed.\n",
      "Validation Batch 720/1101 completed.\n",
      "Validation Batch 730/1101 completed.\n",
      "Validation Batch 740/1101 completed.\n",
      "Validation Batch 750/1101 completed.\n",
      "Validation Batch 760/1101 completed.\n",
      "Validation Batch 770/1101 completed.\n",
      "Validation Batch 780/1101 completed.\n",
      "Validation Batch 790/1101 completed.\n",
      "Validation Batch 800/1101 completed.\n",
      "Validation Batch 810/1101 completed.\n",
      "Validation Batch 820/1101 completed.\n",
      "Validation Batch 830/1101 completed.\n",
      "Validation Batch 840/1101 completed.\n",
      "Validation Batch 850/1101 completed.\n",
      "Validation Batch 860/1101 completed.\n",
      "Validation Batch 870/1101 completed.\n",
      "Validation Batch 880/1101 completed.\n",
      "Validation Batch 890/1101 completed.\n",
      "Validation Batch 900/1101 completed.\n",
      "Validation Batch 910/1101 completed.\n",
      "Validation Batch 920/1101 completed.\n",
      "Validation Batch 930/1101 completed.\n",
      "Validation Batch 940/1101 completed.\n",
      "Validation Batch 950/1101 completed.\n",
      "Validation Batch 960/1101 completed.\n",
      "Validation Batch 970/1101 completed.\n",
      "Validation Batch 980/1101 completed.\n",
      "Validation Batch 990/1101 completed.\n",
      "Validation Batch 1000/1101 completed.\n",
      "Validation Batch 1010/1101 completed.\n",
      "Validation Batch 1020/1101 completed.\n",
      "Validation Batch 1030/1101 completed.\n",
      "Validation Batch 1040/1101 completed.\n",
      "Validation Batch 1050/1101 completed.\n",
      "Validation Batch 1060/1101 completed.\n",
      "Validation Batch 1070/1101 completed.\n",
      "Validation Batch 1080/1101 completed.\n",
      "Validation Batch 1090/1101 completed.\n",
      "Validation Batch 1100/1101 completed.\n",
      "Validation Batch 1101/1101 completed.\n",
      "Validation Accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating BERT\")\n",
    "bert_predictions = validate_model_with_logs(bert_model, val_loader, is_bert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "output_data = {\n",
    "    \"bert_predictions\": bert_predictions\n",
    "}\n",
    "output_df = pd.DataFrame(output_data)\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions saved to predictions.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved.\n"
     ]
    }
   ],
   "source": [
    "bert_model.save_pretrained(\"bert_model\")\n",
    "print(\"Models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
